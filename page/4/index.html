<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Blog of Qing">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Blog of Qing">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/08/ML-Pandas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/08/ML-Pandas/" itemprop="url">Python - Pandas</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-08T01:16:54-05:00">
                2018-06-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文参考<a href="https://www.yiibai.com/pandas/python_pandas_data_structures.html" target="_blank" rel="noopener">1</a></p>
<p>pandas导入</p>
<!--�442-->
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/08/ML-Pandas/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/07/ML-SciPy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/07/ML-SciPy/" itemprop="url">Python-SciPy</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-07T23:41:31-05:00">
                2018-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Scipy基于Numpy，提供了大量科学算法，它的不同子模块相应于不同的应用，本文参考了<a href="https://www.jianshu.com/p/1a3db06e786d" target="_blank" rel="noopener">1</a> <a href="https://www.yiibai.com/scipy/" target="_blank" rel="noopener">2</a></p>
<ol>
<li>文件IO（scipy.io）：数据输入输出</li>
<li>特殊函数（scipy.special）：特殊函数是先验函数，常用的有伽马函数scipy.special.gamma()</li>
<li>线性代数运算（scipy.linalg）</li>
<li>快速傅里叶变化（scipy.fftpack）</li>
<li>优化和拟合（scipy.optimize）：提供了函数最小值(标量或多维)、曲线拟合和寻找等式的根的有用算法。</li>
<li>统计和随机数（scipy.stats）</li>
<li>数值积分（scipy.integrate Fusy）</li>
</ol>
<p>模块导入的标准方式是：</p>
<!--�124-->
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/07/ML-SciPy/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/07/ML-Sklearn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/07/ML-Sklearn/" itemprop="url">Python - Sklearn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-07T23:32:12-05:00">
                2018-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文参考了<a href="https://morvanzhou.github.io/tutorials/machine-learning/sklearn/" target="_blank" rel="noopener">1</a></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/07/ML-Sklearn/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/05/ML - Frequent Itemset Mining/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/05/ML - Frequent Itemset Mining/" itemprop="url">ML - Frequent Itemset Mining</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-05T16:41:24-05:00">
                2018-06-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>An association rule is a pattern that states when an event occurs, another event occurs with certain probability. Association relus find all sets of items that have support count greater than the mimimum support; then using the large itemsets to generate the desired rules that have confidence greater than the minimum confidence. For frequent itemset mining, we use Apriori algorithm.</p>
<p>The following details are from <a href="https://www.youtube.com/watch?v=Hk1zFOMLTrw" target="_blank" rel="noopener">The Apriori Algorithm … How The Apriori Algorithm Works</a>.</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/05/ML - Frequent Itemset Mining/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/04/Algorithm-Bloom-Filter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/04/Algorithm-Bloom-Filter/" itemprop="url">Algorithm - Bloom Filter</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-04T16:35:27-05:00">
                2018-06-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Algorithm/" itemprop="url" rel="index">
                    <span itemprop="name">Algorithm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>文字参考自<a href="https://blog.csdn.net/hguisu/article/details/7866173" target="_blank" rel="noopener">海量数据处理算法—Bloom Filter</a>.</p>
<p>Bloom Filter（BF）是一种空间效率很高的随机数据结构，它是一个判断元素是否存在集合的快速的概率算法。Bloom Filter有可能会出现错误判断，但不会漏掉判断。也就是Bloom Filter判断元素不再集合，那肯定不在。如果判断元素存在集合中，有一定的概率判断错误。因此，Bloom Filter不适合那些“零错误”的应用场合。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/04/Algorithm-Bloom-Filter/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/03/ML-Expectation-Maximization-Algorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/03/ML-Expectation-Maximization-Algorithm/" itemprop="url">ML - Expectation Maximization Algorithm</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-03T16:19:45-05:00">
                2018-06-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>下文资料参考了<a href="https://www.cnblogs.com/zlslch/p/6965374.html" target="_blank" rel="noopener">EM(期望最大化)算法初步认识</a></p>
<p><strong>极大似然估计</strong>，是参数估计的方法之一。其基本思想是已知样本符合某种概率分布，但是分布的参数未知，于是通过采样的随机样本估计参数。其基本步骤是：</p>
<ol>
<li>求出似然函数：该样本集的概率，即每个样本出现的概率连积</li>
<li>对似然函数取对数：将连乘变连加</li>
<li>求导：使对数似然函数取最大值的参数便是结果</li>
<li>求解方程：得到的参数即为所求。</li>
</ol>
<p><strong>期望最大算法</strong>，是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。在每一次的迭代过程中，主要分为两步：即求期望(Expectation)步骤和最大化(Maximization)步骤。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/03/ML-Expectation-Maximization-Algorithm/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/02/DP-Application - Local-Privacy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/02/DP-Application - Local-Privacy/" itemprop="url">DP Application - Local Privacy</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-02T16:22:23-05:00">
                2018-06-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Differential-Privacy/" itemprop="url" rel="index">
                    <span itemprop="name">Differential Privacy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Q"><a href="#Q" class="headerlink" title="Q?"></a>Q?</h2><ol>
<li>the communication cost of $n$ users for Bassily and Smith is $log_2(n)$</li>
<li>the communication cost of $n$ users for k-rr is $log_2d$</li>
<li><a href="https://arxiv.org/pdf/1705.04421.pdf" target="_blank" rel="noopener">[Optimizing Locally Differentially Private Protocols]</a> remains : what is pure? THE protocol? BLH? Threshold $T_s$ in experiment and true/false positive?</li>
</ol>
<h2 id="T"><a href="#T" class="headerlink" title="T!"></a>T!</h2><ol>
<li>in order to optimize ldp protocol, tends to optimize encoding step,</li>
<li>using domain knowledge to elimate impossible candidates to narrow down the size of encoded input.<a href="https://arxiv.org/pdf/1708.06674.pdf" target="_blank" rel="noopener">Locally Differentially Private Heavy Hitter Identification</a></li>
<li></li>
</ol>
<p>Local differential privacy (LDP) techniques collects randomized answers from each user, with guarantees of plausible <a href="https://arxiv.org/pdf/1712.01524.pdf" target="_blank" rel="noopener">deniability</a>; meanwhile, the aggregator can still build accurate models and predictors by analyzing large amounts of such randomized data.</p>
<p>Unlike other models of differential privacy, which publish randomized aggregates but still collect the exact sensitive data, LDP avoids collecting exact personal information in the first place, thus providing a stronger assurance to the users and to the aggregator.</p>
<p>The well-established Laplace mechanism and exponential mechanism are no longer suitable to the local setting in which a user may have only a single element to release and laplace noise may introduce too much noise.  But unlike the laplace mechanism where we can use the noisy output directly, we need to do some estimation on the randomized output to get the estimator in LDP.<a href="https://davidyinyang.weebly.com/uploads/9/8/6/2/9862052/ccs16-ldp.pdf" target="_blank" rel="noopener">2016-Zhan</a></p>
<p><img src="/2018/06/02/DP-Application - Local-Privacy/Screen Shot 2018-06-11 at 10.16.20 PM.png" alt="Screen Shot 2018-06-11 at 10.16.20 PM"></p>
<h2 id="Development-Track"><a href="#Development-Track" class="headerlink" title="Development Track"></a>Development Track</h2><p>Local differential privacy starts from randomized response. At first, it collects <strong>binary categorical data</strong> from clients with <u>W-RR</u> algorithm. Then, polybasic categorical data is considered with solutions like <u>K-RR</u> and <u>K-RAPPOR</u> methods. After that, <u>Random Matrix Projection</u> is proposed for dealling with extremely large categorical data in the practical setting. </p>
<p>Since the method above is limited to categorical data, so <a href="https://arxiv.org/pdf/1302.3203.pdf" target="_blank" rel="noopener">[Duchi et al.]</a> proposed for <strong>numeric data</strong> and details algorithm is in <a href="https://arxiv.org/pdf/1606.05053.pdf" target="_blank" rel="noopener">[Collecting and Analyzing Data from Smart Device Users with Local Differential Privacy]</a> and based on Duchi, <u>harmony algorithm</u> is developed. </p>
<p>The most methods above assmue that each client only has one value, so the mechanism for <u>set-value</u> setting is proposed <a href="https://davidyinyang.weebly.com/uploads/9/8/6/2/9862052/ccs16-ldp.pdf" target="_blank" rel="noopener">[Heavy Hitter Estimation over Set-Valued Data with Local Differential Privacy]</a>.</p>
<p>And in real world, the collecting process in the client end happens frequently, like daily or every few hours. So methods for <strong>data collecting regularly</strong> is proposed like <u>RAPPOR</u> and <a href="https://arxiv.org/pdf/1712.01524.pdf" target="_blank" rel="noopener">[Collecting Telemetry Data Privately]</a></p>
<p>Recently, a mechanism for computing <strong>joint distribution</strong> of data attributes collected by LDP is proposed in <a href="https://arxiv.org/pdf/1503.01214.pdf" target="_blank" rel="noopener">[Building a RAPPOR with the Unknown- Privacy-Preserving Learning of Associations and Data Dictionaries 12.45.24 PM]</a> and <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8306916" target="_blank" rel="noopener">[LoPub: High-Dimensional Crowdsourced Data Publication With Local Differential Privacy]</a></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/06/02/DP-Application - Local-Privacy/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/30/DP-Mechanism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/30/DP-Mechanism/" itemprop="url">Mechanism of Differential Privacy</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-30T18:10:21-05:00">
                2018-05-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Differential-Privacy/" itemprop="url" rel="index">
                    <span itemprop="name">Differential Privacy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Laplace-Distribution"><a href="#Laplace-Distribution" class="headerlink" title="Laplace Distribution"></a>Laplace Distribution</h1><p>The following details are from <a href="https://zh.wikipedia.org/wiki/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83" target="_blank" rel="noopener">Wikipedia</a>. And the python version is <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.laplace.html" target="_blank" rel="noopener">here</a></p>
<h2 id="PDF"><a href="#PDF" class="headerlink" title="PDF"></a>PDF</h2><p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-05-30 at 6.17.03 PM.png" alt="Screen Shot 2018-05-30 at 6.17.03 PM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Laplace_distribution_pdf-7722463.png" alt="Laplace_distribution_pdf-7722463"></p>
<blockquote>
<ol>
<li>概率密度函数反映了概率在$ x$点处的密集程度。</li>
<li>x轴表示每一种取值，而y轴表示概率。</li>
<li>the variance of this distribution is $\sigma^2=2b^2$, while its scale is $b$.</li>
</ol>
</blockquote>
<h2 id="CDF"><a href="#CDF" class="headerlink" title="CDF"></a>CDF</h2><p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-05-30 at 6.18.29 PM.png" alt="Screen Shot 2018-05-30 at 6.18.29 PM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Laplace_distribution_cdf.png" alt="Laplace_distribution_cdf"></p>
<blockquote>
<ol>
<li>CDF表示连续累积概率，即$F(0)=P(x\le{0})$，即所有非正值的概率和。</li>
<li>PDF 表示某一点取值的概率$f(0)=P(x=0)=0.5$</li>
</ol>
</blockquote>
<h1 id="Sensitivity"><a href="#Sensitivity" class="headerlink" title="Sensitivity"></a>Sensitivity</h1><h2 id="L1-sensitivity"><a href="#L1-sensitivity" class="headerlink" title="L1-sensitivity"></a>L1-sensitivity</h2><blockquote>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 3.41.25 PM.png" alt="Screen Shot 2018-06-06 at 3.41.25 PM"></p>
<p><strong>Remarks</strong>:</p>
<ol>
<li>$N^{|X|}$ 表示数据库的大小是$|X|$, 即有$X$条记录；而$\mathbb{R}$表示real number，$\mathbb{R}^{k}$则表示$k$维空间，即数据是$k$维的，$k$维向量。</li>
<li></li>
</ol>
</blockquote>
<h1 id="Laplace-Mechanism"><a href="#Laplace-Mechanism" class="headerlink" title="Laplace Mechanism"></a><a href="https://link.springer.com/content/pdf/10.1007%2F11681878_14.pdf" target="_blank" rel="noopener">Laplace Mechanism</a></h1><p>TO DO QUESTION??</p>
<ol>
<li><p>WHY LAPLACE DISTRIBUTION????</p>
</li>
<li><p>WHY SENSITIVITY IN THE SCALE????</p>
</li>
</ol>
<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><blockquote>
<p>the Laplace mechanism will simply compute $f$, and perturb each coordinate with noise drawn from the Laplace distribution.</p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 3.48.56 PM.png" alt="Screen Shot 2018-06-06 at 3.48.56 PM"></p>
<p>About the proof, the key is that :</p>
<ol>
<li><p>neighbourhood database:</p>
<p> $x\in{N^{|X|}}$ and $y\in{N^{|X|}}$, such that $||x-y||_1=\le1$. </p>
</li>
<li><p>noise result:</p>
<p>$\frac{P(f(x)=z)}{P(f(y)=z)}\le{e^{\epsilon}}$</p>
</li>
</ol>
<p>Remarks:</p>
<ol>
<li><p>Let $\hat{f(x)}$ be the output of Laplace mechanism with zero mean given an input $x$. Then, for ant $x$, $\mathbb{E}[\hat{f(x)}]=f(x)$, where $f(x)$ is true query result without any perturbation.</p>
<p>$\mathbb{E}[\hat{f(x)}]=\int{P(x)}\hat{f(x)}dx=\int{P(x)(f(x)+n(x))}dx=f(x)\int{P(x)}dx+\int{P(x)n(x)}dx$</p>
<p>Obviously, $\int{P(x)}dx=1$, since the distribution of $n$ has zero mean so it is symmetric. For any $Pr(x)$, there are always two variables $n_1$ and $n_2$ such that $n_2=-n_1$, resulting in $P(n_1)n_1+P(n_2)n_2=0$. So $\int{P(x)n(x)}dx=0$.</p>
<p>SO $\mathbb{E}[\hat{f(x)}]=f(x)$</p>
</li>
<li><p>The error introduced by $Lap(0,\frac 1 \epsilon) \ is\  \frac 1 \epsilon​$</p>
<p>Assume $X$ is true answer and $Y=X+n$ is the noise output. $Error^2=E((Y-X)^2)=E(n^2)=E((n-E(n))^2)=E((n-0)^2)=Var(n)$</p>
<p>so the variance of noise distribution is the error, which is $\sqrt 2 b=\sqrt 2 \frac{1}{\epsilon}$ </p>
</li>
</ol>
</blockquote>
<h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><h3 id="Divisibility-of-Laplace-Distribution"><a href="#Divisibility-of-Laplace-Distribution" class="headerlink" title="Divisibility of Laplace Distribution"></a><a href="https://link.springer.com/content/pdf/10.1007%2Fs00450-016-0310-y.pdf" target="_blank" rel="noopener">Divisibility of Laplace Distribution</a></h3><p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-25 at 9.46.44 PM.png" alt="Screen Shot 2018-06-25 at 9.46.44 PM"></p>
<h2 id="Python-Implement"><a href="#Python-Implement" class="headerlink" title="Python Implement"></a>Python Implement</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise</span><span class="params">()</span>:</span></div>
<div class="line">    loc = <span class="number">0</span></div>
<div class="line">    scale = <span class="number">1</span></div>
<div class="line">    noise = np.random.laplace(loc,scale,<span class="number">1</span>) <span class="comment">#返回一个list</span></div>
<div class="line">    <span class="keyword">return</span> noise[<span class="number">0</span>]</div>
</pre></td></tr></table></figure>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><blockquote>
<p>We sometimes refer to the problem of responding to large numbers of (possibly arbitrary) queries as the query release problem.</p>
<ol>
<li><p>Counting Queries</p>
<p>Since the sensitivity of a counting query is 1 (the addition or deletion of a single individual can change a count by at most 1), so $(\epsilon,0)$-differential privacy can be achieved for counting queries by the addition of noise scaled to $\frac{1}{\epsilon}$, that is, by adding noise drawn from Lap($\frac{1}{\epsilon}$). The expected distortion, or error, is $\frac{1}{\epsilon}$, independent of the size of the database.</p>
<p>A fixed but arbitrary list of m counting queries can be viewed as a vector-valued query. Absent any further information about the set of queries a worst-case bound on the sensitivity of this vector-valued query is m, as a single individual might change every count. In this case $(\epsilon,0)$-differential privacy can be achieved by adding noise scaled to $\frac{m}{\epsilon}$ to the true answer to each query.</p>
</li>
<li><p>Histogram Queries</p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 4.04.09 PM.png" alt="Screen Shot 2018-06-06 at 4.04.09 PM"></p>
</li>
</ol>
</blockquote>
<h2 id="Utility"><a href="#Utility" class="headerlink" title="Utility"></a>Utility</h2><blockquote>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 4.05.35 PM.png" alt="Screen Shot 2018-06-06 at 4.05.35 PM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 4.12.18 PM.png" alt="Screen Shot 2018-06-06 at 4.12.18 PM"></p>
<p>Remarks:</p>
<ol>
<li>Theorem3.8中，Pr[]里面，左边表示Laplace mechanism产生的error，右边中的两项，$t=In(\frac{k}{\delta})$，$k$是query result的维度，$b=\frac{\Delta{f}}{\epsilon}$。</li>
<li><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-06 at 4.18.19 PM.png" alt="Screen Shot 2018-06-06 at 4.18.19 PM"></li>
</ol>
</blockquote>
<h1 id="Exponential-mechanism"><a href="#Exponential-mechanism" class="headerlink" title="Exponential mechanism"></a>Exponential mechanism</h1><p>The exponential mechanism was designed for situations in which we wish to choose the “best” response but adding noise directly to the computed quantity can completely destroy its value, such as setting a price in an auction, where the goal is to maximize revenue, and adding a small amount of positive noise to the optimal price (in order to protect the privacy of a bid) could dramatically reduce the resulting revenue.</p>
<h2 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h2><p>The sensitivity of score function $q$ tells us the maximum change in the scoring function for any pair of datasets $d$ and $d’$ such that $|d\otimes d’|=1$:</p>
<script type="math/tex; mode=display">
\Delta q = max_{r,d,d' where |d\otimes d'|=1 }|q(d,r)-q(d',r)|</script><blockquote>
<p>Say we have a discrete candidate output in a range $R$, and assume that the probability distribution of output is $u$, commonly uniform. The general mechanism is to design a query function $q:D^n(input)\times{R(output)}\to{\mathbb{R}}$, which assign a real valued score to any pair $(d,r)$ from $D^n\times{R}$. With a prior distribution of candidate output $u$, we amplify the probability associated with each output by a factor of $e^{\epsilon{q(d,r)}}$:</p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-07 at 12.43.02 PM.png" alt="Screen Shot 2018-06-07 at 12.43.02 PM"></p>
<script type="math/tex; mode=display">
\Delta{q}=max_{r\in{R}}\ max_{x,y:||x-y||_1\le{1}}|q(x,r)-q(y-r)|</script><p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-07 at 12.47.15 PM.png" alt="Screen Shot 2018-06-07 at 12.47.15 PM"></p>
</blockquote>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-08 at 4.21.27 PM.png" alt="Screen Shot 2018-06-08 at 4.21.27 PM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-08 at 4.21.48 PM.png" alt="Screen Shot 2018-06-08 at 4.21.48 PM"></p>
<blockquote>
<p>Remarks:</p>
<ol>
<li><p>by amplifying the probability, the sum of all output probability will not equal 1. So in order to bound the probability, we need a normalization term.</p>
</li>
<li><p>from the denifition, if we set the probability factor as $\epsilon$, then it will provide us $2\epsilon \Delta q$, which amptifies with a factor $2\Delta q$. SO if we want $\epsilon$-DP, then the probability factor should be $\frac{\epsilon}{2\Delta q}$</p>
</li>
<li><p>the exponential mechanism defines a distribution over the output domain and samples from this distribution.</p>
</li>
<li><p>now we want to know how a small change in the database can affect the output. Say we have database $d$ and $d’$, where $||d-d’||=1$. And we assume $q(d,r)=q(d’,r)+\Delta{q}$. we want to bound the probability ratio $\frac{P(r|d)}{P(r|d’)}$</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
\frac{P(r|d)}{P(r|d')}&=\frac{e^{\epsilon{q(d,r)}}}{\int{e^{\epsilon{q(d,r)}}}}\div\frac{e^{\epsilon{q(d',r)}}}{\int{e^{\epsilon{q(d',r)}}}}\\
&=\frac{e^{\epsilon{q(d,r)}}}{e^{\epsilon{q(d',r)}}}\times\frac{\int{e^{\epsilon{q(d',r)}}}}{\int{e^{\epsilon{q(d,r)}}}}\\
for\ the\ left\ one,\ we\ replace\ q(d,r)=q(d',r)+\Delta{q} ,\\ for\ right\ since\ q(d',r)= q(d',r)-q(d,r)+q(d,r)
\\
&={\frac{e^{\epsilon{(q(d',r)+\Delta{q})}}}{e^{\epsilon{q(d',r)}}}}\times\frac{\int{e^{\epsilon{(q(d',r)}-\epsilon{(q(d,r)+\epsilon{(q(d,r)}})}}}
{\int{e^{\epsilon{q(d,r)}}}}\\
since\ |q(d',r)-q(d,r)|\le \Delta q,\ so\ we\ have \\
&\le  e^{\epsilon \Delta q} \times \int{e^{\epsilon \Delta q}}\\
&=e^{\epsilon \Delta q}\times{e^{\epsilon{\Delta{q}}}}\\
&=e^{2\epsilon \Delta q}
\end{aligned}
\end{equation}</script></li>
</ol>
</blockquote>
<h2 id="Utility-1"><a href="#Utility-1" class="headerlink" title="Utility"></a>Utility</h2><p>The exponential mechanism can often give strong utility guarantees, because it discounts outcomes exponentially quickly as their quality score falls off.</p>
<p>Let $OPT_{q}(d)=max_{r\in R}q(d,r)$ denote the maximum score of any candidate output $r\in R$ with respect to database $d$. </p>
<p>Fixing a database $d$, let $R_{OPT}=\{r\in R:q(d,r)=OPT_{q}(x)\}$ denote the set of candidates in $R$ which attain maximum utility score $OPT_q(x)$. Then:</p>
<p><strong>Theorem</strong>:</p>
<script type="math/tex; mode=display">
Pr[q(M_{E(d,q,R)}\le OPT_q(d)-\frac{2\Delta q}{\epsilon}(ln(\frac{|R|}{|R_{OPT}|})+t))]\le e^{-t}</script><p><strong>Corollary</strong>:</p>
<script type="math/tex; mode=display">
Pr[q(M_{E(d,q,R)}\le OPT_q(d)-\frac{2\Delta q}{\epsilon}(ln(|R|)+t))]\le e^{-t}</script><blockquote>
<p>Remarks:</p>
<ol>
<li>We bound the probability that the exponential mechanism returns a “good” output of $R$, where good is measured in terms of $OPT_q(d)$.  The result is that it will be highly unlikely that the returned output $r$ has a utility score that is inferior to $OPT_q(x)$ by more than an additive factoc of $O(\frac{\Delta q}{\epsilon}log|R|)$</li>
<li>from the utility theorem, we can find that utility of the mechanism only depends on log(|Outputs|), leading to the fact that sampling an output may not be computationally efficient if output space is large. </li>
<li><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-08 at 11.08.54 AM.png" alt="Screen Shot 2018-06-08 at 11.08.54 AM"></li>
<li><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-08 at 3.37.36 PM.png" alt="Screen Shot 2018-06-08 at 3.37.36 PM"></li>
<li></li>
</ol>
</blockquote>
<h2 id="Laplace-vs-Exponential"><a href="#Laplace-vs-Exponential" class="headerlink" title="Laplace vs Exponential"></a><a href="http://www.cs.bu.edu/~goldbe/teaching/HW55812/exponential.pdf" target="_blank" rel="noopener">Laplace vs Exponential</a></h2><p>Exponential mechanism is an instance of the exponential mechanism.</p>
<ol>
<li><p><strong>candidate output domain</strong></p>
<p>Say we have the output domian $r\in R$, and the query function is $f$ which works over the database $d$ and $d’$ such that $|d\otimes{d’}|=1$.</p>
</li>
<li><p><strong>utility function</strong></p>
<script type="math/tex; mode=display">
q(d,r)=-|f(d)-r|</script><p>To see how this works, notice first that with this scoring function, the exponential mechanism becomes:</p>
<p>$M(d,q,\epsilon)$=output $r$ with probability proportional to $e^{\epsilon q(d,r)}$</p>
<p>which provides $2\epsilon \Delta q$-DP.</p>
</li>
<li><p><strong>sensitivity</strong></p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
\Delta q &=max|q(d,r)-q(d',r)|\\
&=max||f(d')-r|-|f(d,r)||\\
&\le max|f(d',r)-f(d,r)| \ \ \ \ \ \ \ \ \ \ \ \ \ \ (triangle inequlity)\\
\end{aligned}
\end{equation}</script><blockquote>
<p>So based on above details, for query function with sensitivity 1 and with privacy parameter $\epsilon$, exponential mechanism provides $2\epsilon$-DP, while Laplace mechanism provides $\epsilon$-DP. This is because we’ve used the general analysis of the exponential mechanism, so our result is less “tight”.</p>
<p>This means that to provide the same privacy level $\epsilon$, laplace mechanism is $\epsilon-$DP while exponential mechanism is  $\frac{\epsilon}{2}$-DP, meaning more noise.</p>
</blockquote>
</li>
</ol>
<h2 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h2><p><strong>The median mechanism</strong></p>
<p>Recall that the median of a list numbers $d=\{1,2,4,5,6\}$ is 4; so we write $med(d)=4$</p>
<ol>
<li><p><strong>candidate ooutputs</strong></p>
<p>every element in $d$ is the possilble output of the median query.</p>
</li>
<li><p><strong>utility function</strong></p>
<p>For the median example, our scoring function will be:</p>
<p>$q(d,r)=-min|d\otimes d’|$ such that $med(d’)=r$</p>
<blockquote>
<p>What does it mean? The idea is that we take in a database $d$ and a candidate median $r$, and we look for a $d’$ that is as similar as possible to $d$, such that $med(d’)=r$.</p>
<p>For example, $d=\{1,2,3,4,5\}$ and candidate output $r=4$. What we want to do is to change $d$ to $d’$ so that  $med(d’)=4$. To do so, we can remove $1$ and $2$ from the $d$ to get $d’=\{3,4,5\}$. so $q(\{1,2,3,4,5\},4)=-2$. If $r=3$, $q(\{1,2,3,4,5\},4)=0$ becasue $3$ is the true median and we needn’t change anything about database $d$. </p>
</blockquote>
</li>
<li><p><strong>sensitivity</strong> </p>
<p>We can get $|q(d,r)-q(d’,r)|\le 1$. It is obvious because the input database is added or removed one element, for the unchanged database, the change you make to make $r$ median is $x$ step.  Now we have already help you make a step. So the best situation is you only need to maek (x-1) step for x as median. The utility change is 1. While the worst situation is the addition or removal in the original database don’t help you at all, so you still need $x$ step. So the utility change is 0.</p>
<p><strong>There is the mathametical proof.</strong></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-09 at 12.02.40 PM.png" alt="Screen Shot 2018-06-09 at 12.02.40 PM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-09 at 12.02.49 PM.png" alt="Screen Shot 2018-06-09 at 12.02.49 PM"></p>
</li>
</ol>
<h1 id="Composition-Theorems"><a href="#Composition-Theorems" class="headerlink" title="Composition Theorems"></a>Composition Theorems</h1><p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2009/06/sigmod115-mcsherry.pdf" target="_blank" rel="noopener">[2009-McSherry]</a> Any approach to privacy must address issues of composition: that several outputs may be taken together, and should still provide privacy guarantees even when subjected to joint analysis</p>
<p><a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" target="_blank" rel="noopener">[2014-Dwork]</a> The combination of two differentially private algorithms is differentially private itself. But the parameters $\epsilon$ and $\delta$ will necessarily degrade —- consider repeatedly computing the same statistic using the Laplace mechanism. The average of the answer given by each instance of the mechanism will eventually converge to the true value of the statistic, and so we cannot avoid that the strength of our privacy guarantee will degrade with repeated use.</p>
<h2 id="Sequential-composition"><a href="#Sequential-composition" class="headerlink" title="Sequential composition"></a>Sequential composition</h2><p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-11 at 9.55.46 AM.png" alt="Screen Shot 2018-06-11 at 9.55.46 AM"></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-11 at 10.31.41 AM.png" alt="Screen Shot 2018-06-11 at 10.31.41 AM"></p>
<blockquote>
<p>Proof:</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
Pr(M(X)=O)&
=\prod_{i=1}^{m}Pr(M_i(X)=O_i) \\
&\le \prod_{i=1}^{m} e^{\epsilon_i}Pr(M_i{(X')=O_i})\\
&=e^{\sum_{i=1}^{m}\epsilon_i}\prod_{i=1}^{m} Pr(M_i(X')=O_i)\\
&=e^{\sum_{i=1}^{m}\epsilon_i} Pr(M_i(X)=O)
\end{aligned}
\end{equation}</script><p>x</p>
</blockquote>
<h2 id="Parallel-composition"><a href="#Parallel-composition" class="headerlink" title="Parallel composition"></a>Parallel composition</h2><p>While general sequences of queries accumulate privacy costs additively, when the queries are applied to disjoint subsets of the data we can improve the bound. Specifically, if the domain of input records is partitioned into disjoint sets, independent of the actual data, and the restrictions of the input data to each part are subjected to differentially-private analysis, the ultimate privacy guarantee depends only on the worst of the guarantees of each analysis, not the sum.</p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-11 at 9.58.34 AM.png" alt="Screen Shot 2018-06-11 at 9.58.34 AM"></p>
<h2 id="KL-Divergence"><a href="#KL-Divergence" class="headerlink" title="KL-Divergence"></a>KL-Divergence</h2><blockquote>
<p>又叫相对熵，是衡量分布间距离的一个度量。</p>
</blockquote>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><blockquote>
<p>设$P(i)​$和$Q(i)​$是$X​$取值的两个概率分布，则$P​$相对$Q​$的KL-Divergence是：</p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-06-05 at 10.10.43 AM.png" alt="Screen Shot 2018-06-05 at 10.10.43 AM"></p>
</blockquote>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><blockquote>
<ol>
<li><p>非对称性</p>
<script type="math/tex; mode=display">
D(p||q)\ne{D(q||p)}</script></li>
<li><p>非负性</p>
<script type="math/tex; mode=display">
D(p||q)\ge0</script></li>
</ol>
</blockquote>
<p><a href="http://www.cis.upenn.edu/~aaroth/courses/slides/Lecture4.pdf" target="_blank" rel="noopener">[2011-Aaron]</a></p>
<p><img src="/2018/05/30/DP-Mechanism/Screen Shot 2018-05-31 at 3.10.30 PM.png" alt="Screen Shot 2018-05-31 at 3.10.30 PM"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[2014-Dwork] The Algorithmic Foundations of Differential Privacy</p>
<p>[2006-Dwork] Calibrating Noise to Sensitivity in Private Data Analysis</p>
<p>[2009-McSherry] Privacy Integrated Queries</p>
<p>[2016-Gunther Eibl] Differential privacy for real smart metering data</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/30/Statistic-110/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/30/Statistic-110/" itemprop="url">Statistic 110</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-30T16:20:26-05:00">
                2018-05-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/unit-i/" target="_blank" rel="noopener">Probabilistic Systems Analysis and Applied Probability</a></p>
<p><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/unit-iii/lecture-13/" target="_blank" rel="noopener">last time</a></p>
<p><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-436j-fundamentals-of-probability-fall-2008/index.htm" target="_blank" rel="noopener">[Fundamentals of Probability]</a></p>
<p><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-262-discrete-stochastic-processes-spring-2011/index.htm" target="_blank" rel="noopener">[Discrete Stochastic Processes]</a></p>
<h1 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h1><ol>
<li><p><strong>Definition</strong>:</p>
<script type="math/tex; mode=display">
P(AB)=P(A)P(B)</script><p><img src="/2018/05/30/Statistic-110/Screen%20Shot%202018-06-10%20at%2011.04.20%20PM.png" alt="Screen Shot 2018-06-10 at 11.04.20 PM"></p>
<p>Based on the pic, $P(AB)\ne P(A)P(B)$, so event A and event B are not independent event.</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-13 at 9.26.43 PM.png" alt="Screen Shot 2018-06-13 at 9.26.43 PM"></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-13 at 9.26.49 PM.png" alt="Screen Shot 2018-06-13 at 9.26.49 PM"></p>
</li>
</ol>
<h1 id="Discrete-Random-Variables"><a href="#Discrete-Random-Variables" class="headerlink" title="Discrete Random Variables"></a>Discrete Random Variables</h1><ol>
<li><p><strong>Probability mass function (PMF)</strong></p>
<p>it is the probability of a discrete random variable; while in continus setting, the probability of a random variable is called PDF.</p>
</li>
<li><p><strong>Expectation</strong></p>
<script type="math/tex; mode=display">
E(X)=\sum_{x}xp_X(x)</script><blockquote>
<ul>
<li>Average in large number of repetitions the experiment</li>
</ul>
</blockquote>
</li>
<li><p><strong>Properties of expectations</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-11 at 5.23.20 PM.png" alt="Screen Shot 2018-06-11 at 5.23.20 PM"></p>
<blockquote>
<ul>
<li>Once x is determined, then y is determined; so the probability of y is the probability of x;</li>
</ul>
</blockquote>
<p>If $\alpha , \beta$ are constants, then:</p>
<script type="math/tex; mode=display">
E(\alpha)=\alpha\\
E(\alpha X)=\alpha E(X)\\
E(\alpha X+\beta)=\alpha E(X)+\beta</script><p>But if A and B are two independent variables, then</p>
<script type="math/tex; mode=display">
\begin{equation}

\begin{aligned}

E(AB)&=\sum_A\sum_B(ab)P_{A,B}(a,b)\\

&=\sum_A\sum_B(ab)P_A(a)P_B(b)
\\&=E(A)E(B)
\end{aligned}

\end{equation}</script></li>
<li><p><strong>Variance</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-11 at 5.32.18 PM.png" alt="Screen Shot 2018-06-11 at 5.32.18 PM"></p>
<blockquote>
<ul>
<li>since $X$ is random while $E(X)$ is a number, so $X-E(X)$ is a random variable.</li>
<li>variance measures the average square distance from the mean.</li>
<li>a big variance means the variable are far away from the center while a small one means the variables are tightly concentrated around the mean value.</li>
</ul>
</blockquote>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-13 at 7.09.01 PM.png" alt="Screen Shot 2018-06-13 at 7.09.01 PM"></p>
<blockquote>
<p>In the example, since $X=Y$, then $X$ and $Y$ are not independent, so ..</p>
</blockquote>
</li>
<li><p><strong>Standard deviation</strong></p>
<script type="math/tex; mode=display">
\sigma_X=\sqrt{var(X)}</script></li>
<li><p><strong>Covariance</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-22 at 9.29.21 PM.png" alt="Screen Shot 2018-06-22 at 9.29.21 PM"></p>
</li>
<li><p><strong>Correlation coefficient</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-22 at 9.29.27 PM.png" alt="Screen Shot 2018-06-22 at 9.29.27 PM"></p>
</li>
</ol>
<h1 id="Binomial-Random-Variable"><a href="#Binomial-Random-Variable" class="headerlink" title="Binomial Random Variable"></a>Binomial Random Variable</h1><ol>
<li><p><strong>Definition</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-13 at 9.10.33 PM.png" alt="Screen Shot 2018-06-13 at 9.10.33 PM"></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-13 at 9.10.40 PM.png" alt="Screen Shot 2018-06-13 at 9.10.40 PM"></p>
</li>
<li><p><strong>Binomial mean and variance</strong></p>
<p>$X= # $ of successes in $n$ independent trials</p>
<p>$X_i=\left\{\begin{align} 1&amp; &amp; \text{if success in trial i}\\0&amp;&amp;\text{otherwise}\end{align}\right.$ </p>
<ul>
<li><p>$E(X_i)=p$</p>
<blockquote>
<p>$E(X_i)=p<em>1+(1-p)</em>0$</p>
</blockquote>
</li>
<li><p>$E(X)=np$</p>
<blockquote>
<p>$E(X)=E(x_1,x_2,…,x_n)=E(x_1)+E(x_2)+…+E(x_n)=np$</p>
</blockquote>
</li>
<li><p>$Var(X_i)=p-p^2$</p>
<blockquote>
<p>$Var(X_i)=E(X_i^2)-E(X_i)^2$</p>
<p>$X_i^2=\left\{\begin{align} 1&amp; &amp; \text{if success in trial i}\\0&amp;&amp;\text{otherwise}\end{align}\right.$</p>
<p>So $E(X_i^2)=1<em>p+0</em>(1-p)=p$</p>
<p>$Var(X_i)=E(X_i^2)-E(X_i)^2=p-p^2$</p>
</blockquote>
</li>
<li><p>$Var(X)=n(p-p^2)$</p>
<blockquote>
<p>$Var(X)=Var(X_i,X_2,…,X_n)$</p>
<p>because $X_i$ is independent to each other, so</p>
<p>$Var(X)=Var(X_i,X_2,…,X_n)=Var(X_1)+Var(X_2)+…+Var(X_n)=nVar(X_i)$</p>
</blockquote>
</li>
</ul>
</li>
<li><p><strong>Example-Hat Problem</strong></p>
<ul>
<li><p>$n$ people throw their hats in a box and then pick one at random.</p>
<p>Let $X$ be the number of people who get their own hat. We want to find out $E(X)$. This is Binomial distribution:</p>
<p>$X_i=\left\{\begin{align} 1&amp; &amp; \text{if i selects his hat}\\0&amp;&amp;\text{otherwise}\end{align}\right.$</p>
</li>
<li><p>$P(X_i)=\frac{1}{n}$</p>
</li>
<li><p>$E(X_i)=1<em>\frac{1}{n}+0</em>(1-\frac{1}{n})=\frac{1}{n}$</p>
</li>
<li><p>the $X_i$ are not independent</p>
</li>
<li><p>$E(X)=E(X_1)+E(X_2)+…+E(X_n)$ is always true no matter whether $X_i$ are independent or not.</p>
<p>$E(X)=E(X_1)+E(X_2)+…+E(X_n)=n*\frac{1}{n}=1$</p>
</li>
<li><p>$Var(X)=E(X^2)-E(X)^2=E(X^2)-1$</p>
<p>because $X$ is the number of people who has his hat, so $X=X_1+X_2+…+X_n$, then $X^2=\sum_i X_i^2+\sum_{i,j}X_iX_j$</p>
<p>$Var(X)=E(X^2)-1=nE(X_i^2)+n(n-1)E(X_iX_j)-1$</p>
<p>$E(X_i^2)=E(X_i)=\frac{1}{n}$</p>
<p>$P(X_iX_j=1)=P(X_i=1)P(X_J=1|X_i=1)=\frac{1}{n}\frac{1}{n-1}=E(X_iX_j)$</p>
<p>$Var(X)=E(X^2)-1=nE(X_i^2)+n(n-1)E(X_iX_j)-1=n\frac{1}{n}+n(n-1)\frac{1}{n}\frac{1}{n-1}-1=1$</p>
</li>
</ul>
</li>
</ol>
<h1 id="Continuous-Random-Variable"><a href="#Continuous-Random-Variable" class="headerlink" title="Continuous Random Variable"></a>Continuous Random Variable</h1><ol>
<li><p><strong>PDF (Probability Density Function)</strong> : </p>
<p>$X$ has PDF $f(x)$ if $P(a\le{X}\le{b})=\int_{a}^{b}f(x)$</p>
<blockquote>
<ul>
<li><p>According to this definition, the probability of one point is 0: $P(a\le{X}\le{a})=\int_{a}^{a}f(x)=0$</p>
</li>
<li><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 5.57.31 PM.png" alt="Screen Shot 2018-06-14 at 5.57.31 PM"></p>
<p>so pdf describes the the probability of intervals. </p>
</li>
<li><p>n</p>
</li>
</ul>
</blockquote>
</li>
<li><p><strong>Means and Variances</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.05.16 PM.png" alt="Screen Shot 2018-06-14 at 6.05.16 PM"></p>
</li>
<li><p><strong>continuous uniform r.v.</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.19.30 PM.png" alt="Screen Shot 2018-06-14 at 6.19.30 PM"></p>
<ul>
<li>$f(x)=\frac{1}{b-a},a\le x \le b$</li>
<li>$E(X)=\int_{a}^{b}x\frac{x}{b-a}=\frac{a+b}{2}$</li>
<li><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.21.59 PM.png" alt="Screen Shot 2018-06-14 at 6.21.59 PM"></li>
</ul>
</li>
<li><p><strong>Cumulative distribution function(CDF)</strong></p>
<p>if $X$ has PDF $f$, then the CDF is $F(X)=P(X\le{x})=\int_{-\infty}^{x}f(t)dt$</p>
</li>
<li><p><strong>Gaussian (normal) PDF</strong></p>
<ul>
<li><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.31.09 PM.png" alt="Screen Shot 2018-06-14 at 6.31.09 PM"></p>
<blockquote>
<p>The factor $\frac{1}{\sqrt{2\pi}}$ is to make the calculus equal 1.</p>
<p>$E(X)=1, Var(X)=1$</p>
</blockquote>
</li>
<li><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.37.15 PM.png" alt="Screen Shot 2018-06-14 at 6.37.15 PM"></p>
</li>
<li><p>Let $Y=aX+b$, then</p>
<p>$E(Y)=a\mu +b$, $Var(Y)=a^2 \sigma^2$</p>
<p>Fact: $Y\sim N(a\mu+b,a^2\sigma^2)$, which means linear functions of normal random variabls are themselevs normal.</p>
</li>
<li><p>If $X\sim N(\mu,\sigma^2)$, then $\frac{X-\mu}{\sigma}\sim N(0,1)$</p>
<p>so based on this transform, we can simplify our cdf calculation:</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-14 at 6.44.55 PM.png" alt="Screen Shot 2018-06-14 at 6.44.55 PM"></p>
</li>
</ul>
</li>
</ol>
<h1 id="Multiple-Continuous-Random-Variables"><a href="#Multiple-Continuous-Random-Variables" class="headerlink" title="Multiple Continuous Random Variables"></a>Multiple Continuous Random Variables</h1><h2 id="Joint-PDF"><a href="#Joint-PDF" class="headerlink" title="Joint PDF"></a>Joint PDF</h2><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 5.57.12 PM.png" alt="Screen Shot 2018-06-15 at 5.57.12 PM"></p>
<ul>
<li><p>From the joint to the marginal:</p>
<p>$f_X(x)=\int_{-\infin}^{\infin}f_{X,Y}(x,y)dy$</p>
</li>
<li><p>$X$ and $Y$ are called <strong>independent</strong> if:</p>
<p>$f_{X,Y}(x,y)=f_{X}(x)f_{Y}(y)$ </p>
</li>
</ul>
<h2 id="Buffon’s-needle"><a href="#Buffon’s-needle" class="headerlink" title="Buffon’s needle"></a>Buffon’s needle</h2><ol>
<li><p><strong>problem setting</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 6.10.37 PM.png" alt="Screen Shot 2018-06-15 at 6.10.37 PM"></p>
</li>
<li><p><strong>analysis</strong></p>
<p>$X$, $\Theta$ are uniform and independent to each other</p>
<p>$f_{X,\Theta}(x,\theta)=f_X(x)f_{\Theta}(\theta)=\frac{2}{d}\frac{2}{\pi}$, where $0\le x \le \frac{d}{2}$, $0\le \theta \le\frac{\pi}{2}$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 6.15.39 PM.png" alt="Screen Shot 2018-06-15 at 6.15.39 PM"></p>
</li>
</ol>
<h2 id="conditioning"><a href="#conditioning" class="headerlink" title="conditioning"></a>conditioning</h2><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 6.21.18 PM.png" alt="Screen Shot 2018-06-15 at 6.21.18 PM"></p>
<h2 id="Stick-breaking-example"><a href="#Stick-breaking-example" class="headerlink" title="Stick-breaking example"></a>Stick-breaking example</h2><h3 id="problem-setting"><a href="#problem-setting" class="headerlink" title="problem setting"></a>problem setting</h3><p>Break a stick of length $l$ twice: break at $X$ uniformly in $[0,l]$; then break at $Y$ uniformly in $[0,X]$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 6.26.23 PM.png" alt="Screen Shot 2018-06-15 at 6.26.23 PM"></p>
<h3 id="analysis"><a href="#analysis" class="headerlink" title="analysis"></a>analysis</h3><p>$f_{X,Y}(x,y)=f_{X}(x)f_{Y|X}(y|x)=\frac{1}{l}\frac{1}{x}$</p>
<p>$E(Y|X=x)=\int yf_{Y|X}(y|X=x)dy=\int_{0}^{x}y\frac{1}{x}dy=\frac{x}{2}$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-15 at 6.35.34 PM.png" alt="Screen Shot 2018-06-15 at 6.35.34 PM"></p>
<h1 id="Derived-Distribution"><a href="#Derived-Distribution" class="headerlink" title="Derived Distribution"></a>Derived Distribution</h1><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ol>
<li><p>The discrete value bayes</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 6.52.10 PM.png" alt="Screen Shot 2018-06-21 at 6.52.10 PM"></p>
<p>The continuous counterpart</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 6.53.27 PM.png" alt="Screen Shot 2018-06-21 at 6.53.27 PM"></p>
<p>discrete $x$ and continuous $y$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 6.58.50 PM.png" alt="Screen Shot 2018-06-21 at 6.58.50 PM"></p>
<p>continuous $x$ and discrete $y$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 6.58.55 PM.png" alt="Screen Shot 2018-06-21 at 6.58.55 PM"></p>
</li>
</ol>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><ol>
<li><p>Example One</p>
<p>Say $X : $ uniform on $[0,2]$. And we want to the PDF of $Y=X^3$.</p>
<blockquote>
<p>Firstly, we calculate the PMF of $Y$, $F_Y(y)$, where $y\in[0,8]$. According to the definition of PMF, </p>
<script type="math/tex; mode=display">
F_Y(y)=P(Y\le y)</script><p>And $Y=X^3$, so we have:</p>
<script type="math/tex; mode=display">
F_Y(y)=P(Y\le y)=P(X^3 \le y)=P(X\le y^{\frac{1}{3}})</script><p>Now we want to calculate the mass probability of $X\le y^{\frac{1}{3}}$. We know that $X$ is uniform, and according to the following pic,  $P(X\le y^{\frac{1}{3}})$ is the area of length=$ y^{\frac{1}{3}}$ and height=$\frac{1}{2}$</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 9.15.25 PM.png" alt="Screen Shot 2018-06-21 at 9.15.25 PM"></p>
<p>so we have</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-21 at 9.15.54 PM.png" alt="Screen Shot 2018-06-21 at 9.15.54 PM"></p>
</blockquote>
</li>
<li><p>Example Two</p>
<p>Calculate the PDF of $Y=aX+b$.</p>
<blockquote>
<script type="math/tex; mode=display">
F_Y(y)=P(Y\le y)=P(aX+b \le y)=P(aX \le y-b)\\


F_Y(y)=
\left\{

\begin{align} 

&P(X\le \frac{y-b}{a})  & \text{if a >=0 }\\

&P(X\ge \frac{y-b}{a})=1- P(X\le \frac{y-b}{a})&\text{if a <=0}

\end{align}

\right.</script><p>Then the PDF is:</p>
<script type="math/tex; mode=display">
F_Y(y)=
\left\{

\begin{align} 

&P(X\le \frac{y-b}{a})  & \text{if a >=0 }\\

&P(X\ge \frac{y-b}{a})=1- P(X\le \frac{y-b}{a})&\text{if a <=0}

\end{align}

\right.</script><p>Because the $P(X\le x)=F_X(x)$,</p>
<script type="math/tex; mode=display">
F_Y(y)=
\left\{

\begin{align} 

&F_X( \frac{y-b}{a})  & \text{if a >=0 }\\

&1- F_X( \frac{y-b}{a}) &\text{if a <=0}

\end{align}

\right.</script><p>Then the PDF is </p>
<script type="math/tex; mode=display">
f_Y(y)=
\left\{
\begin{align} 
&\frac{1}{a}f_X( \frac{y-b}{a})  & \text{if a >=0 }\\
&- \frac{1}{a}f_X( \frac{y-b}{a}) &\text{if a <=0}
\end{align}
\right.</script><p>So overall,</p>
<script type="math/tex; mode=display">
f_Y(y)=\frac{1}{|a|}f_X( \frac{y-b}{a})</script></blockquote>
</li>
</ol>
<h1 id="Bernoulli-process"><a href="#Bernoulli-process" class="headerlink" title="Bernoulli process"></a><a href="http://zhouyichu.com/randomized-algorithm/Randomized-Algorithms-2/" target="_blank" rel="noopener">Bernoulli process</a></h1><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-24 at 10.29.40 PM.png" alt="Screen Shot 2018-06-24 at 10.29.40 PM"></p>
<ol>
<li><p><strong>Definition</strong></p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-24 at 9.52.34 PM.png" alt="Screen Shot 2018-06-24 at 9.52.34 PM"></p>
</li>
<li><p><strong>Properties</strong></p>
<p>There is a random process and the sequence of random variables is $X_1, X_2,…$</p>
<script type="math/tex; mode=display">
E(X_t)=1\times p+0\times (1-p)=p\\
Var(X_t)=E(X_t^2)-E^2(X_t)=p-p^2</script><p>And for the infinite sequence and no matter what the variable value is, the probability of infinite sequence is :</p>
<script type="math/tex; mode=display">
P=P(X_1)P(X_2)...P(X_\infin)=p^k (1-p)^g\\
lim_{k\to\infin,g_\to \infin}p^k (1-p)^g=0\\
P=0</script><p>Number of success $S$ in $n$ time slots</p>
<script type="math/tex; mode=display">
P(S=k)=(_{k}^{n})p(1-p)\\
E[S]=kp\\
Var(S)=kp(1-p)</script><p>Let $T_1$ be the number of trials until first success:</p>
<blockquote>
<script type="math/tex; mode=display">
P(T_1=t)=(1-p)^{(t-1)}p</script><p>Memoryless peoperty: what happens in the past has no effect on the future random provess</p>
<script type="math/tex; mode=display">
E[T_1]=\frac{1}p{}\\
Var(T_1)=\frac{1-p}{p^2}</script></blockquote>
</li>
</ol>
<h1 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h1><p>乘除 —&gt; 加减</p>
<ol>
<li>$log_a(MN)=log_a{M}+log_a{N}$</li>
<li>$log_a{\frac{M}{N}}=log_a{M}-log_a{N}$</li>
</ol>
<h1 id="Unbiased-estimator"><a href="#Unbiased-estimator" class="headerlink" title="Unbiased estimator"></a><a href="https://www.zhihu.com/question/22983179/answer/23470969" target="_blank" rel="noopener">Unbiased estimator</a></h1><blockquote>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-06 at 9.20.56 PM.png" alt="Screen Shot 2018-06-06 at 9.20.56 PM"></p>
</blockquote>
<h1 id="Additive-Chernoff-Bound"><a href="#Additive-Chernoff-Bound" class="headerlink" title="Additive Chernoff Bound"></a>Additive Chernoff Bound</h1><p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-05 at 8.35.00 PM.png" alt="Screen Shot 2018-06-05 at 8.35.00 PM"></p>
<blockquote>
<p>上式即</p>
<script type="math/tex; mode=display">
P(|S\ge{\mu}|\ge\epsilon)\le2e^{-2m\epsilon^2}</script><p><img src="/2018/05/30/Statistic-110/929166-20161116214202513-1545949382.png" alt="929166-20161116214202513-1545949382"></p>
<p>Lemma说明我们用随机变量的均值$\hat{\phi}$取估计参数$\phi$, 估计的参数和实际参数的差超过一个特定数值的概率有一确定的上界，并且随着样本量m的增大，$\hat{\phi}$越接近$\phi$.</p>
</blockquote>
<h1 id="Johnson-Lindenstrauss-Lemma"><a href="#Johnson-Lindenstrauss-Lemma" class="headerlink" title="Johnson-Lindenstrauss Lemma"></a><a href="https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma" target="_blank" rel="noopener">Johnson-Lindenstrauss Lemma</a></h1><blockquote>
<p>The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved.</p>
<p><img src="/2018/05/30/Statistic-110/Screen Shot 2018-06-06 at 11.01.27 PM.png" alt="Screen Shot 2018-06-06 at 11.01.27 PM"></p>
<p>Remarks:</p>
<ol>
<li>the new dimention $n$ is decided by data sample number $m$ and error bound $\epsilon$; less error (small $\epsilon$) and more sample points require more dimensions, meaning the new dimension $n$ should not be too small; </li>
<li>Johnson–Lindenstrauss 引理表明任何高维数据集均可以被随机投影到一个较低维度的欧氏空间,同时可以控制pairwise距离的失真.</li>
</ol>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/28/DP-Application-Random-Response/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/28/DP-Application-Random-Response/" itemprop="url">DP Application - Random Response</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-28T17:31:23-05:00">
                2018-05-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Differential-Privacy/" itemprop="url" rel="index">
                    <span itemprop="name">Differential Privacy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-45871-7_17.pdf" target="_blank" rel="noopener">[2016-Atsushi]</a> gives a comprehensive survey about random response. Randomized response tends to be used in data collection scenario.Randomized response is purely a client-based privacy solution. It does not rely upon a trusted third-party server and puts control over data back to clients. The basic idea is answer truthfully with probability $p$, and answer randomly by picking a answer from the rest choices with probability $1-p$. And the rest choices include the true answer.</p>
<h3 id="Random-Response-and-its-Variant"><a href="#Random-Response-and-its-Variant" class="headerlink" title="Random Response and its  Variant"></a>Random Response and its  Variant</h3><h4 id="Definition-2016-Wang"><a href="#Definition-2016-Wang" class="headerlink" title="Definition[2016-Wang]"></a>Definition<a href="http://ceur-ws.org/Vol-1558/paper35.pdf" target="_blank" rel="noopener">[2016-Wang]</a></h4><p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 10.18.29 PM.png" alt="Screen Shot 2018-05-29 at 10.18.29 PM"></p>
<h4 id="Warner-Version"><a href="#Warner-Version" class="headerlink" title="Warner Version"></a>Warner Version</h4><p>Random response was first proposed by [1965-Warner]. The aim is to estimate the proportion $\pi(A)$ of people who have some attribute A.</p>
<p>Each user has  reports her true answer $t\in \{1,-1\}​$ with probability p, and a random answer with probability 1 − p. The latter has the same probability to be −1 and +1;</p>
<h5 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h5><ol>
<li>There are red cards and non-red cards in a box, where the ratio of red cards among all the cards is $q$ with $0 &lt; q &lt; 1$ and $q \ne \frac{1}{2}$. And user draws a card.</li>
<li>If red, answer truthfully to the question “I am a member of A”</li>
<li>Otherwise, answer truthfully to the question “I am a member of A”</li>
</ol>
<h5 id="Utility"><a href="#Utility" class="headerlink" title="Utility"></a>Utility</h5><p>Let $\hat{T}$ be the proportion to which the respondents reply “True.” It is easy to see that the expectation of $\hat{T}$  is:</p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 12.40.16 AM.png" alt="Screen Shot 2018-05-29 at 12.40.16 AM"></p>
<h5 id="Privacy-Analysis"><a href="#Privacy-Analysis" class="headerlink" title="Privacy Analysis"></a>Privacy Analysis</h5><p>According to the definition of Differential Privacy, the following ratio should be bounded,</p>
<script type="math/tex; mode=display">
P(A|A)\le{e^\epsilon{P(A|not \ A)}}\\
P(A|not \ A)\le{e^\epsilon{P(A|A)}}</script><p>$P(A|A)=q​$</p>
<p>$P(A| not \ A)=(1-q)$</p>
<p>So combining the above two, we have:</p>
<p>The randomized response satisfied $\epsilon$-Differential Privacy, where</p>
<script type="math/tex; mode=display">
\epsilon=max\{ln\frac{1-q}{q},ln\frac{q}{1-q}  \}</script><p><img src="/2018/05/28/DP-Application-Random-Response/myplot.jpeg" alt="myplot"></p>
<h4 id="Kuk-Version"><a href="#Kuk-Version" class="headerlink" title="Kuk Version"></a>Kuk Version</h4><p>Kuk’s proposed another kind of randomized response mechanism to estimate the proportion $\pi_A$, the same as Warner’s mechanism. </p>
<h5 id="Framework-1"><a href="#Framework-1" class="headerlink" title="Framework"></a>Framework</h5><ol>
<li>There are two boxes, $BOX_1$ and $BOX_2$. There are red and non-red cards in each box and the ratio of red cards in each box is $q_1,q_2$ respectively, where $0&lt;q_1,q_2&lt;1, q_1\ne{q_2}$. User takes one card from each box.</li>
<li>If this user is a member of A, then replies “red card” or “non-red card” in accordance<br>with the card taken from $BOX_1$</li>
<li>Otherwise, he does the same as above except that he takes a card from $BOX_2$.</li>
</ol>
<h5 id="Privacy-Analysis-1"><a href="#Privacy-Analysis-1" class="headerlink" title="Privacy Analysis"></a>Privacy Analysis</h5><p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.08.31 AM.png" alt="Screen Shot 2018-05-29 at 1.08.31 AM"></p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.08.51 AM.png" alt="Screen Shot 2018-05-29 at 1.08.51 AM"></p>
<h4 id="Negative-Survey-Mechanism"><a href="#Negative-Survey-Mechanism" class="headerlink" title="Negative Survey Mechanism"></a>Negative Survey Mechanism</h4><h5 id="Framework-2"><a href="#Framework-2" class="headerlink" title="Framework"></a>Framework</h5><p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.10.11 AM.png" alt="Screen Shot 2018-05-29 at 1.10.11 AM"></p>
<h5 id="Privacy-Analysis-2"><a href="#Privacy-Analysis-2" class="headerlink" title="Privacy Analysis"></a>Privacy Analysis</h5><p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.11.13 AM.png" alt="Screen Shot 2018-05-29 at 1.11.13 AM"></p>
<h4 id="t-times-Negative-Survey"><a href="#t-times-Negative-Survey" class="headerlink" title="t-times Negative Survey"></a>t-times Negative Survey</h4><h5 id="Privacy-Analysis-3"><a href="#Privacy-Analysis-3" class="headerlink" title="Privacy Analysis"></a>Privacy Analysis</h5><p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.12.13 AM-7574379.png" alt="Screen Shot 2018-05-29 at 1.12.13 AM-7574379"></p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-05-29 at 1.12.36 AM.png" alt="Screen Shot 2018-05-29 at 1.12.36 AM"></p>
<h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><h4 id="2011-Quercia"><a href="#2011-Quercia" class="headerlink" title="[2011-Quercia] "></a><a href="https://pdfs.semanticscholar.org/7e74/15857ddcc798affff74d7e615b0d29f6bf74.pdf" target="_blank" rel="noopener">[2011-Quercia] </a></h4><blockquote>
<h5 id="Framework-3"><a href="#Framework-3" class="headerlink" title="Framework"></a>Framework</h5><p>[2011-Quercia] uses random response to obfuscate locations.</p>
<p>Let $k$ be the number of locations on a map. Then, the main part of SpotMe works as follows:</p>
<ol>
<li>the mobile phone chooses the location k uniformly at random with probability $p$</li>
<li>it chooses the true location with probability $1-p$</li>
</ol>
<h5 id="Privacy-Analysis-4"><a href="#Privacy-Analysis-4" class="headerlink" title="Privacy Analysis"></a>Privacy Analysis</h5><p>According to the definition of Differential Privacy, the following ratio should be bounded,</p>
<script type="math/tex; mode=display">
P(L_{noise}|L_{true})\le{e^{\epsilon}P(L_{true}|L^{'}_{true})}</script><p>where $L_{true}$ is user’s actual location and $L^{‘}_{true}$ is the user’s location after making some changes while $L_{noise}$ is user’s obfuscated location.</p>
<p>$P(L_{true}|L_{true})=(1-p)+p*\frac{1}{k}$</p>
<p>$P(L_{true}|L^{‘}_{true})=p*\frac{1}{k}$</p>
<p>so after combining above two formulations, we have privacy bugdet:</p>
<script type="math/tex; mode=display">
\epsilon=ln\frac{k-(k-1)p}{p}</script></blockquote>
<h4 id="2016-Wang"><a href="#2016-Wang" class="headerlink" title="[2016-Wang]"></a><a href="http://ceur-ws.org/Vol-1558/paper35.pdf" target="_blank" rel="noopener">[2016-Wang]</a></h4><blockquote>
<p>Randomized Response vs. Laplace Mechanism</p>
<p><u><strong>Randomized Response</strong></u> </p>
<p>Without loss of generality, we assume the randomized response still favors the true value, i.e., $p_{00}, p_{11} &gt; 0.5$. Intuitively, under the same privacy standard, the mechanism with larger diagonal elements in the corresponding design matrix tends to achieve better utility.</p>
<ul>
<li><img src="/2018/05/28/DP-Application-Random-Response/Screen%20Shot%202018-06-01%20at%205.09.06%20PM.png" alt="Screen Shot 2018-06-01 at 5.09.06 PM"></li>
<li>What is the proportion of $X=1$? It aims to o learn the population distribution based on the collected randomized dataset. We use $\pi_1$to denote the true proportion of value 1 to be estimated in the original population. The observed proportion of value 1 in the collected dataset is denoted as $\lambda_1$. We denote the unbiased estimator for $\pi_1$ respectively as $\hat{\pi}_1$. </li>
<li><p><img src="/2018/05/28/DP-Application-Random-Response/Screen%20Shot%202018-06-01%20at%205.13.14%20PM.png" alt="Screen Shot 2018-06-01 at 5.13.14 PM"></p>
<p><strong><u>Laplace Mechanism</u></strong></p>
</li>
<li><p><img src="/2018/05/28/DP-Application-Random-Response/Screen%20Shot%202018-06-01%20at%205.22.11%20PM.png" alt="Screen Shot 2018-06-01 at 5.22.11 PM"></p>
</li>
<li><img src="/2018/05/28/DP-Application-Random-Response/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/DP-Application-Random-Response/Screen%20Shot%202018-06-01%20at%205.23.19%20PM-7891843.png" alt="Screen Shot 2018-06-01 at 5.23.19 PM-7891843"></li>
<li><img src="/2018/05/28/DP-Application-Random-Response/Screen%20Shot%202018-06-01%20at%205.24.26%20PM.png" alt="Screen Shot 2018-06-01 at 5.24.26 PM"></li>
<li></li>
</ul>
</blockquote>
<h4 id="2006-Huseyin"><a href="#2006-Huseyin" class="headerlink" title="[2006-Huseyin]"></a><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.3576&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">[2006-Huseyin]</a></h4><p><strong>One-Group Scheme</strong>s  vs <strong>Multi-Group Schemes</strong>. </p>
<blockquote>
<p>in my understanding, one-group means there arw n users and m items. for a user, all the items rating are in a group. For example, user_i’s true rateing for all items is (0101),with probability theta to upload (0101) and (1-theta) probability to upload (1010).</p>
<p>And in m-group, for example m=2, then user_i’s rating is (01)and(11). with probability theta1 to upload (01) and (1-theta1) to upload (10); theta2 to upload(11) and (1-theta2) to upload (00)</p>
<p>Although we achieve decent accuracy in this scheme, the privacy level is very low. We improve privacy level by introducing multi-group schemes, while with increasing M, accuracy decreases because we add more randomness. The accuracy is from how much info is preserved after randomness. The more info, the more accurate. P(true=x|randon resp = x) means preserved info. m-group info preserved: $P^m$</p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-06-02 at 4.16.46 PM.png" alt="Screen Shot 2018-06-02 at 4.16.46 PM"></p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-06-02 at 4.16.55 PM.png" alt="Screen Shot 2018-06-02 at 4.16.55 PM"></p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-06-02 at 4.17.21 PM.png" alt="Screen Shot 2018-06-02 at 4.17.21 PM"></p>
</blockquote>
<p><strong>Private Mechanism With Full Privacy</strong></p>
<blockquote>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-06-02 at 4.20.01 PM.png" alt="Screen Shot 2018-06-02 at 4.20.01 PM"></p>
</blockquote>
<h4 id="2014-Sun"><a href="#2014-Sun" class="headerlink" title="[2014-Sun]"></a><a href="https://pdfs.semanticscholar.org/ff20/5884c8e34f8a1d6616809ca532e6ed801393.pdf?_ga=2.49109027.44169730.1528666244-1946321552.1526143877" target="_blank" rel="noopener">[2014-Sun]</a></h4><blockquote>
<p>The problem setting is how to find frequent itemset with privacy. Say we have the item set $I={I_1,I_2,..,I_n}$. Before each user sends out their transaction which is $n$-dimention vector and ithe entry being 1 means this user has this item or else, he does the the randomized selection for each item. That is, keep true answer with probability $p_i$ for item i and  perturb the answer with $1-p$. And p controls the privacy level.</p>
<p>For k-itemset, we want to find out its support, which comes from the estimator based on the perturbed data. Say we want to calculate the support of $2$-itemset. And the item set is $\{A,B,C,D\}$. And the candidate domain is $\{AB,AC,AD,BC,BD,CD\}$. The aim is to get the true count of $AB, \ c(AB)$, which is $11$ and may comes from $\{00,01,10,11\}$, with the probability matrix $P=\matrix{p_{00},p_{01}\\p_{10},p_{11}}$. so based on the observed count of $[A=0,B=0],[A=0,B=1],[A=1,B=0],[A=1,B=1]$ we can get estimator count matrix by $C_{observed}=PC_{estimator}\to C_{estimator}=P^{-1}C_{observed}$. And the support for $AB$ is $C_{estimator}[-1]$.</p>
</blockquote>
<p>Basic RAPPOR</p>
<blockquote>
<p><a href="https://arxiv.org/pdf/1503.01214.pdf" target="_blank" rel="noopener">[Building a RAPPOR with the Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries]</a></p>
<p><img src="/2018/05/28/DP-Application-Random-Response/Screen Shot 2018-06-17 at 11.08.18 AM.png" alt="Screen Shot 2018-06-17 at 11.08.18 AM"></p>
</blockquote>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[2011-Quercia] SpotME if you can: randomized responses for location obfuscation on mobile phones</p>
<p>[1965-Warner] Randomized response: a survey technique for eliminating evasive answer bias</p>
<p>[2016-Wang] Using Randomized Response for Differential Privacy Preserving Data Collection </p>
<p>[2006-Huseyin] Achieving Private Recommendations Using Randomized Response Techniques</p>
<p>[2014-Sun] Personalized Privacy-Preserving Frequent Itemset Mining Using Randomized Response</p>
<p>[]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">47</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
