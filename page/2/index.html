<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Blog of Qing">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Blog of Qing">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/03/Grid-Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/03/Grid-Search/" itemprop="url">Grid Search</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-03T11:47:49-05:00">
                2018-09-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>模型参数(Model Parameters)</p>
<p>模型参数是根据训练集数据而定义的，故它们是利用训练集数据训练得到的，它们往往不能手动设置，常见的模型参数包括：</p>
<ul>
<li>线性模型、非线性模型的系数</li>
<li>神经网络的权重，隐藏层的层数，每一层的神经元个数等</li>
<li>随机森林中决策树的个数</li>
</ul>
<p>模型超参数(Model Hyper-Parameters)</p>
<p>模型超参数往往独立于训练集而被定义，所以它们不能从训练集中学习得到。常见的超参数包括：</p>
<ul>
<li>模型的学习速率</li>
<li>k折交叉验证的k值</li>
</ul>
<p>Grid Search</p>
<p>每一个模型几乎都有许多超参数，所以寻找超参数的一个直观的方法是尝试这些超参数的不能组合，然后比较结果。</p>
<p>Python实现</p>
<p>下面我们以寻找逻辑斯蒂回归模型最佳正则函数和学习速率为例，来感受一个Grid Search。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Create logistic regression object</span></div>
<div class="line">logistic = linear_model.LogisticRegression()</div>
<div class="line"><span class="comment"># Create a list of all of the different penalty values that you want to test and save them to a variable called 'penalty'</span></div>
<div class="line">penalty = [<span class="string">'l1'</span>, <span class="string">'l2'</span>]</div>
<div class="line"><span class="comment"># Create a list of all of the different C values that you want to test and save them to a variable called 'C'</span></div>
<div class="line">C = [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">1</span>, <span class="number">100</span>]</div>
<div class="line"><span class="comment"># Now that you have two lists each holding the different values that you want test, use the dict() function to combine them into a dictionary.</span></div>
<div class="line"><span class="comment"># Save your new dictionary to the variable 'hyperparameters'</span></div>
<div class="line">hyperparameters = dict(C=C, penalty=penalty)</div>
<div class="line"><span class="comment"># Fit your model using gridsearch</span></div>
<div class="line">clf = GridSearchCV(logistic, hyperparameters, cv=<span class="number">5</span>, verbose=<span class="number">0</span>)</div>
<div class="line">best_model = clf.fit(X, Y)</div>
<div class="line"><span class="comment">#Print all the Parameters that gave the best results:</span></div>
<div class="line">print(<span class="string">'Best Parameters'</span>,clf.best_params_)</div>
<div class="line"><span class="comment"># You can also print the best penalty and C value individually from best_model.best_estimator_.get_params()</span></div>
<div class="line">print(<span class="string">'Best Penalty:'</span>, best_model.best_estimator_.get_params()[<span class="string">'penalty'</span>])</div>
<div class="line">print(<span class="string">'Best C:'</span>, best_model.best_estimator_.get_params()[<span class="string">'C'</span>])</div>
</pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/23/Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/23/Tree/" itemprop="url">Tree</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-23T16:55:10-05:00">
                2018-08-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Algorithm/" itemprop="url" rel="index">
                    <span itemprop="name">Algorithm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h5 id="树的定义"><a href="#树的定义" class="headerlink" title="树的定义"></a>树的定义</h5><!--�565-->
<h5 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h5><p>Pre-order ：root， (left)，(right)</p>
<!--�566-->
<p>In-order： (left)，root，(right)</p>
<!--�567-->
<p>Post-order： (left)，(right)，root</p>
<!--�568-->
<h5 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h5><!--�569-->
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/23/Tree/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/21/Algorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/21/Algorithm/" itemprop="url">Algorithm</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-21T15:19:42-05:00">
                2018-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Algorithm/" itemprop="url" rel="index">
                    <span itemprop="name">Algorithm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Algorithm is a finite list of instrictions (to people) to accomplish something useful (that solves some problems); properties are following:</p>
<ul>
<li>clear(unambiguous), doable(terminate)</li>
<li>does what it is supposed to do</li>
<li>does not have any redundancy(several steps together caused redundacy, not caused by a single step)</li>
</ul>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/21/Algorithm/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/20/Variant-GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/20/Variant-GAN/" itemprop="url">Variant GAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-20T10:54:39-05:00">
                2018-08-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>我们之前介绍了GAN模型，在本章中，将介绍一些GAN的变体模型。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/20/Variant-GAN/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/18/Logistic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/18/Logistic-Regression/" itemprop="url">Logistic Regression</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-18T16:44:27-05:00">
                2018-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>用于分类任务的逻辑斯蒂回归。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/18/Logistic-Regression/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/09/Python-Sth/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/09/Python-Sth/" itemprop="url">Python Sth</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-09T10:52:36-05:00">
                2018-08-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>检查目录，并生成一级目录</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">path = <span class="string">'./xx/'</span></div>
<div class="line"><span class="keyword">if</span> os.path.isdir(path) == <span class="keyword">False</span>:</div>
<div class="line">    os.mkdir(path)</div>
</pre></td></tr></table></figure>
<p>多级目录生成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">path = <span class="string">'./xx/yy/zz/'</span></div>
<div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(path):</div>
<div class="line">    os.makedirs(path)</div>
</pre></td></tr></table></figure>
<h2 id="R-amp-W-in-TXT"><a href="#R-amp-W-in-TXT" class="headerlink" title="R &amp; W in TXT"></a>R &amp; W in TXT</h2><p> <a href="https://blog.csdn.net/heyijia0327/article/details/42506063" target="_blank" rel="noopener">ref</a> </p>
<p><code>np.loadtxt()</code>用于从文本加载数据。 文本文件中的每一行必须含有相同的数据。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">loadtxt(fname, dtype=&lt;class 'float'&gt;, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0)</div>
</pre></td></tr></table></figure>
<ul>
<li>fname：文件名</li>
<li>dtype：数据类型，默认float</li>
<li>comments：注释</li>
<li>delimiter：分隔符，默认是空格</li>
<li>skiprows：跳过前几行，0是第一行，必须int</li>
<li><code>usecols</code>：要读取哪些列，0是第一列。例如，usecols = （1,4,5）将提取第2，第5和第6列。默认读取所有列。</li>
<li><code>unpack</code>如果为<code>True</code>，将分列读取。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> open(<span class="string">'odom.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div>
<div class="line">    data = f.readlines()  <span class="comment">#txt中所有字符串读入data</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> data:</div>
<div class="line">        odom = line.split()        <span class="comment">#将单个数据分隔开存好</span></div>
<div class="line">        numbers_float = map(float, odom) <span class="comment">#转化为浮点数</span></div>
</pre></td></tr></table></figure>
<p>TXT追加内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line">my_open = open(file_name, <span class="string">'a'</span>)</div>
<div class="line"><span class="comment">#打开fie_name路径下的my_infor.txt文件,采用追加模式</span></div>
<div class="line"><span class="comment">#若文件不存在,创建，若存在，追加</span></div>
<div class="line">my_open.write(<span class="string">'xx\n'</span>)</div>
<div class="line">my_open.close()</div>
</pre></td></tr></table></figure>
<h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><h3 id="文件移动"><a href="#文件移动" class="headerlink" title="文件移动"></a>文件移动</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> shutil</div>
<div class="line">shutil.move(src,des)</div>
</pre></td></tr></table></figure>
<h2 id="Random"><a href="#Random" class="headerlink" title="Random"></a>Random</h2><h3 id="np-random-rand"><a href="#np-random-rand" class="headerlink" title="np.random.rand()"></a>np.random.rand()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">numpy.random.rand(d0,d1,…,dn)</div>
</pre></td></tr></table></figure>
<ul>
<li>rand函数根据给定维度生成[0,1)之间的数据，包含0，不包含1</li>
<li>dn为每个维度</li>
<li>返回值为指定维度的数组</li>
</ul>
<h3 id="np-random-randn"><a href="#np-random-randn" class="headerlink" title="np.random.randn()"></a>np.random.randn()</h3><ul>
<li>randn函数返回具有标准正态分布的数据。</li>
<li>dn为每个维度</li>
<li>返回值为指定维度的数组</li>
</ul>
<h3 id="np-random-randint"><a href="#np-random-randint" class="headerlink" title="np.random.randint()"></a>np.random.randint()</h3><p><code>numpy.random.randint(low, high, size)</code></p>
<ul>
<li>返回开区间 <strong>[low, high)</strong>范围内的整数值</li>
<li><p>默认high是None,如果只有low，那范围就是[0,low)。如果有high，范围就是[low,high)</p>
</li>
<li><p>size是输出数组的维度（形状），可以是列表，或者元组 </p>
</li>
</ul>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="数字补0"><a href="#数字补0" class="headerlink" title="数字补0"></a>数字补0</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">n = <span class="number">123</span></div>
<div class="line">number = <span class="string">"%05d"</span>%n <span class="comment">### number = 00123</span></div>
</pre></td></tr></table></figure>
<h2 id="Plt"><a href="#Plt" class="headerlink" title="Plt"></a>Plt</h2><p>图片保存去除周边空白<a href="https://www.jianshu.com/p/5f4c71b3024d" target="_blank" rel="noopener">ref</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>)) </div>
<div class="line">p = plt.subplot(<span class="number">111</span>)</div>
<div class="line">plt.savefig(<span class="string">'image_name'</span>, ,bbox_inches=<span class="string">'tight'</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<p>bbox_inches =’tight’ 只能用于保存图片，不能用于显示。</p>
</blockquote>
<h2 id="Time"><a href="#Time" class="headerlink" title="Time"></a>Time</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div>
<div class="line">start_time = time.time()</div>
</pre></td></tr></table></figure>
<h2 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> argparse</div>
<div class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Process some parameters."</span>)</div>
<div class="line">    parser.add_argument(<span class="string">'--trainFeature'</span>, <span class="string">'-tf'</span>, type=int, required=<span class="keyword">True</span>, default=<span class="number">1</span>, help=<span class="string">'train feature'</span>)</div>
<div class="line">    parser.add_argument(<span class="string">'--trainInitial'</span>, <span class="string">'-ti'</span>, type=int, required=<span class="keyword">True</span>, default=<span class="number">1</span>,help=<span class="string">'train initial'</span>)</div>
<div class="line">    parser.add_argument(<span class="string">'--learningRate'</span>, <span class="string">'-lr'</span>, type=float, required=<span class="keyword">True</span>, default=<span class="number">0.00001</span>,help=<span class="string">'learning rate'</span>)</div>
<div class="line">    parser.add_argument(<span class="string">'--criticNum'</span>, <span class="string">'-cn'</span>, type=int, required=<span class="keyword">True</span>, default=<span class="number">5</span>,help=<span class="string">'critic number'</span>)</div>
<div class="line">    parser.add_argument(<span class="string">'--clipRange'</span>, <span class="string">'-cr'</span>, type=float, required=<span class="keyword">True</span>,default=<span class="number">0.01</span>, help=<span class="string">'clip range'</span>)</div>
<div class="line"></div>
<div class="line">    args = parser.parse_args()</div>
<div class="line">    n_critic = args.criticNum</div>
<div class="line">    train_initial = args.trainInitial</div>
<div class="line">    train_feature = args.trainFeature</div>
<div class="line">    lr = args.learningRate</div>
<div class="line">    clip = args.clipRange</div>
<div class="line"></div>
<div class="line">    dgan = StageTwo(n_critic,train_initial,train_feature,lr,clip)</div>
</pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">python xx.py -trainFeature 1 -trainInitial 1 -learningRate 0.001 -criticNum 5 -clipRange 0.01</div>
</pre></td></tr></table></figure>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p><a href="https://towardsdatascience.com/5-quick-and-easy-data-visualizations-in-python-with-code-a2284bae952f" target="_blank" rel="noopener">5 Quick and Easy Data Visualizations in Python with Code</a> </p>
<p><a href="https://mail.google.com/mail/u/0/#inbox/FMfcgxwBVWMvVdMrPPqPgrmqWvZFZxvh" target="_blank" rel="noopener">8 of the best articles on visualizing data</a> </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/08/Adversarial-AutoEncoder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/08/Adversarial-AutoEncoder/" itemprop="url">Adversarial AutoEncoder</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-08T16:27:54-05:00">
                2018-08-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Adversarial-Autoencoder"><a href="#Adversarial-Autoencoder" class="headerlink" title="Adversarial Autoencoder"></a>Adversarial Autoencoder</h1><p><a href="https://duvenaud.github.io/learn-discrete/slides/AdversarialAutoencoders.pdf" target="_blank" rel="noopener">ref1</a> <a href="http://closure11.com/%E5%AF%B9%E6%8A%97%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%9Aadversarial-autoencoders/" target="_blank" rel="noopener">gocha</a> <a href="https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-2-exploring-latent-space-with-adversarial-2d53a6f8a4f9" target="_blank" rel="noopener">good one</a>  </p>
<h2 id="无监督AAE"><a href="#无监督AAE" class="headerlink" title="无监督AAE"></a>无监督AAE</h2><p>autoencoder中的encoder的输出(潜在码)并不能在某一特定空间均匀分布，而且AE 的 G 只能保证将由 x 生成的 z 还原为 x。如果我们随机生成 1 个 z，经过 AE 的 G 后往往不会得到有效的图像。</p>
<p>所以我们希望encoder的输出可以服从某一分布，这个分布可以是正态分布，均匀分布等，这样就会使encoder的输出均匀分布在给定的先验分布，使decoder学习到一个先验分布到输入数据的映射(本例中就是学习到MNIST手写体数据的分布)，那么此时只需从这个先验分布采样出 z，就能通过 G 得到有效的图像。</p>
<p>假设你正在学习一门课程，如果你的老师并没有提供任何资料，你又会如何学习这门课呢？但是考试怎么办呢，难道要自己瞎答吗？这种情况就是类似我们的encoder的输出并不服从某种特定分布，这样decoder就无法学习到一个从任意数字到图片的映射。</p>
<p>但是如果你有了一个课程指导书，你就可以在考试之前复习这本书，这样就知道了可能的考试内容。类似的，如果我们的encoder输出服从一个已知分布，那么encoder就会将潜在码覆盖整个先验分布。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p><img src="/2018/08/08/Adversarial-AutoEncoder/Screen-Shot-2016-10-13-at-11.17.21-AM-690x332.png" alt="Screen-Shot-2016-10-13-at-11.17.21-AM-690x332"></p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/Screen Shot 2018-08-08 at 9.33.36 PM.png" alt="Screen Shot 2018-08-08 at 9.33.36 PM"></p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_nnf4UUq9Uuf2l19iCYaNfg.png" alt="1_nnf4UUq9Uuf2l19iCYaNfg"></p>
<ul>
<li>$x$是输入</li>
<li>$q(z|x)$是encoder基于输入$x$的输出</li>
<li>$z$是潜在码，同时也是一个假输入，从$q(z|x)$中采样得到</li>
<li>$z’$是采样自想要的分布，作为真实输入</li>
<li>$p(x|z)$是基于$z$的decoder输入</li>
<li>$x_$是重构图像</li>
</ul>
<p>我们的主要目的是迫使encoder的输出逼近一个先验分布（比如正态分布，gamma分布等）。我们将使用encoder$(q(z|x))$作为生成器，而判别器辨别它的输入是来自于一个先验分布$p(z)$，亦或是来自于encoder的输出$z$，decoder仍然进行图片重构的工作。</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>AAE的训练分成两个部分：重构阶段和正则化阶段。</p>
<p>训练上述模型，分成两个阶段：一个是对辨别器的训练；另一个是对GAN模型的训练。</p>
<p>对于分辨器，其输入就是真假latent code，输出real概率</p>
<p>对于GAN模型，它需要配合分辨器来完成训练。encoder-decoder产生两个输出：一个是latent code，一个是image，但是我们只需要latent code作为分辨器的输入，从而完成GAN模型的训练。</p>
<h4 id="重构阶段"><a href="#重构阶段" class="headerlink" title="重构阶段"></a>重构阶段</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_DKPl7YOnX-8FJQuHAZop-g.png" alt="1_DKPl7YOnX-8FJQuHAZop-g"></p>
<p>在该阶段，我们需要训练encoder和decoder来最小化重构误差（输入图片与重构图片间的均方误差）。我们将输入传递给encoder，encoder输出一个潜在码；随后，我们将该潜在码送入decoder从而得到一张重构图像。</p>
<h4 id="正则化阶段"><a href="#正则化阶段" class="headerlink" title="正则化阶段"></a>正则化阶段</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1__pIXKcCCqJRNmIWTRymJzA.png" alt="1__pIXKcCCqJRNmIWTRymJzA"></p>
<p>在该阶段，我们训练生成器和辨别器，我们将encod的输出$z$和随机采样$z’$（来自于想要的分布）作为输入来训练辨别器，这样辨别器就会返回1如果输入是$z’$，而返回0如果输入是$z$。接下来，为了迫使encoder的输出$z$逼近我们想要的分布，我们将encoder的输出作为辨别器的输入，连接encoder和辨别器。</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_DoJESN2LvxpxNVYADRJXWw.png" alt="1_DoJESN2LvxpxNVYADRJXWw"></p>
<p>我们固定辨别器的权重参数，固定输入的目标标签为1，然后我们输入一些图像到encoder，并计算辨别器的输出与目标标签间的差异（使用交叉熵损失函数），这个阶段我们只更新encoder的权重参数，这样促使encoder去学习我们想要的分布，使输出服从这个分布。</p>
<h3 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h3><h4 id="Encoder构造"><a href="#Encoder构造" class="headerlink" title="Encoder构造"></a>Encoder构造</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_Hud7t2vLY2JIP3SXn4WTDA.png" alt="1_Hud7t2vLY2JIP3SXn4WTDA"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_encoder</span><span class="params">(self)</span>:</span></div>
<div class="line">    input_img = Input(self.input)</div>
<div class="line">    h = Flatten()(input_img)</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">    mean = Dense(<span class="number">2</span>)(h)</div>
<div class="line">    logvar = Dense(<span class="number">2</span>)(h)</div>
<div class="line">    z = Lambda(self.sampling, output_shape=(self.latent_dim,))([mean, logvar])</div>
<div class="line">    encoder = Model(input_img,z)</div>
<div class="line">    encoder.summary()</div>
<div class="line">    <span class="keyword">return</span> encoder</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sampling</span><span class="params">(self, args)</span>:</span></div>
<div class="line">    z_mean, z_log_sigma = args</div>
<div class="line">    epsilon = K.random_normal(shape=(K.shape(z_mean)[<span class="number">0</span>], self.latent_dim), mean=<span class="number">0.</span>, stddev=<span class="number">1.0</span>)</div>
<div class="line">    <span class="keyword">return</span> z_mean + K.exp(z_log_sigma / <span class="number">2</span>) * epsilon</div>
</pre></td></tr></table></figure>

</div></div>
<h4 id="Decoder构造"><a href="#Decoder构造" class="headerlink" title="Decoder构造"></a>Decoder构造</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_0t7JrvUqyzg7AdQGDjZkRw.png" alt="1_0t7JrvUqyzg7AdQGDjZkRw"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_decoder</span><span class="params">(self)</span>:</span> <span class="comment"># ok</span></div>
<div class="line">    input_code = Input((self.latent_dim,))</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(input_code)</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">    h = Dense(<span class="number">784</span>,activation=<span class="string">'sigmoid'</span>)(h)</div>
<div class="line">    recon_img = Reshape(self.input)(h)</div>
<div class="line">    decoder = Model(input_code,recon_img)</div>
<div class="line">    decoder.summary()</div>
<div class="line">    <span class="keyword">return</span> decoder</div>
</pre></td></tr></table></figure>

</div></div>
<h4 id="Discriminator构造"><a href="#Discriminator构造" class="headerlink" title="Discriminator构造"></a>Discriminator构造</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_Df3_l66beZqsqRe5i6lZRw.png" alt="1_Df3_l66beZqsqRe5i6lZRw"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_discriminator</span><span class="params">(self)</span>:</span> <span class="comment"># ok</span></div>
<div class="line">    input_code = Input((self.latent_dim,))</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(input_code)</div>
<div class="line">    h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">    valid = Dense(<span class="number">1</span>)(h)</div>
<div class="line">    discriminator = Model(input_code,valid)</div>
<div class="line">    discriminator.summary()</div>
<div class="line">    <span class="keyword">return</span> discriminator</div>
</pre></td></tr></table></figure>

</div></div>
<h4 id="GAN的构造与编译"><a href="#GAN的构造与编译" class="headerlink" title="GAN的构造与编译"></a>GAN的构造与编译</h4><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
</pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">aae</span><span class="params">()</span>:</span></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div>
<div class="line">        self.input = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</div>
<div class="line">        self.latent_dim = <span class="number">2</span></div>
<div class="line">        optimizer = Adam(lr=<span class="number">0.0002</span>,beta_1=<span class="number">0.5</span>)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># Build and compile the discriminator</span></div>
<div class="line">        self.discriminator = self.make_discriminator()</div>
<div class="line">        self.discriminator.compile(optimizer=optimizer,</div>
<div class="line">                                   loss=[<span class="string">'binary_crossentropy'</span>],</div>
<div class="line">                                   metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"></div>
<div class="line">        <span class="comment"># Build the encoder / decoder</span></div>
<div class="line">        self.encoder = self.make_encoder()</div>
<div class="line">        self.decoder = self.make_decoder()</div>
<div class="line">        image = Input(self.input)</div>
<div class="line">        latent_code = self.encoder(image)</div>
<div class="line">        recon_img = self.decoder(latent_code)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># for the adversarial_autoencoder model, we only train the generator</span></div>
<div class="line">        self.discriminator.trainable = <span class="keyword">False</span></div>
<div class="line">        valid = self.discriminator(latent_code)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># The adversarial_autoencoder model  (stacked generator and discriminator)</span></div>
<div class="line"></div>
<div class="line">        self.adversarial_autoencoder = Model(image,[recon_img,valid])</div>
<div class="line">        self.adversarial_autoencoder.compile(loss=[<span class="string">'mae'</span>,<span class="string">'binary_crossentropy'</span>],</div>
<div class="line">                                             loss_weights=[<span class="number">0.999</span>,<span class="number">0.001</span>],</div>
<div class="line">                                             optimizer=optimizer)</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,epoches=<span class="number">1000</span>,batch_size=<span class="number">100</span>)</span>:</span></div>
<div class="line"></div>
<div class="line">    <span class="comment"># Load the dataset</span></div>
<div class="line">    (X_train, _), (_, _) = mnist.load_data()</div>
<div class="line">    <span class="comment"># Configure input</span></div>
<div class="line">    X_train = (X_train.astype(np.float32) - <span class="number">127.5</span>) / <span class="number">127.5</span> <span class="comment"># pixel between [-1,1]</span></div>
<div class="line">    X_train = np.expand_dims(X_train, axis=<span class="number">3</span>) <span class="comment"># change shape from (60000,28,28) to (60000,28,28,1)</span></div>
<div class="line">    <span class="comment"># Adversarial ground truths</span></div>
<div class="line">    valid = np.ones((batch_size, <span class="number">1</span>))</div>
<div class="line">    fake = np.zeros((batch_size, <span class="number">1</span>))</div>
<div class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,epoches+<span class="number">1</span>):</div>
<div class="line">        <span class="comment"># Select a random half batch of images</span></div>
<div class="line">        idx = np.random.randint(<span class="number">0</span>, X_train.shape[<span class="number">0</span>], batch_size)</div>
<div class="line">        imgs = X_train[idx]</div>
<div class="line"></div>
<div class="line">        latent_fake = self.encoder.predict(imgs)</div>
<div class="line">        latent_real = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">2</span>))</div>
<div class="line"></div>
<div class="line">        <span class="comment"># train the discriminator</span></div>
<div class="line">        d_loss_real = self.discriminator.train_on_batch(latent_real, valid)</div>
<div class="line">        d_loss_fake = self.discriminator.train_on_batch(latent_fake, fake)</div>
<div class="line">        d_loss = <span class="number">0.5</span> * np.add(d_loss_real, d_loss_fake)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># train the generator</span></div>
<div class="line">        g_loss = self.adversarial_autoencoder.train_on_batch(imgs, [imgs, valid])</div>
<div class="line">        print(<span class="string">"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]"</span> % (</div>
<div class="line">        epoch, d_loss[<span class="number">0</span>], <span class="number">100</span> * d_loss[<span class="number">1</span>], g_loss[<span class="number">0</span>], g_loss[<span class="number">1</span>]))</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div>
<div class="line">    model = aae()</div>
<div class="line">    model.train()</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="监督AAE"><a href="#监督AAE" class="headerlink" title="监督AAE"></a>监督AAE</h2><p><a href="https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-3-disentanglement-of-style-and-content-89262973a4d7" target="_blank" rel="noopener">Disentanglement of style and content</a> </p>
<p>对于一个写作主题，每一个人写出来的文章都有不同的内容（content）和字体（style）。对于MNIST字体，可以发现它的所有图像都有一样的style，所以我们想要从这个数据集中学习MNIST字体的style。为了更明确content和style的区别，我们有如下图：</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/Screen Shot 2018-08-28 at 11.39.06 AM.png" alt="Screen Shot 2018-08-28 at 11.39.06 AM"></p>
<p>每个文本都有相同的content “Autoencoder”，但是它们的字体是不一样的，现在我们想要从图片中去区分style（Myriad Pro, MV Boil,…）和content，特征分离是表征学习(<a href="http://www.cl.uni-heidelberg.de/courses/ws14/deepl/BengioETAL12.pdf" target="_blank" rel="noopener">representation learning</a>)的一个重要内容。</p>
<p>Autoencoder和Adversarial Autoencoder都是无监督学习，因为在训练过程中我们并没有世人任何label信息，但是如果利用图片的label信息则会帮助AAE去提取style信息而不受图片content的影响，这样我们的AAE就变成了一个监督模型。</p>
<h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_vGU0REkvre1DI7sFLU97_g.png" alt="1_vGU0REkvre1DI7sFLU97_g"></p>
<p>除了利用latent code作为decoder的输入，我们同时把标签<code>y</code>信息作为另一个输入，decoder利用这两个输入来生成图片。encoder学习图片的style，decoder利用该学习到的style和额外的内容信息<code>y</code>来重构输入图片</p>
<p>相比较于无监督AAE，唯一的区别就是decoder的输入：</p>
<ul>
<li>来自encoder的latent code</li>
<li>图像标签的独热表示</li>
</ul>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><h4 id="重构阶段-1"><a href="#重构阶段-1" class="headerlink" title="重构阶段"></a>重构阶段</h4><p>我们将输入图像送入encoder得到输出latent code<code>z</code>，然后将<code>z</code>和图像标签<code>y</code>串接起来成为一个更大的输入送入decoder。我们训练AE使最小化图片重构损失</p>
<h4 id="正则化阶段-1"><a href="#正则化阶段-1" class="headerlink" title="正则化阶段"></a>正则化阶段</h4><p>与无监督    AAE一样。</p>
<h3 id="Python实现-1"><a href="#Python实现-1" class="headerlink" title="Python实现"></a>Python实现</h3><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_lzIl05QPdy-aEtVvh-y1LQ.png" alt="1_lzIl05QPdy-aEtVvh-y1LQ"></p>
<p>MNIST的图像总共有10类，则<code>y</code>的独热向量长度就是10，laten code的长度是2，则decoder的输入长度是（10+2）</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
<div class="line">78</div>
<div class="line">79</div>
<div class="line">80</div>
<div class="line">81</div>
<div class="line">82</div>
<div class="line">83</div>
<div class="line">84</div>
<div class="line">85</div>
<div class="line">86</div>
<div class="line">87</div>
<div class="line">88</div>
<div class="line">89</div>
<div class="line">90</div>
<div class="line">91</div>
<div class="line">92</div>
<div class="line">93</div>
<div class="line">94</div>
<div class="line">95</div>
<div class="line">96</div>
<div class="line">97</div>
<div class="line">98</div>
<div class="line">99</div>
<div class="line">100</div>
<div class="line">101</div>
<div class="line">102</div>
<div class="line">103</div>
<div class="line">104</div>
<div class="line">105</div>
<div class="line">106</div>
<div class="line">107</div>
<div class="line">108</div>
<div class="line">109</div>
<div class="line">110</div>
<div class="line">111</div>
<div class="line">112</div>
<div class="line">113</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, Reshape, Flatten, Dropout, multiply</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> BatchNormalization, Embedding, Lambda,Concatenate</div>
<div class="line"><span class="keyword">from</span> keras.layers.advanced_activations <span class="keyword">import</span> LeakyReLU</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Model</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"><span class="keyword">import</span> keras</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> os</div>
<div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"></div>
<div class="line"><span class="class"><span class="keyword">class</span> <span class="title">aae</span><span class="params">()</span>:</span></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div>
<div class="line">        self.input = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</div>
<div class="line">        self.latent_dim = <span class="number">15</span></div>
<div class="line">        self.classes = <span class="number">10</span></div>
<div class="line">        optimizer = Adam(lr=<span class="number">0.0002</span>,beta_1=<span class="number">0.5</span>)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># Build and compile the discriminator</span></div>
<div class="line">        self.discriminator = self.make_discriminator()</div>
<div class="line">        self.discriminator.compile(optimizer=optimizer,</div>
<div class="line">                                   loss=[<span class="string">'binary_crossentropy'</span>],</div>
<div class="line">                                   metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"></div>
<div class="line">        <span class="comment"># Build the encoder / decoder</span></div>
<div class="line">        self.encoder = self.make_encoder()</div>
<div class="line">        self.decoder = self.make_decoder()</div>
<div class="line">        image = Input(self.input)</div>
<div class="line">        label = Input((self.classes,))</div>
<div class="line">        latent_code = self.encoder(image)</div>
<div class="line">        recon_img = self.decoder([label,latent_code])</div>
<div class="line"></div>
<div class="line">        <span class="comment"># for the adversarial_autoencoder model, we only train the generator</span></div>
<div class="line">        self.discriminator.trainable = <span class="keyword">False</span></div>
<div class="line">        valid = self.discriminator(latent_code)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># The adversarial_autoencoder model  (stacked generator and discriminator)</span></div>
<div class="line"></div>
<div class="line">        self.adversarial_autoencoder = Model([image,label],[recon_img,valid])</div>
<div class="line">        self.adversarial_autoencoder.compile(loss=[<span class="string">'mse'</span>,<span class="string">'binary_crossentropy'</span>],</div>
<div class="line">                                             loss_weights=[<span class="number">0.999</span>,<span class="number">0.001</span>],</div>
<div class="line">                                             optimizer=optimizer)</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sampling</span><span class="params">(self, args)</span>:</span></div>
<div class="line">        z_mean, z_log_sigma = args</div>
<div class="line">        epsilon = K.random_normal(shape=(K.shape(z_mean)[<span class="number">0</span>], self.latent_dim), mean=<span class="number">0.</span>, stddev=<span class="number">1.0</span>)</div>
<div class="line">        <span class="keyword">return</span> z_mean + K.exp(z_log_sigma / <span class="number">2</span>) * epsilon</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_encoder</span><span class="params">(self)</span>:</span></div>
<div class="line">        input_img = Input(self.input)</div>
<div class="line">        h = Flatten()(input_img)</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">        mean = Dense(self.latent_dim)(h)</div>
<div class="line">        logvar = Dense(self.latent_dim)(h)</div>
<div class="line">        z = Lambda(self.sampling, output_shape=(self.latent_dim,))([mean, logvar])</div>
<div class="line">        encoder = Model(input_img,z)</div>
<div class="line">        encoder.summary()</div>
<div class="line">        <span class="keyword">return</span> encoder</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_decoder</span><span class="params">(self)</span>:</span> <span class="comment"># ok</span></div>
<div class="line">        input_code = Input((self.latent_dim,))</div>
<div class="line">        input_label = Input((self.classes,))</div>
<div class="line">        combine_input = Concatenate(axis=<span class="number">-1</span>)([input_label, input_code])</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(combine_input)</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">        h = Dense(<span class="number">784</span>,activation=<span class="string">'sigmoid'</span>)(h)</div>
<div class="line">        recon_img = Reshape(self.input)(h)</div>
<div class="line">        decoder = Model([input_label,input_code],recon_img)</div>
<div class="line">        decoder.summary()</div>
<div class="line">        <span class="keyword">return</span> decoder</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_discriminator</span><span class="params">(self)</span>:</span> <span class="comment"># ok</span></div>
<div class="line">        input_code = Input((self.latent_dim,))</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(input_code)</div>
<div class="line">        h = Dense(<span class="number">1000</span>,activation=<span class="string">'relu'</span>)(h)</div>
<div class="line">        valid = Dense(<span class="number">1</span>)(h)</div>
<div class="line">        discriminator = Model(input_code,valid)</div>
<div class="line">        discriminator.summary()</div>
<div class="line">        <span class="keyword">return</span> discriminator</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,epoches=<span class="number">1000</span>,batch_size=<span class="number">100</span>)</span>:</span></div>
<div class="line"></div>
<div class="line">        <span class="comment"># Load the dataset</span></div>
<div class="line">        (X_train, y_train), (_, _) = mnist.load_data()</div>
<div class="line">        <span class="comment"># Configure input</span></div>
<div class="line">        X_train = (X_train.astype(np.float32) - <span class="number">127.5</span>) / <span class="number">127.5</span> <span class="comment"># pixel between [-1,1]</span></div>
<div class="line">        X_train = np.expand_dims(X_train, axis=<span class="number">3</span>) <span class="comment"># change shape from (60000,28,28) to (60000,28,28,1)</span></div>
<div class="line">        y_train = y_train.reshape(<span class="number">-1</span>, <span class="number">1</span>)</div>
<div class="line">        <span class="comment"># Adversarial ground truths</span></div>
<div class="line">        valid = np.ones((batch_size, <span class="number">1</span>))</div>
<div class="line">        fake = np.zeros((batch_size, <span class="number">1</span>))</div>
<div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,epoches+<span class="number">1</span>):</div>
<div class="line">            <span class="comment"># Select a random half batch of images</span></div>
<div class="line">            idx = np.random.randint(<span class="number">0</span>, X_train.shape[<span class="number">0</span>], batch_size)</div>
<div class="line">            imgs = X_train[idx]</div>
<div class="line">            labels = y_train[idx]</div>
<div class="line">            labels = keras.utils.to_categorical(labels,self.classes)</div>
<div class="line"></div>
<div class="line">            latent_fake = self.encoder.predict(imgs)</div>
<div class="line">            latent_real = np.random.normal(<span class="number">0</span>, <span class="number">5.</span>, (batch_size, self.latent_dim))</div>
<div class="line"></div>
<div class="line">            <span class="comment"># train the discriminator</span></div>
<div class="line">            d_loss_real = self.discriminator.train_on_batch(latent_real, valid)</div>
<div class="line">            d_loss_fake = self.discriminator.train_on_batch(latent_fake, fake)</div>
<div class="line">            d_loss = <span class="number">0.5</span> * np.add(d_loss_real, d_loss_fake)</div>
<div class="line"></div>
<div class="line">            <span class="comment"># train the generator</span></div>
<div class="line">            g_loss = self.adversarial_autoencoder.train_on_batch([imgs,labels], [imgs, valid])</div>
<div class="line">            print(<span class="string">"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]"</span> % (</div>
<div class="line">            epoch, d_loss[<span class="number">0</span>], <span class="number">100</span> * d_loss[<span class="number">1</span>], g_loss[<span class="number">0</span>], g_loss[<span class="number">1</span>]))</div>
<div class="line"></div>
<div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div>
<div class="line">    model = aae()</div>
<div class="line">    model.train()</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="GAN分类器"><a href="#GAN分类器" class="headerlink" title="GAN分类器"></a>GAN分类器</h2><p><a href="https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-4-classify-mnist-using-1000-labels-2ca08071f95" target="_blank" rel="noopener">ref</a> </p>
<p>本节我们将介绍如何利用encoder对MNIST手写体进行分类，并与传统的神经网络分类器(NN)比较，为保证实验公平性，encoder和NN使用相同的结构。</p>
<p>我们首先介绍传统的NN分类器，如下图所示，</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_OPtU8py5KBpbVUZKylGDPA.png" alt="1_OPtU8py5KBpbVUZKylGDPA"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
<p>那么我们如何将encoder改造成为一个分类器呢？实际上，encoder分类器不仅能够提升分类准确率，还可以减少数据维度，从图片中分离内容和风格，我们的模型如下：</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_8RuZ8kguLuosOGoDpiSgUQ.png" alt="1_8RuZ8kguLuosOGoDpiSgUQ"></p>
<p>可以看到，我们增加了额外的discriminator（$D_{cat}$），该分类器以对抗的方式与encoder一起训练，从而迫使encoder产生10维的独热分类向量</p>
<p>在AAE的基础上对encoder作了修改，此时encoder有两个输出：latent code（z）和classification（y），由于有10个类，则y为10维向量，而z的维度由用户决定。</p>
<h4 id="图片重构阶段"><a href="#图片重构阶段" class="headerlink" title="图片重构阶段"></a>图片重构阶段</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_onLoFTa8qcFMdgm9ILKDaw.png" alt="1_onLoFTa8qcFMdgm9ILKDaw"></p>
<p>该阶段我们欲使生成的图片逼近我们的真实图片，所以我们使用MSE（mean squared error）来衡量输入图片与输出图片间的差异。</p>
<h4 id="正则化阶段-2"><a href="#正则化阶段-2" class="headerlink" title="正则化阶段"></a>正则化阶段</h4><p>该阶段由两个部分组成：$D_{cat}$和$D_{gauss}$的训练</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_HKvMbwaXmDAg12GjgOC39Q.png" alt="1_HKvMbwaXmDAg12GjgOC39Q"></p>
<p>我们首先训练discriminator <strong>D_cat</strong>来辨别真实的分类标签$y^{‘}$和encoder生成的分类标签$y$。为此，我们将图片作为encoder的输入取产生$y$和$z$，然后将生成的$y$和真实的$y^{‘}$用于discriminator的训练。最后，我们固定分辨器的参数，并设置目标为1，训练encoder来欺骗分辨器。</p>
<p><img src="/2018/08/08/Adversarial-AutoEncoder/1_qMGBvI2q14lNKGMrx_gMnw.png" alt="1_qMGBvI2q14lNKGMrx_gMnw"></p>
<p>同样的，为了生成具有高斯分布的latent code（z），我们还需要训练分辨器$D_{gauss}$。</p>
<h4 id="半监督分类器阶段"><a href="#半监督分类器阶段" class="headerlink" title="半监督分类器阶段"></a>半监督分类器阶段</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_ZS7wa7H8tHUDWkuqGZJT2Q.png" alt="1_ZS7wa7H8tHUDWkuqGZJT2Q"></p>
<p>最终我们训练encoder来对手写体数字进行分类，目的是最小化生成的分类标签与真实的标签的交叉熵。</p>
<h3 id="Python实现-2"><a href="#Python实现-2" class="headerlink" title="Python实现"></a>Python实现</h3><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_qufKKgKUPUGvYKWsmqiv5w.png" alt="1_qufKKgKUPUGvYKWsmqiv5w"></p>
<p>在原始encoder的基础上，只需要需改encoder的输出维度，增加对分类标签的输出</p>
<h4 id="Decoder-1"><a href="#Decoder-1" class="headerlink" title="Decoder"></a>Decoder</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_nRF013A75pCdlgOT48w0MA.png" alt="1_nRF013A75pCdlgOT48w0MA"></p>
<h4 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h4><p><img src="/2018/08/08/Adversarial-AutoEncoder/1_jzDB_IJhVL74Zb0NU03Uew.png" alt="1_jzDB_IJhVL74Zb0NU03Uew"></p>
<p>我们需要两个分辨器，它们除了输入维度不同，其他是一样的</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
<h2 id="CVAE-GAN"><a href="#CVAE-GAN" class="headerlink" title="CVAE-GAN"></a>CVAE-GAN</h2><p><a href="https://www.jiqizhixin.com/articles/2018-06-12-5" target="_blank" rel="noopener">REF1</a> </p>
<p>《 CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training》</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/Linear-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/Linear-Regression/" itemprop="url">Linear Regression</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T10:47:44-05:00">
                2018-08-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>线性回归模型，顾名思义就是线性模型求解回归问题。</p>
<h3 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h3><p>【<strong>定义</strong>】给定具有$d$个属性的数据样本$x=\{x_1,x_2,…,x_d\}$，$x_i$是$x$在第$i$个属性上的取值，线性模型通过对属性的线性组合来进行预测的函数：</p>
<script type="math/tex; mode=display">
f(x)=w_1x_1+w_2x_2+...+w_dx_d+b</script><p>向量形式表示为：</p>
<script type="math/tex; mode=display">
f(x)=w^Tx+b</script><p>其中$w=(w_1;w_2;…;w_d)$，只要确定了$w$和$b$，模型就得以确定。</p>
<blockquote>
<p>向量都表示成竖直的一条直线。</p>
</blockquote>
<h3 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h3><p>回归属于监督学习的范畴，用于预测输入变量与输出变量的关系。其本质就是数据拟合，选择一条函数曲线使其很好地拟合已知的数据，同时能够预测未知的数据。</p>
<p>按照输入变量的属性个数，分为一元回归和多元回归；按照输入变量和输出变量之间的映射关系，分为线性回归和非线性回归。</p>
<h3 id="线性回归-1"><a href="#线性回归-1" class="headerlink" title="线性回归"></a>线性回归</h3><p>线性模型描述的是属性间的组合关系，而回归问题求解的是输入与输出的关系。</p>
<p>即使用一个线性函数去建模输入变量属性间的线性关系，从而发现输入变量与输出变量的关系。给定数据集$D=\{(x_1,y_1),(x_2,y_2),…,(x_m,y_m)\}$，其中$x_i=(x_i1;x_i2;…;x_id)$。</p>
<p><strong>问题描述</strong>：线性回归试图学习一个线性模型$f(x_i)=w^Tx_i+b$，使$f(x_i)\approx y_i$。</p>
<blockquote>
<p>又称为多元线性回归，或者多变量线性回归。</p>
</blockquote>
<h2 id="算法求解"><a href="#算法求解" class="headerlink" title="算法求解"></a>算法求解</h2><h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>只要确定了权重$w$和偏差$b$的值，那么我们就可以得到模型了，而我们想让预测值$f(x_i)$无限接近真实值$y_i$，所以使用均方误差作为性能度量，即我们试图让均方差最小：</p>
<script type="math/tex; mode=display">
Loss(w^*,b^*)=\sum_{i=1}^{m}(f(x_i)-y_i)^2</script><p>均方误差对应了常用的欧几里得距离，基于均方误差最小化进行模型求解的方法称为“最小二乘法”，实际上，最小二乘法就是试图找到一条直线，使样本到直线的欧氏距离之和最小。</p>
<blockquote>
<ul>
<li>关于为什么使用均方误差作为损失度量，一个是因为其本质是最大似然法，<a href="https://blog.csdn.net/saltriver/article/details/57544704" target="_blank" rel="noopener">ref</a> </li>
<li>常用损失函数对比<a href="https://www.jiqizhixin.com/articles/2018-06-21-3" target="_blank" rel="noopener">ref2</a> </li>
</ul>
</blockquote>
<h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><h4 id="Loss函数求导取极值"><a href="#Loss函数求导取极值" class="headerlink" title="Loss函数求导取极值"></a>Loss函数求导取极值</h4><p>我们可以对损失函数$Loss$求导，并令导数为零来求得最优参数：</p>
<script type="math/tex; mode=display">
\begin{cases} 
w=\frac{\sum_{i=1}^{n}y_i(x_i-\bar{x})}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}(\sum_{i=1}^{n}x_i)^2}\\
b=\frac{1}{m}\sum_{i=1}^{n}(y_i-wx_i)
    \end{cases}</script><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<p><strong>公式推导</strong></p>
<ol>
<li><p>偏导</p>
<script type="math/tex; mode=display">
\begin{cases} 
\frac{\partial{}E}{\partial{w}}=2[w\sum_{i=1}^{n}x_{i}^{2}-\sum_{i=1}^{n}(y_i-b)x_i]\\
\frac{\partial{}E}{\partial{b}}=2[mb-\sum^{n}_{i=1}(y_i-wx_i)]
    \end{cases}</script></li>
<li><p>求解b，$\frac{\partial{}E}{\partial{b}}=0$</p>
<script type="math/tex; mode=display">
\begin{align*}
mb&=\sum^{n}_{i=1}(y_i-wx_i)\\
&=(y_1-wx_1)+(y_2-wx_2)+...+(y_n-wx_n)=(y_1+y_2+...+y_n)-w(x_1+x_2+...+x_n)\\
&=\sum{y_i}-w\sum{x_i}
\end{align*}</script><p>则$b=\frac{1}{n}\sum_{i=1}^{n}(y_i-wx_i)=\bar{y}-w\bar{x}$</p>
</li>
<li><p>求解w，$\frac{\partial{}E}{\partial{w}}=0$</p>
<script type="math/tex; mode=display">
\begin{align*}
w\sum_{i=1}^{n}x_{i}^{2}&=\sum_{i=1}^{n}(y_i-\bar{y}+w\bar{x})x_i\\
&=(y_1-\bar{y}+w\bar{x})x_1+(y_2-\bar{y}+w\bar{x})x_2+...+(x_n-\bar{y}+w\bar{x})x_n\\
&=(y_1x_1+y_2x_2+...+y_nx_n)-\bar{y}(x_1+x_2+...+x_n)+w\bar{x}(x_1+x_2+...+x_n)\\
&=\sum_{i=1}^{n}x_iy_i-\bar{y}\sum_{i=1}^{n}x_i+w\bar{x}\sum_{i=1}^{n}x_i\\
&=\sum_{i=1}^{n}x_iy_i-n\bar{y}\bar{x}+w\bar{x}n\bar{x}
\end{align*}</script><p>则$w(\sum_{i=1}^{n}x_{i}^{2}-n\bar{x}^2)=\sum_{i=1}^{n}x_iy_i-n\bar{y}\bar{x}$，故</p>
<script type="math/tex; mode=display">
w=\frac{\sum_{i=1}^{n}x_iy_i-n\bar{y}\bar{x}}{\sum_{i=1}^{n}x_{i}^{2}-n\bar{x}^2}</script></li>
</ol>

</div></div>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>损失函数是：</p>
<script type="math/tex; mode=display">
\begin{align*}
Loss(w,b)&=\sum_{i=1}^{n}(f(x_i)-y_i)^2\\
&=\sum_{i=1}^{n}(wx_i+b-y_i)^2
\end{align*}</script><p>参数更新：</p>
<script type="math/tex; mode=display">
\begin{cases} 
w=w-\alpha(f(x)-y){x}\\
b=b-\alpha(f(x)-y)
    \end{cases}</script><blockquote>
<script type="math/tex; mode=display">
\begin{align*}
\frac{\partial{E}}{\partial{w}}&=\frac{\partial{}}{\partial{w}}{\frac{1}{2}(f(x)-y)^2}\\
&=(f(x)-y)\frac{\partial}{\partial{w}}(wx+b-y)\\
&=(f(x)-y)x
\end{align*}</script></blockquote>
<p>即：</p>
<script type="math/tex; mode=display">
w_i=w_i-\alpha\frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)\cdot x_i</script><p>此时，$b=w_0$，$x_0=1$。</p>
<h4 id="正则化的损失函数"><a href="#正则化的损失函数" class="headerlink" title="正则化的损失函数"></a>正则化的损失函数</h4><p>此时目标函数为：</p>
<script type="math/tex; mode=display">
\begin{align*}
E(w,b)&=\sum_{i=1}^{n}(wx_i+b-y_i)^2+\lambda\sum_{i=1}^{n}w_{i}^{2}
\end{align*}</script><blockquote>
<p>$w_0$不需要正则化</p>
</blockquote>
<p>此时梯度下降法为：</p>
<script type="math/tex; mode=display">
w_0=w_0-\alpha\frac{1}{n}\sum_{i=1}^{n}(h_w(x^{(i)})-y^{(i)})x_0^{(i)}\\
w_j=w_j-\alpha[\frac{1}{n}\sum_{i=1}^{n}(h_w(x^{(i)})-y^{(i)})x_j^{(i)}-\frac{\lambda}{n}w_j]</script><h1 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h1><p><strong>Feature Scaling</strong></p>
<p>It involves <strong>dividing the input values by the range</strong> (i.e. the maximum value minus the minimum value) of the input variable, resulting in <strong>a new range of just 1</strong>.</p>
<p><strong>Mean normalization</strong> </p>
<p>This involves <strong>subtracting the average value</strong> for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. </p>
<p>By combining the two techniques and adjust the input values as shown in the following formula:</p>
<script type="math/tex; mode=display">
x_i=\frac{x_i-\mu_i}{s_i}</script><p>where $\mu_i$ is the average of all the values for feature $(i)$ and $s_i$ is the range of values (max - min), or $s_i$ is the standard deviation.</p>
<h1 id="Convergence-Figure"><a href="#Convergence-Figure" class="headerlink" title="Convergence Figure"></a>Convergence Figure</h1><p>In order to make sure that our algorithm runs correctly, we need to debug gradient descent. Make a plot with <em>number of iterations</em> on the x-axis. Now plot the cost function, $J(\theta)$ over the number of iterations of gradient descent. If $J(\theta)$ ever increases, then you probably need to decrease learning rate $\alpha$.</p>
<p><strong>Summary</strong></p>
<ul>
<li><p>If $\alpha$ is too small, it could result in slow convergence.</p>
</li>
<li><p>If $\alpha$ is too large, it may not decrease on every iteration and thus may not converge, like the following pic:</p>
</li>
</ul>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-06 at 12.58.12 PM.png" alt="Screen Shot 2018-08-06 at 12.58.12 PM"></p>
<p><strong>Example</strong></p>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-06 at 12.54.04 PM.png" alt="Screen Shot 2018-08-06 at 12.54.04 PM"></p>
<blockquote>
<p>A is $\alpha=0.1$, B is $\alpha=0.01$, A is $\alpha=1$.</p>
<p>In graph C, the cost function is increasing, so the learning rate is set too high. Both graphs A and B converge to an optimum of the cost function, but graph B does so very slowly, so its learning rate is set too low. Graph A lies between the two.</p>
</blockquote>
<h1 id="Polynomial-Regression"><a href="#Polynomial-Regression" class="headerlink" title="Polynomial Regression"></a>Polynomial Regression</h1><p>Our hypothesis function need not be linear (a straight line) if that does not fit the data well.</p>
<p> We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</p>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-07 at 12.18.01 AM.png" alt="Screen Shot 2018-08-07 at 12.18.01 AM"></p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><h2 id="线性回归预测一维数据"><a href="#线性回归预测一维数据" class="headerlink" title="线性回归预测一维数据"></a>线性回归预测一维数据</h2><p>来自Andrew Ng第二周的课程练习，给出城市人口及该市的商店利润，预测如何进行店铺扩展，即选择哪座城市开分店？给定的数据只有一个人口特征及利润目标值。</p>
<p>第一步就是进行<strong>数据的可视化</strong>。</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_data</span><span class="params">()</span>:</span></div>
<div class="line">    data = np.loadtxt(<span class="string">'./dataset/ex1data1.txt'</span>, delimiter=<span class="string">','</span>)</div>
<div class="line">    x = data[:, <span class="number">0</span>]</div>
<div class="line">    y = data[:, <span class="number">1</span>]</div>
<div class="line">    plt.scatter(x, y, marker=<span class="string">'x'</span>)</div>
<div class="line">    plt.xlabel(<span class="string">"Population of City in 10,000s"</span>)</div>
<div class="line">    plt.ylabel(<span class="string">"Profit in $10,000s"</span>)</div>
<div class="line">    plt.show()</div>
</pre></td></tr></table></figure>
<p><img src="/2018/08/06/Linear-Regression/image-20180815174124083.png" alt="image-20180815174124083"></p>

</div></div>
<p>第二步：数据处理及参数初始化</p>
<p>我们为数据增加一列全一</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line">length = x.shape[<span class="number">0</span>]</div>
<div class="line">z = np.ones(length)</div>
<div class="line">x = np.array(list(zip(z,x)))  <span class="comment"># add a column of ones to x</span></div>
<div class="line">theta = np.zeros([x.shape[<span class="number">1</span>],<span class="number">1</span>]) <span class="comment"># initialize fitting parameters</span></div>
<div class="line">alpha = <span class="number">0.01</span></div>
<div class="line">iters = <span class="number">1500</span></div>
</pre></td></tr></table></figure>

</div></div>
<p>第三步：损失函数</p>
<p>我们使用公式</p>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-15 at 6.19.39 PM.png" alt="Screen Shot 2018-08-15 at 6.19.39 PM"></p>
<p>初次调用，返回值是32.07。</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(x,y,theta)</span>:</span></div>
<div class="line">    y_ = x.dot(theta)</div>
<div class="line">    loss = (y-y_)**<span class="number">2</span></div>
<div class="line">    cost = sum(loss) / (<span class="number">2</span>*length)</div>
<div class="line">    <span class="keyword">return</span> cost</div>
</pre></td></tr></table></figure>

</div></div>
<p>第四步：梯度下降法</p>
<p>检查梯度下降法是否正确的一个手段：查看损失函数是否在逐步减小。我们使用梯度更新公式：</p>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-15 at 6.26.20 PM.png" alt="Screen Shot 2018-08-15 at 6.26.20 PM"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span><span class="params">(x,y,theta,alpha,iters)</span>:</span></div>
<div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(iters):</div>
<div class="line">        <span class="comment"># cost_function(x,y,theta)</span></div>
<div class="line">        y_ = x.dot(theta)</div>
<div class="line">        loss = (y_ - y)</div>
<div class="line">        gd = loss.T.dot(x) <span class="comment"># shape = (1,2)</span></div>
<div class="line">        gd = alpha * gd.T / length</div>
<div class="line">        theta = theta - gd</div>
<div class="line">    <span class="keyword">return</span> theta</div>
</pre></td></tr></table></figure>
<blockquote>
<p>需要注意的一个点是：loss = ( y_pred - y )。反过来的话，会出现loss趋于无穷大。这个是对loss函数求导得到的，无论$(h_\theta(x)-y )^2$还是$(y-h_\theta(x) )^2$，都是一样的。</p>
</blockquote>

</div></div>
<p>第五步：可视化拟合曲线</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_data</span><span class="params">(x,y,theta)</span>:</span></div>
<div class="line">    plt.scatter(x, y, marker=<span class="string">'x'</span>,label=<span class="string">'Training data'</span>)</div>
<div class="line">    plt.xlabel(<span class="string">"Population of City in 10,000s"</span>)</div>
<div class="line">    plt.ylabel(<span class="string">"Profit in $10,000s"</span>)</div>
<div class="line">    x_ = np.linspace(min(x),max(x),<span class="number">1000</span>)</div>
<div class="line">    y_ = x_*theta[<span class="number">1</span>] + theta[<span class="number">0</span>]</div>
<div class="line">    plt.plot(x_,y_,label=<span class="string">'Linear regression'</span>)</div>
<div class="line">    plt.show()</div>
</pre></td></tr></table></figure>
<p><img src="/2018/08/06/Linear-Regression/image-20180816163328931.png" alt="image-20180816163328931"></p>

</div></div>
<h2 id="线性回归预测多特征数据"><a href="#线性回归预测多特征数据" class="headerlink" title="线性回归预测多特征数据"></a>线性回归预测多特征数据</h2><p>我们使用线性回归预测房价，数据集有两个特征：第一列是房屋面积(单位：$feet^2$)，第二列是房间数，最后一列是房价。</p>
<h3 id="特征正则化"><a href="#特征正则化" class="headerlink" title="特征正则化"></a>特征正则化</h3><p>发现两个特征数据范围相差特别大，所以需要对数据进行正则化，这样可以加快梯度下降法的收敛。</p>
<ul>
<li>减去均值</li>
<li>除以标准差</li>
</ul>
<p>正则化之后，别忘记加一个全一列。</p>
<p><strong>注意：</strong>记得存储mean和std的值，这样我们在预测位置数据的时候，第一步就是使用mean和std对未知数据做同样的处理。</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_norm</span><span class="params">(x)</span>:</span></div>
<div class="line">    mean = np.mean(x,axis=<span class="number">0</span>)</div>
<div class="line">    std = np.std(x,axis=<span class="number">0</span>)</div>
<div class="line">    x = (x-mean)/std</div>
<div class="line">    ones = np.ones((x.shape[<span class="number">0</span>], <span class="number">1</span>))</div>
<div class="line">    x = np.concatenate([ones, x], axis=<span class="number">1</span>)</div>
<div class="line">    <span class="keyword">return</span> x,mean,std</div>
</pre></td></tr></table></figure>

</div></div>
<h3 id="梯度下降法-1"><a href="#梯度下降法-1" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>先实现损失函数</p>
<p><img src="/2018/08/06/Linear-Regression/Screen Shot 2018-08-15 at 6.19.39 PM.png" alt="Screen Shot 2018-08-15 at 6.19.39 PM"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_func</span><span class="params">(x,y,thetas)</span>:</span></div>
<div class="line">    y_pred = x.dot(thetas)</div>
<div class="line">    loss = sum((y_pred-y)**<span class="number">2</span>)/(<span class="number">2</span>*x.shape[<span class="number">0</span>])</div>
<div class="line">    <span class="keyword">return</span> loss</div>
</pre></td></tr></table></figure>

</div></div>
<p>再实现梯度下降法，损失函数都是10次方。</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_dec</span><span class="params">(x,y,thetas,lr,iter)</span>:</span></div>
<div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(iter):</div>
<div class="line">        y_pred = x.dot(thetas)</div>
<div class="line">        gd = (y_pred - y).T.dot(x)</div>
<div class="line">        thetas -= lr * gd.T / x.shape[<span class="number">0</span>]</div>
<div class="line">        loss = cost_func(x, y, thetas)</div>
<div class="line">        print(loss)</div>
<div class="line">    <span class="keyword">return</span> thetas</div>
</pre></td></tr></table></figure>

</div></div>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/05/Linux命令/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/05/Linux命令/" itemprop="url">Linux命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-05T10:35:29-05:00">
                2018-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p>退出保存</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">:wq</div>
</pre></td></tr></table></figure>
<p>利用scp远程上传下载文件/文件夹<a href="https://www.cnblogs.com/zhaofeng555/p/8075279.html" target="_blank" rel="noopener">ref1</a> </p>
<p>统计文件个数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">ls -l |grep "^-"|wc -l #统计当前目录下文件数量</div>
<div class="line">ls -l |grep "^ｄ"|wc -l #统计当前目录下文件夹数量</div>
</pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">cp -r dir1/. /dir2/</div>
</pre></td></tr></table></figure>
<p>设置屏幕分辨率</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">xrandr -s 1366x768</div>
</pre></td></tr></table></figure>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><ul>
<li><p>删除目录下所有文件</p>
<p>用通配符*英文星号可以表示“所有文件”这个概念，所以删除文件夹下所有文件的方法就是，先用cd命令切换到这个文件夹下，然后执行rm ./*命令表示删除当前目录下所有的文件，但是注意，如果文件夹下有子目录，这条命令就无法生效了，因为它无法删除子目录（删除子目录要加上-r选项）。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/03/Training-Techiniques/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/03/Training-Techiniques/" itemprop="url">Training Techiniques</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T11:47:08-05:00">
                2018-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h1><p><img src="/2018/08/03/Training-Techiniques/Screen Shot 2019-02-17 at 3.37.19 PM.png" alt="creen Shot 2019-02-17 at 3.37.19 P"></p>
<h1 id="Soft-labels"><a href="#Soft-labels" class="headerlink" title="Soft labels"></a>Soft labels</h1><p>This is extremely important when training the discriminator. Having hard labels (1 or 0) nearly killed all learning early on, leading the discriminator to approach 0 loss very rapidly. I ended up using a random number between 0 and 0.1 to represent 0 labels (real images) and a random number between 0.9 and 1.0 to represent 1 labels (generated images). This is not required when training the generator. <a href="https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9" target="_blank" rel="noopener">resource</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">valid = np.random.uniform(<span class="number">0.9</span>,<span class="number">1.0</span>,size=(batch_size,<span class="number">1</span>))</div>
<div class="line">fake = np.random.uniform(<span class="number">0</span>,<span class="number">0.1</span>,size=(batch_size,<span class="number">1</span>))</div>
</pre></td></tr></table></figure>
<h1 id="Weight-Initialization"><a href="#Weight-Initialization" class="headerlink" title="Weight Initialization"></a>Weight Initialization</h1><h2 id="Problem-with-initializing-all-weights-to-0"><a href="#Problem-with-initializing-all-weights-to-0" class="headerlink" title="Problem with initializing all weights to 0"></a>Problem with initializing all weights to 0</h2><p>In this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck. It is important to note that the bias weight in each neuron is set to zero by default, not a small random value. <a href="https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/" target="_blank" rel="noopener">ref</a> </p>
<p>During forward propagation each unit in hidden layer gets signal:</p>
<p><img src="/2018/08/03/Training-Techiniques/gif.gif" alt="i"></p>
<p>That is, each hidden unit gets sum of inputs multiplied by the corresponding weight.</p>
<p>Now imagine that you initialize all weights to the same value (e.g. zero or one). In this case, <strong>each hidden unit will get exactly the same signal</strong>. E.g. if all weights are initialized to 1, each unit gets signal equal to sum of inputs (and outputs <code>sigmoid(sum(inputs))</code>). If all weights are zeros, which is even worse, every hidden unit will get zero signal. <strong>No matter what was the input - if all weights are the same, all units in hidden layer will be the same too</strong>.</p>
<p>This is the main issue with symmetry and reason why you should initialize weights randomly (or, at least, with different values). Note, that this issue affects all architectures that use each-to-each connections. <a href="https://stackoverflow.com/questions/20027598/why-should-weights-of-neural-networks-be-initialized-to-random-numbers" target="_blank" rel="noopener">ref</a></p>
<h2 id="Problems-with-initializing-weights-randomly-ref"><a href="#Problems-with-initializing-weights-randomly-ref" class="headerlink" title="Problems with initializing weights randomly ref"></a>Problems with initializing weights randomly <a href="https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94" target="_blank" rel="noopener">ref</a></h2><h3 id="Vanishing-gradients"><a href="#Vanishing-gradients" class="headerlink" title="Vanishing gradients"></a>Vanishing gradients</h3><p>If weights are initialized with low values it gets mapped to 0, then the activation value would be small, say, almost 0. When backpropogating gradients, samll gradients times small weights, it will result in smaller gradients, meaning the earlier layers, the samller gradients, resulting vanishing gradients.</p>
<h3 id="Exploding-gradients"><a href="#Exploding-gradients" class="headerlink" title="Exploding gradients"></a>Exploding gradients</h3><p>Consider you have non-negative and large weights and small activations A (as can be the case for sigmoid(z)). When these weights are multiplied along the layers, they cause a large change in the cost. Thus, the gradients are also going to be large. This means that the changes in W, by <code>W — ⍺ * dW,</code> will be in huge steps, the downward moment will increase.</p>
<blockquote>
<p>This may result in oscillating around the minima or even overshooting the optimum again and again and the model will never learn!</p>
</blockquote>
<p>Another impact of exploding gradients is that huge values of the gradients may cause number overflow resulting in incorrect computations or introductions of NaN’s. This might also lead to the loss taking the value NaN.</p>
<h2 id="New-Initialization-techniques-ref"><a href="#New-Initialization-techniques-ref" class="headerlink" title="New Initialization techniques ref"></a>New Initialization techniques <a href="https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78" target="_blank" rel="noopener">ref</a></h2><h3 id="Xavier-initialization"><a href="#Xavier-initialization" class="headerlink" title="Xavier initialization"></a>Xavier initialization</h3><p>It is used when we use tanh as our activation function.</p>
<p><img src="/2018/08/03/Training-Techiniques/1_Lv9TNpAXffRnO0p0WMGJwQ.png" alt="_Lv9TNpAXffRnO0p0WMGJw"></p>
<p>Some also use the following as initialization:</p>
<p><img src="/2018/08/03/Training-Techiniques/1_QIzXjH8uefVbcaycsjfdmw.png" alt="_QIzXjH8uefVbcaycsjfdm"></p>
<h3 id="He-initialization"><a href="#He-initialization" class="headerlink" title="He initialization"></a>He initialization</h3><p>When we use relu as activation, we just simply multiply random initialization with:</p>
<p><img src="/2018/08/03/Training-Techiniques/1_zxD6Nr6TyAb8JEG6oXAjkg.png" alt="_zxD6Nr6TyAb8JEG6oXAjk"></p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p><a href="https://blog.csdn.net/Jaster_wisdom/article/details/78380839" target="_blank" rel="noopener">ref1</a> <a href="https://www.zhihu.com/question/22334626" target="_blank" rel="noopener">zhihu</a> <a href="http://www.sohu.com/a/200918239_206784" target="_blank" rel="noopener">intuition</a> <a href="https://www.cnblogs.com/rgvb178/p/6055213.html" target="_blank" rel="noopener">details</a> <a href="https://towardsdatascience.com/deep-learning-concepts-part-1-ea0b14b234c8" target="_blank" rel="noopener">to do</a> </p>
<p>根据是否饱和，激活函数可以分类为“饱和激活函数”和“非饱和激活函数”。</p>
<p><strong>sigmoid和tanh</strong>是“饱和激活函数”，而ReLU及其变体则是“非饱和激活函数”，但是他们都属于非线性激活函数。使用“非饱和激活函数”的优势在于两点：     </p>
<p>1.首先，“非饱和激活函数”能解决所谓的“梯度消失”问题。 vanishing gradient在网络层数多的时候尤其明显，是加深网络结构的主要障碍之一   </p>
<p> 2.其次，它能加快收敛速度。    </p>
<p><img src="/2018/08/03/Training-Techiniques/692825-20180328173642905-311674055.png" alt="692825-20180328173642905-311674055"></p>
<h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>将实数压缩到$(0,1)$，用来二分类。</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{1+e^{-x}}</script><p><img src="/2018/08/03/Training-Techiniques/20171028233231084.png" alt="20171028233231084"></p>
<p>sigmoid的优缺点<a href="https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/" target="_blank" rel="noopener">source</a> </p>
<ul>
<li><p><strong>Vanishing gradients</strong>: Notice, the sigmoid function is flat near 0 and 1. In other words, the gradient of the sigmoid is near 0 and 1. During backpropagation through the network with sigmoid activation, the gradients in neurons whose output is near 0 or 1 are nearly 0. These neurons are called saturated neurons. Thus, the weights in these neurons do not update. Not only that, the weights of neurons connected to such neurons are also slowly updated. This problem is also known as vanishing gradient. So, imagine if there was a large network comprising of sigmoid neurons in which many of them are in a saturated regime, then the network will not be able to backpropagate.</p>
<blockquote>
<p><a href="http://www.sohu.com/a/148114422_500659" target="_blank" rel="noopener">ref1</a> 在GAN中， 给 D 最后的输出加个 Sigmoid 激活函数，让它取值在 0 到 1 之间？事实上这个方案在理论上是没有问题的，然而这会造成训练的困难。因为 Sigmoid 函数具有饱和区，一旦 D 进入了饱和区，就很难传回梯度来更新 G 了。</p>
</blockquote>
</li>
<li><p><strong>Not zero centered</strong>: Sigmoid outputs are not zero-centered. The output is always between 0 and 1, that means that the output after applying sigmoid is always positive hence, i.e. $x_i &gt; 0$.</p>
<p><img src="/2018/08/03/Training-Techiniques/Screen%20Shot%202019-02-13%20at%204.07.13%20PM.png" alt="creen Shot 2019-02-13 at 4.07.13 P"></p>
<p>which means the gradients on the weights $w$ during backpropagation become either all positive or all negative. This could introduce undesirable zig-zagging dynamics in the gradient updates for the weights. Say we </p>
<blockquote>
<ul>
<li>Tanh, Rectified Linear Unit (ReLU), Leaky ReLU and Parametric ReLU are all zero-centered activation functions.</li>
<li>This is also why you want zero-mean data</li>
</ul>
</blockquote>
</li>
<li><p><strong>Computationally expensive</strong>: The exp() function is computationally expensive compared with the other non-linear activation functions.</p>
</li>
</ul>
<h2 id="Tanh函数"><a href="#Tanh函数" class="headerlink" title="Tanh函数"></a>Tanh函数</h2><p>将实数压缩到$[-1,1]$</p>
<script type="math/tex; mode=display">
f(x) = tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}\\
 f'(x)=1-f^2(x)</script><p><img src="/2018/08/03/Training-Techiniques/20171028235024692.png" alt="20171028235024692"></p>
<blockquote>
<p>ZERO-centered but still kills gradients when saturated</p>
</blockquote>
<h2 id="ReLu函数"><a href="#ReLu函数" class="headerlink" title="ReLu函数"></a>ReLu函数</h2><script type="math/tex; mode=display">
f(x)=max(0,x)</script><p><img src="/2018/08/03/Training-Techiniques/20171028235337038.png" alt="20171028235337038"></p>
<blockquote>
<p><strong>Advantages:</strong> Does not saturate (in +region); Very computationally efficient; Converges much faster than sigmoid/tanh in practice (e.g. 6x); </p>
<p><strong>Disadvantages:</strong> Not zero-centered output; It kills the gradient when $x \le 0$  </p>
<p><a href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" target="_blank" rel="noopener">dead unit problem</a> <a href="https://ayearofai.com/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b" target="_blank" rel="noopener">dying unit</a> </p>
</blockquote>
<h2 id="LeakyReLu"><a href="#LeakyReLu" class="headerlink" title="LeakyReLu"></a>LeakyReLu</h2><p><img src="/2018/08/03/Training-Techiniques/Screen%20Shot%202019-02-17%20at%202.54.22%20PM.png" alt="creen Shot 2019-02-17 at 2.54.22 P"></p>
<h2 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h2><p><img src="/2018/08/03/Training-Techiniques/Screen%20Shot%202019-02-17%20at%202.55.56%20PM.png" alt="creen Shot 2019-02-17 at 2.55.56 P"></p>
<h1 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h1><p><img src="/2018/08/03/Training-Techiniques/Screen%20Shot%202019-02-17%20at%202.58.24%20PM.png" alt="creen Shot 2019-02-17 at 2.58.24 P"></p>
<h2 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h2><p>用于多分类问题，输出每类可能出现的概率大小，和为1</p>
<script type="math/tex; mode=display">
f(x)_j=\frac{e^{x_j}}{\sum_{i=1}^{k}e^{x_i}}</script><p><img src="/2018/08/03/Training-Techiniques/Screen Shot 2019-02-17 at 2.59.26 PM.png" alt="creen Shot 2019-02-17 at 2.59.26 P"></p>
<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_tensorboard</span><span class="params">(self,generator_step, summary_writer,losses)</span>:</span></div>
<div class="line"></div>
<div class="line">        summary = tf.Summary()</div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Real Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Fake Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">3</span>]</div>
<div class="line">        value.tag = <span class="string">'Generator Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] - losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_real - D_fake)'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] + losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_fake + D_real)'</span></div>
<div class="line"></div>
<div class="line">        summary_writer.add_summary(summary, generator_step)</div>
<div class="line">        summary_writer.flush()</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,epochs,batch_size=<span class="number">10</span>,sample_interval=<span class="number">100</span>)</span>:</span></div>
<div class="line">        summary_writer = tf.summary.FileWriter(<span class="string">'./logs/trainBoth'</span>)</div>
<div class="line">        generator_step = <span class="number">1</span></div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(range(<span class="number">1</span>, epochs + <span class="number">1</span>)):</div>
<div class="line">            <span class="keyword">for</span> e, (figure_imgs, pose_imgs) <span class="keyword">in</span> tqdm(enumerate(self.data_loader.load_batch(batch_size=batch_size))):</div>
<div class="line">                    <span class="comment"># Train the critic</span></div>
<div class="line"></div>
<div class="line">                    figure_loss_real = self.figure_critic.train_on_batch(figure_imgs, valid)</div>
<div class="line">                    figure_loss_fake = self.figure_critic.train_on_batch(gen_figure_imgs, fake)</div>
<div class="line">                    d_figure_loss = <span class="number">0.5</span> * np.add(figure_loss_real, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                print(self.figure_critic.metrics_names,d_figure_loss)</div>
<div class="line">                losses = np.empty(shape=<span class="number">1</span>)</div>
<div class="line">                losses = np.append(losses, figure_loss_real)</div>
<div class="line">                losses = np.append(losses, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line">                <span class="comment">#  Train Generator</span></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line"></div>
<div class="line">                figure_loss = self.figure_EN.train_on_batch([figure_noise,pose_imgs],valid)</div>
<div class="line">                print(self.figure_EN.metrics_names,figure_loss)</div>
<div class="line">                losses = np.append(losses, figure_loss)</div>
<div class="line">                self.write_to_tensorboard(generator_step, summary_writer, losses)</div>
<div class="line">                generator_step += <span class="number">1</span></div>
</pre></td></tr></table></figure>
<h1 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h1><p><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">paper1</a> <a href="https://arxiv.org/pdf/1603.05027v2.pdf" target="_blank" rel="noopener">paper2</a> </p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>simplely stack layers exhibit higher training error when the depth increases.</p>
<h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><p><img src="/2018/08/03/Training-Techiniques/Screen Shot 2018-11-16 at 2.33.45 PM.png" alt="creen Shot 2018-11-16 at 2.33.45 P"></p>
<p><img src="/2018/08/03/Training-Techiniques/residualnet_34.png" alt="esidualnet_3"></p>
<p>Figure from <a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/residual_net.html" target="_blank" rel="noopener">ref</a> </p>
<p><img src="/2018/08/03/Training-Techiniques/2228224-1a6202911b46d1dc.png" alt="228224-1a6202911b46d1d"></p>
<p><a href="https://www.jianshu.com/p/e502e4b43e6d" target="_blank" rel="noopener">pic</a> </p>
<h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p><strong>Optimizer(优化器)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.optimizers.Adam(lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>, amsgrad=<span class="keyword">False</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li>decay, learning rate decay over each update</li>
<li>epsilon, fuzz factor, almost zero but greater than zero, to avoid denominator being zero </li>
<li>according to my search, lr is usually among [0.001, 0.0001, 0.0002], beta_1 is chosen as 0.5</li>
</ul>
</blockquote>
<p><strong>LeakyReLU(激活函数)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.LeakyReLU(alpha=<span class="number">0.3</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li>It allows a small gradient when the unit is not active: <code>f(x) = alpha * x for x &lt; 0</code>, <code>f(x) = x for x &gt;= 0</code></li>
<li>alpha is usually chosen 0.2</li>
</ul>
</blockquote>
<p><strong>BatchNormalization(批正则化)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.BatchNormalization(axis=<span class="number">-1</span>, momentum=<span class="number">0.99</span>, epsilon=<span class="number">0.001</span>, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>momentum</strong>: </li>
<li><strong>epsilon</strong>: Small float added to variance to avoid dividing by zero.</li>
</ul>
</blockquote>
<p><strong>Dropout</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Dropout(rate, noise_shape=<span class="keyword">None</span>, seed=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>rate</strong>: float between 0 and 1. Fraction of the input units to drop. It seems that it has many options, like 0.1, 0.2, 0.5.</li>
</ul>
</blockquote>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<h3 id="Original"><a href="#Original" class="headerlink" title="Original"></a>Original</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">opt  = RMSprop(lr=<span class="number">0.0003</span>, decay=<span class="number">1e-6</span>)</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line">Encoder-Decoder</div>
<div class="line">BatchNormalization(momentum=<span class="number">0.8</span>)</div>
<div class="line">LeakyReLU(<span class="number">0.2</span>)</div>
<div class="line"></div>
<div class="line">Discriminator</div>
<div class="line">BatchNormalization(momentum=<span class="number">0.9</span>)</div>
<div class="line">LeakyReLU(<span class="number">0.2</span>)</div>
</pre></td></tr></table></figure>
<h3 id="DCGAN-CGAN"><a href="#DCGAN-CGAN" class="headerlink" title="DCGAN || CGAN"></a><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="noopener">DCGAN</a> || <a href="https://github.com/zhangqianhui/Conditional-Gans" target="_blank" rel="noopener">CGAN</a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">optim = tf.train.AdamOptimizer(lr=<span class="number">0.0002</span>, beta1=<span class="number">0.5</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<p>beta1 is Momentum term of adam [0.5]</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">lrelu(0.2) </div>
<div class="line">batch_norm(epsilon=1e-5, momentum = 0.9)</div>
</pre></td></tr></table></figure>
<h3 id="INFO-GAN"><a href="#INFO-GAN" class="headerlink" title="INFO-GAN"></a><a href="https://github.com/openai/InfoGAN" target="_blank" rel="noopener">INFO-GAN</a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">d_opt = tf.train.AdamOptimizer(lr = <span class="number">0.0002</span>, beta1=<span class="number">0.5</span>)</div>
<div class="line">g_opt = tf.train.AdamOptimizer(lr = <span class="number">0.001</span>, beta1=<span class="number">0.5</span>)</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">batch_norm(epsilon=<span class="number">1e-5</span>,momentum=<span class="number">0.1</span>)</div>
<div class="line">Lrelu(<span class="number">0.1</span>)</div>
</pre></td></tr></table></figure>
<h3 id="AC-GAN"><a href="#AC-GAN" class="headerlink" title="AC-GAN"></a><a href="https://arxiv.org/pdf/1610.09585.pdf" target="_blank" rel="noopener">AC-GAN</a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">optim = Adam(lr=[<span class="number">0.0001</span>,<span class="number">0.0002</span>,<span class="number">0.00003</span>],beta1=<span class="number">0.5</span>,beta2=<span class="number">0.999</span>)</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">LRELU(<span class="number">0.2</span>)</div>
<div class="line">dropout(<span class="number">0.5</span>)</div>
</pre></td></tr></table></figure>
<h3 id="Adversarial-Autoencoder"><a href="#Adversarial-Autoencoder" class="headerlink" title="Adversarial Autoencoder"></a>Adversarial Autoencoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">optim = tf.train.AdamOptimizer(learning_rate=<span class="number">0.001</span>,beta1=<span class="number">0.9</span>)</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">dropout(<span class="number">0.2</span>)</div>
</pre></td></tr></table></figure>
<h3 id="BI-GAN"><a href="#BI-GAN" class="headerlink" title="BI-GAN"></a>BI-GAN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">optim = Adam(lr=<span class="number">0.0002</span>,beta1=<span class="number">0.5</span>,beta2=<span class="number">0.999</span>)</div>
<div class="line">lr decays exponentially to <span class="number">0.000002</span> starting halfway through training.</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">lrelu(<span class="number">0.2</span>)</div>
<div class="line">(params free) batch_normalization()</div>
</pre></td></tr></table></figure>
<h3 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">Adam(lr=0.0001,beta1=0,beta2=0.9) -&gt; WGAN with Gradient penalty</div>
<div class="line">RMSProp(lr=0.00005) -&gt; WGAN with weight clipping</div>
</pre></td></tr></table></figure>
<h3 id="LSGAN"><a href="#LSGAN" class="headerlink" title="LSGAN"></a>LSGAN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">RMSProp(lr=<span class="number">0.0001</span>)[chosen by search over lr=<span class="number">.001</span>,<span class="number">.0002</span>,<span class="number">.0001</span>]</div>
</pre></td></tr></table></figure>
<h3 id="SR-GAN"><a href="#SR-GAN" class="headerlink" title="SR-GAN"></a>SR-GAN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">Adam(lr=<span class="number">0.0001</span>,beta1=<span class="number">0.9</span>)</div>
</pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">lrelu(0.2)</div>
<div class="line">batch_normalization()</div>
</pre></td></tr></table></figure>
<h3 id="PixelDA"><a href="#PixelDA" class="headerlink" title="PixelDA"></a>PixelDA</h3><p><a href="https://arxiv.org/pdf/1612.05424.pdf" target="_blank" rel="noopener">loss weights</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">Adam(lr=[<span class="number">0.0002</span>,<span class="number">0.001</span>],beta1=<span class="number">0.5</span>)</div>
<div class="line">Learning rate decayed by <span class="number">0.95</span> every <span class="number">20</span>,<span class="number">000</span> steps</div>
</pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">lrelu(<span class="number">0.2</span>)</div>
<div class="line">dropout(<span class="number">0.1</span>) <span class="comment"># with keep probability of 90%</span></div>
</pre></td></tr></table></figure>

</div></div>
<h1 id="DC-GAN"><a href="#DC-GAN" class="headerlink" title="DC-GAN"></a>DC-GAN</h1><p><a href="https://julianzaidi.wordpress.com/2017/04/24/deep-convolution-gan-dcgan-architecture-and-training/" target="_blank" rel="noopener">Deep Convolutional GAN (DCGAN) : Architecture and choice of the good set of hyper-parameters</a></p>
<h1 id="VGG-FEATURE-LOSS"><a href="#VGG-FEATURE-LOSS" class="headerlink" title="VGG-FEATURE-LOSS"></a>VGG-FEATURE-LOSS</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG19</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vgg</span><span class="params">()</span>:</span></div>
<div class="line">    vgg = VGG19(weights=<span class="string">"imagenet"</span>)</div>
<div class="line">    vgg.outputs = [vgg.layers[<span class="number">9</span>].output]</div>
<div class="line">    img = layers.Input(shape=self.img_shape)</div>
<div class="line">    img_features = vgg(img)</div>
<div class="line">    <span class="keyword">return</span> Model(img, img_features)</div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">vgg = build_vgg()</div>
<div class="line">vgg.trainable = <span class="keyword">False</span></div>
<div class="line">vgg.compile(loss=<span class="string">'mse'</span>,optimizer=optimizer,metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"></div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">fake_pose_vgg_feature = vgg(pose_recons)</div>
<div class="line">pose_ende = Model(pose_img,fake_pose_vgg_feature)</div>
<div class="line"> D D</div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">pose_real_vgg_feature = vgg.predict(pose_imgs)</div>
<div class="line">pose_loss = pose_ende.train_on_batch(pose_imgs,pose_real_vgg_feature)</div>
</pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">67</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
