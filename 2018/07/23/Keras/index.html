<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network," />










<meta name="description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network">
<meta property="og:type" content="article">
<meta property="og:title" content="Keras">
<meta property="og:url" content="http://yoursite.com/2018/07/23/Keras/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133932722-715494711.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Time-Based-Learning-Rate-Schedule.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Drop-Based-Learning-Rate-Schedule-2237380.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/history_training_dataset.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/history_validation_dataset.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Screen%20Shot%202019-03-13%20at%2010.25.34%20PM.png">
<meta property="og:updated_time" content="2019-03-28T23:45:16.089Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keras">
<meta name="twitter:description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta name="twitter:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/23/Keras/"/>





  <title>Keras | Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/23/Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Keras</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-23T17:32:39-05:00">
                2018-07-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Keras使用技巧。</p>
<p>TODO</p>
<ul>
<li>[ ] LSTM</li>
<li>[ ] CONV1D</li>
<li>[ ] TIMEDISTRIBUTED-VIDEOS</li>
<li>[ ] FIT_GENERATOR</li>
<li>[ ] STATEFUL_RNN</li>
</ul>
<a id="more"></a>
<h1 id="Keras模块结构"><a href="#Keras模块结构" class="headerlink" title="Keras模块结构"></a>Keras模块结构</h1><p><img src="/2018/07/23/Keras/1119747-20170707133635659-888158147.png" alt="1119747-20170707133635659-888158147"></p>
<h1 id="Keras构建神经网络"><a href="#Keras构建神经网络" class="headerlink" title="Keras构建神经网络"></a>Keras构建神经网络</h1><p><img src="/2018/07/23/Keras/1119747-20170707133932722-715494711.png" alt="1119747-20170707133932722-715494711"></p>
<h1 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h1><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><h3 id="Get-output-shape"><a href="#Get-output-shape" class="headerlink" title="Get output/shape"></a>Get output/shape</h3><p>Whenever you are calling a layer on some input, you are creating a new tensor (the output of the layer), and you are adding a “node” to the layer, linking the input tensor to the output tensor. When you are calling the same layer multiple times, that layer owns multiple nodes indexed as 0, 1, 2…</p>
<p>In previous versions of Keras, you could obtain the output tensor of a layer instance via <code>layer.get_output()</code>, or its output shape via <code>layer.output_shape</code>. You still can (except <code>get_output()</code> has been replaced by the property <code>output</code>). But what if a layer is connected to multiple inputs?</p>
<p>As long as a layer is only connected to one input, there is no confusion, and <code>.output</code> will return the one output of the layer:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">lstm = LSTM(<span class="number">32</span>)</div>
<div class="line">encoded_a = lstm(a)</div>
<div class="line"><span class="keyword">assert</span> lstm.output == encoded_a</div>
</pre></td></tr></table></figure>
<p>If we have multiple inputs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">b = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">lstm = LSTM(<span class="number">32</span>)</div>
<div class="line">encoded_a = lstm(a)</div>
<div class="line">encoded_b = lstm(b)</div>
<div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">0</span>) == encoded_a</div>
<div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">1</span>) == encoded_b</div>
</pre></td></tr></table></figure>
<p>The same is true for the properties <code>input_shape</code> and <code>output_shape</code>: as long as the layer has only one node, or as long as all nodes have the same input/output shape, then the notion of “layer output/input shape” is well defined, and that one shape will be returned by <code>layer.output_shape</code>/<code>layer.input_shape</code>. But if, for instance, you apply the same <code>Conv2D</code> layer to an input of shape <code>(32, 32, 3)</code>, and then to an input of shape <code>(64, 64, 3)</code>, the layer will have multiple input/output shapes, and you will have to fetch them by specifying the index of the node they belong to:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</div>
<div class="line">b = Input(shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</div>
<div class="line">conv = Conv2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>)</div>
<div class="line">conved_a = conv(a)</div>
<div class="line"><span class="comment"># Only one input so far, the following will work:</span></div>
<div class="line"><span class="keyword">assert</span> conv.input_shape == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line">conved_b = conv(b)</div>
<div class="line"><span class="comment"># now the `.input_shape` property wouldn't work, but this does:</span></div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">0</span>) == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">1</span>) == (<span class="keyword">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</div>
</pre></td></tr></table></figure>
<h3 id="Obtain-output-of-an-intermediate-layer"><a href="#Obtain-output-of-an-intermediate-layer" class="headerlink" title="Obtain output of an intermediate layer"></a>Obtain output of an intermediate layer</h3><p>There are two ways to do it. The first one is to create a new model that outputs the layers we want.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line">complete_model = Model() <span class="comment">#create the original model</span></div>
<div class="line">layer_name = <span class="string">'my_layer'</span></div>
<div class="line">intermediate_layer_model = Model(inputs=complete_model.input,outputs=model.get_layer(layer_name).output)</div>
<div class="line">intermediate_output = intermediate_layer_model.predict(data)</div>
</pre></td></tr></table></figure>
<p>Alternatively, we can build a Keras function that will return the output of a certain layer given a certain input, for example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"><span class="comment"># with a Sequential model</span></div>
<div class="line">get_3rd_layer_output = K.function([model.layers[<span class="number">0</span>].input],</div>
<div class="line">                                  [model.layers[<span class="number">3</span>].output])</div>
<div class="line">layer_output = get_3rd_layer_output([x])[<span class="number">0</span>]</div>
</pre></td></tr></table></figure>
<h1 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h1><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><h3 id="模型保存-1"><a href="#模型保存-1" class="headerlink" title="模型保存"></a>模型保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">json_string = model.to_json()</div>
<div class="line">open(<span class="string">'model.json'</span>, <span class="string">'w'</span>).write(json_string)</div>
<div class="line">model.save_weights(<span class="string">'weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h3 id="模型载入"><a href="#模型载入" class="headerlink" title="模型载入"></a>模型载入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div>
<div class="line">model = model_from_json(open(<span class="string">'keras_modelB/model.json'</span>).read())</div>
<div class="line">model.load_weights(<span class="string">'keras_modelB/weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div>
<div class="line">model.save(<span class="string">'my_model.h5'</span>)</div>
<div class="line">model = load_model(<span class="string">'my_model.h5'</span>)</div>
</pre></td></tr></table></figure>
<h1 id="Keras-Callback"><a href="#Keras-Callback" class="headerlink" title="Keras-Callback"></a>Keras-Callback</h1><h2 id="ModelCheckpoint"><a href="#ModelCheckpoint" class="headerlink" title="ModelCheckpoint"></a><a href="https://machinelearningmastery.com/check-point-deep-learning-models-keras/" target="_blank" rel="noopener">ModelCheckpoint</a></h2><h3 id="Checkpoint-Neural-Network-Model-Improvements"><a href="#Checkpoint-Neural-Network-Model-Improvements" class="headerlink" title="Checkpoint Neural Network Model Improvements"></a>Checkpoint Neural Network Model Improvements</h3><p>Checkpoint is an approach where a snapshot of the state of the system is taken in case of system failure. If there is a problem, not all is lost. The checkpoint may be used directly, or used as the starting point for a new run, picking up where it left off. When training deep learning models, the checkpoint is the weights of the model. These weights can be used to make predictions as is, or used as the basis for ongoing training.</p>
<p>The ModelCheckpoint callback class allows you to define where to checkpoint the model weights, how the file should named and under what circumstances to make a checkpoint of the model. The API allows you to specify which metric to monitor, such as loss or accuracy on the training or validation dataset. You can specify whether to look for an improvement in maximizing or minimizing the score. Finally, the filename that you use to store the weights can include variables like the epoch number or metric. The ModelCheckpoint can then be passed to the training process when calling the fit() function on the model.</p>
<p>Note, you may need to install the <a href="http://www.h5py.org/" target="_blank" rel="noopener">h5py library</a> to output network weights in HDF5 format.</p>
<p>Checkpointing is setup to save the network weights only when there is an improvement in classification accuracy on the validation dataset (monitor=’val_acc’ and mode=’max’). The weights are stored in a file that includes the score in the filename (weights-improvement-{val_acc=.2f}.hdf5).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Checkpoint the weights when validation accuracy improves</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># checkpoint</span></div>
<div class="line">filepath=<span class="string">"weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5"</span></div>
<div class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">'val_acc'</span>, verbose=<span class="number">1</span>, save_best_only=<span class="keyword">True</span>, mode=<span class="string">'max'</span>)</div>
<div class="line">callbacks_list = [checkpoint]</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=callbacks_list, verbose=<span class="number">0</span>)</div>
</pre></td></tr></table></figure>
<p>Running the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
</pre></td><td class="code"><pre><div class="line">...</div>
<div class="line">Epoch <span class="number">00134</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00135</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00136</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00137</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00138</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00139</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00140</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.83465</span> to <span class="number">0.83858</span>, saving model to weights-improvement<span class="number">-140</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00141</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00142</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00143</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00144</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00145</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00146</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.83858</span> to <span class="number">0.84252</span>, saving model to weights-improvement<span class="number">-146</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00147</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00148</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.84252</span> to <span class="number">0.84252</span>, saving model to weights-improvement<span class="number">-148</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00149</span>: val_acc did <span class="keyword">not</span> improve</div>
</pre></td></tr></table></figure>
<h3 id="Loading-a-Check-Pointed-Neural-Network-Model"><a href="#Loading-a-Check-Pointed-Neural-Network-Model" class="headerlink" title="Loading a Check-Pointed Neural Network Model"></a>Loading a Check-Pointed Neural Network Model</h3><p>Now that you have seen how to checkpoint your deep learning models during training, you need to review how to load and use a checkpointed model. </p>
<p>In the example below, the model structure is known and the best weights are loaded from the previous experiment, stored in the working directory in the weights.best.hdf5 file.</p>
<p>The model is then used to make predictions on the entire dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># How to load and use weights from a checkpoint</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># load weights</span></div>
<div class="line">model.load_weights(<span class="string">"weights.best.hdf5"</span>)</div>
<div class="line"><span class="comment"># Compile model (required to make predictions)</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line">print(<span class="string">"Created model and loaded weights from file"</span>)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># estimate accuracy on whole dataset using loaded weights</span></div>
<div class="line">scores = model.evaluate(X, Y, verbose=<span class="number">0</span>)</div>
<div class="line">print(<span class="string">"%s: %.2f%%"</span> % (model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]*<span class="number">100</span>))</div>
</pre></td></tr></table></figure>
<h2 id="LearningRateScheduler"><a href="#LearningRateScheduler" class="headerlink" title="LearningRateScheduler"></a><a href="https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/" target="_blank" rel="noopener">LearningRateScheduler</a></h2><p>Adapting the learning rate for your stochastic gradient descent optimization procedure can increase performance and reduce training time. The simplest and perhaps most used adaptation of learning rate during training are techniques that reduce the learning rate over time. These have the benefit of making large changes at the beginning of the training procedure when larger learning rate values are used, and decreasing the learning rate such that a smaller rate and therefore smaller training updates are made to weights later in the training procedure.</p>
<p>Two popular and easy to use learning rate schedules are as follows:</p>
<ul>
<li>Decrease the learning rate gradually based on the epoch.</li>
<li>Decrease the learning rate using punctuated large drops at specific epochs.</li>
</ul>
<p>Next, we will look at how you can use each of these learning rate schedules in turn with Keras.</p>
<h3 id="Time-Based-Learning-Rate-Schedule"><a href="#Time-Based-Learning-Rate-Schedule" class="headerlink" title="Time-Based Learning Rate Schedule"></a>Time-Based Learning Rate Schedule</h3><p>Keras has a time-based learning rate schedule built in.</p>
<p>The stochastic gradient descent optimization algorithm implementation in the SGD class has an argument called decay. This argument is used in the time-based learning rate decay schedule equation as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">LearningRate = LearningRate * <span class="number">1</span>/(<span class="number">1</span> + decay * epoch)</div>
</pre></td></tr></table></figure>
<p>When the decay argument is zero (the default), this has no effect on the learning rate.</p>
<p>When the decay argument is specified, it will decrease the learning rate from the previous epoch by the given fixed amount.</p>
<p>For example, if we use the initial learning rate value of 0.1 and the decay of 0.001, the first 5 epochs will adapt the learning rate as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line">Epoch	Learning Rate</div>
<div class="line"><span class="number">1</span>	<span class="number">0.1</span></div>
<div class="line"><span class="number">2</span>	<span class="number">0.0999000999</span></div>
<div class="line"><span class="number">3</span>	<span class="number">0.0997006985</span></div>
<div class="line"><span class="number">4</span>	<span class="number">0.09940249103</span></div>
<div class="line"><span class="number">5</span>	<span class="number">0.09900646517</span></div>
</pre></td></tr></table></figure>
<p>Extending this out to 100 epochs will produce the following graph of learning rate (y axis) versus epoch (x axis):</p>
<p><img src="/2018/07/23/Keras/Time-Based-Learning-Rate-Schedule.png" alt="ime-Based-Learning-Rate-Schedul"></p>
<p>You can create a nice default schedule by setting the decay value as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">Decay = LearningRate / Epochs</div>
<div class="line">Decay = <span class="number">0.1</span> / <span class="number">100</span></div>
<div class="line">Decay = <span class="number">0.001</span></div>
</pre></td></tr></table></figure>
<p>The example below demonstrates using the time-based learning rate adaptation schedule in Keras. The learning rate for stochastic gradient descent has been set to a higher value of 0.1. The model is trained for 50 epochs and the decay argument has been set to 0.002, calculated as 0.1/50. Additionally, it can be a good idea to use momentum when using an adaptive learning rate. In this case we use a momentum value of 0.8.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Time Based Learning Rate Decay</span></div>
<div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div>
<div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load dataset</span></div>
<div class="line">dataframe = read_csv(<span class="string">"ionosphere.csv"</span>, header=<span class="keyword">None</span>)</div>
<div class="line">dataset = dataframe.values</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">34</span>].astype(float)</div>
<div class="line">Y = dataset[:,<span class="number">34</span>]</div>
<div class="line"><span class="comment"># encode class values as integers</span></div>
<div class="line">encoder = LabelEncoder()</div>
<div class="line">encoder.fit(Y)</div>
<div class="line">Y = encoder.transform(Y)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">34</span>, input_dim=<span class="number">34</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">epochs = <span class="number">50</span></div>
<div class="line">learning_rate = <span class="number">0.1</span></div>
<div class="line">decay_rate = learning_rate / epochs</div>
<div class="line">momentum = <span class="number">0.8</span></div>
<div class="line">sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=<span class="keyword">False</span>)</div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=sgd, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=epochs, batch_size=<span class="number">28</span>, verbose=<span class="number">2</span>)</div>
</pre></td></tr></table></figure>
<h3 id="Drop-Based-Learning-Rate-Schedule"><a href="#Drop-Based-Learning-Rate-Schedule" class="headerlink" title="Drop-Based Learning Rate Schedule"></a>Drop-Based Learning Rate Schedule</h3><p>Another popular learning rate schedule used with deep learning models is to systematically drop the learning rate at specific times during training.</p>
<p>Often this method is implemented by dropping the learning rate by half every fixed number of epochs. For example, we may have an initial learning rate of 0.1 and drop it by 0.5 every 10 epochs. The first 10 epochs of training would use a value of 0.1, in the next 10 epochs a learning rate of 0.05 would be used, and so on.</p>
<p>If we plot out the learning rates for this example out to 100 epochs you get the graph below showing learning rate (y axis) versus epoch (x axis).</p>
<p><img src="/2018/07/23/Keras/Drop-Based-Learning-Rate-Schedule-2237380.png" alt="rop-Based-Learning-Rate-Schedule-223738"></p>
<p>We can implement this in Keras using a the <a href="http://keras.io/callbacks/" target="_blank" rel="noopener">LearningRateScheduler</a> callback when fitting the model.</p>
<p>The LearningRateScheduler callback allows us to define a function to call that takes the epoch number as an argument and returns the learning rate to use in stochastic gradient descent. When used, the learning rate specified by stochastic gradient descent is ignored.</p>
<p>In the code below, we use the same example before of a single hidden layer network on the Ionosphere dataset. A new step_decay() function is defined that implements the equation:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop)</div>
</pre></td></tr></table></figure>
<p>Where InitialLearningRate is the initial learning rate such as 0.1, the DropRate is the amount that the learning rate is modified each time it is changed such as 0.5, Epoch is the current epoch number and EpochDrop is how often to change the learning rate such as 10.</p>
<p>Notice that we set the learning rate in the SGD class to 0 to clearly indicate that it is not used. Nevertheless, you can set a momentum term in SGD if you want to use momentum with this learning rate schedule.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Drop-Based Learning Rate Decay</span></div>
<div class="line"><span class="keyword">import</span> pandas</div>
<div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="keyword">import</span> math</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div>
<div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> LearningRateScheduler</div>
<div class="line"></div>
<div class="line"><span class="comment"># learning rate schedule</span></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_decay</span><span class="params">(epoch)</span>:</span></div>
<div class="line">	initial_lrate = <span class="number">0.1</span></div>
<div class="line">	drop = <span class="number">0.5</span></div>
<div class="line">	epochs_drop = <span class="number">10.0</span></div>
<div class="line">	lrate = initial_lrate * math.pow(drop, math.floor((<span class="number">1</span>+epoch)/epochs_drop))</div>
<div class="line">	<span class="keyword">return</span> lrate</div>
<div class="line"></div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load dataset</span></div>
<div class="line">dataframe = read_csv(<span class="string">"ionosphere.csv"</span>, header=<span class="keyword">None</span>)</div>
<div class="line">dataset = dataframe.values</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">34</span>].astype(float)</div>
<div class="line">Y = dataset[:,<span class="number">34</span>]</div>
<div class="line"><span class="comment"># encode class values as integers</span></div>
<div class="line">encoder = LabelEncoder()</div>
<div class="line">encoder.fit(Y)</div>
<div class="line">Y = encoder.transform(Y)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">34</span>, input_dim=<span class="number">34</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">sgd = SGD(lr=<span class="number">0.0</span>, momentum=<span class="number">0.9</span>, decay=<span class="number">0.0</span>, nesterov=<span class="keyword">False</span>)</div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=sgd, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># learning schedule callback</span></div>
<div class="line">lrate = LearningRateScheduler(step_decay)</div>
<div class="line">callbacks_list = [lrate]</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">50</span>, batch_size=<span class="number">28</span>, callbacks=callbacks_list, verbose=<span class="number">2</span>)</div>
</pre></td></tr></table></figure>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a><a href="https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/" target="_blank" rel="noopener">History</a></h2><p>History callback records training metrics for each epoch. This includes the loss and the accuracy (for classification problems) as well as the loss and accuracy for the validation dataset, if one is set. The history object is returned from calls to the fit() function used to train the model. Metrics are stored in a dictionary in the history member of the object returned.</p>
<p>For example, you can list the metrics collected in a history object using the following snippet of code after a model is trained:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># list all data in history</span></div>
<div class="line">print(history.history.keys())</div>
</pre></td></tr></table></figure>
<p>For example, for a model trained on a classification problem with a validation dataset, this might produce the following listing:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">[<span class="string">'acc'</span>, <span class="string">'loss'</span>, <span class="string">'val_acc'</span>, <span class="string">'val_loss'</span>]</div>
</pre></td></tr></table></figure>
<h3 id="Visualize-Model-Training-History-in-Keras"><a href="#Visualize-Model-Training-History-in-Keras" class="headerlink" title="Visualize Model Training History in Keras"></a>Visualize Model Training History in Keras</h3><p>The example collects the history, returned from training the model and creates two charts:</p>
<ol>
<li>A plot of accuracy on the training and validation datasets over training epochs.</li>
<li>A plot of loss on the training and validation datasets over training epochs.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Visualize training history</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">history = model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div>
<div class="line"><span class="comment"># list all data in history</span></div>
<div class="line">print(history.history.keys())</div>
<div class="line"><span class="comment"># summarize history for accuracy</span></div>
<div class="line">plt.plot(history.history[<span class="string">'acc'</span>])</div>
<div class="line">plt.plot(history.history[<span class="string">'val_acc'</span>])</div>
<div class="line">plt.title(<span class="string">'model accuracy'</span>)</div>
<div class="line">plt.ylabel(<span class="string">'accuracy'</span>)</div>
<div class="line">plt.xlabel(<span class="string">'epoch'</span>)</div>
<div class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</div>
<div class="line">plt.show()</div>
<div class="line"><span class="comment"># summarize history for loss</span></div>
<div class="line">plt.plot(history.history[<span class="string">'loss'</span>])</div>
<div class="line">plt.plot(history.history[<span class="string">'val_loss'</span>])</div>
<div class="line">plt.title(<span class="string">'model loss'</span>)</div>
<div class="line">plt.ylabel(<span class="string">'loss'</span>)</div>
<div class="line">plt.xlabel(<span class="string">'epoch'</span>)</div>
<div class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</div>
<div class="line">plt.show()</div>
</pre></td></tr></table></figure>
<p>The plots are provided below. The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.</p>
<p>From the plot of accuracy we can see that the model could probably be trained a little more as the trend for accuracy on both datasets is still rising for the last few epochs. We can also see that the model has not yet over-learned the training dataset, showing comparable skill on both datasets.</p>
<p><img src="/2018/07/23/Keras/history_training_dataset.png" alt="istory_training_datase"></p>
<p>From the plot of loss, we can see that the model has comparable performance on both train and validation datasets (labeled test). If these parallel plots start to depart consistently, it might be a sign to stop training at an earlier epoch.</p>
<p><img src="/2018/07/23/Keras/history_validation_dataset.png" alt="istory_validation_datase"></p>
<h2 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h2><p><a href="http://www.moxleystratton.com/tensorflow-visualizing-weights/" target="_blank" rel="noopener">Visualizing Neuron Weights During Training</a> <a href="**https**://www.jianshu.com/p/25e30055d7ac">如何在使用train_on_batch时候调用tensorboard</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_tensorboard</span><span class="params">(self,generator_step, summary_writer,losses)</span>:</span></div>
<div class="line"></div>
<div class="line">        summary = tf.Summary()</div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Real Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Fake Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">3</span>]</div>
<div class="line">        value.tag = <span class="string">'Generator Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] - losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_real - D_fake)'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] + losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_fake + D_real)'</span></div>
<div class="line"></div>
<div class="line">        summary_writer.add_summary(summary, generator_step)</div>
<div class="line">        summary_writer.flush()</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,epochs,batch_size=<span class="number">10</span>,sample_interval=<span class="number">100</span>)</span>:</span></div>
<div class="line">        summary_writer = tf.summary.FileWriter(<span class="string">'./logs/trainBoth'</span>)</div>
<div class="line">        generator_step = <span class="number">1</span></div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(range(<span class="number">1</span>, epochs + <span class="number">1</span>)):</div>
<div class="line">            <span class="keyword">for</span> e, (figure_imgs, pose_imgs) <span class="keyword">in</span> tqdm(enumerate(self.data_loader.load_batch(batch_size=batch_size))):</div>
<div class="line">                    <span class="comment"># Train the critic</span></div>
<div class="line"></div>
<div class="line">                    figure_loss_real = self.figure_critic.train_on_batch(figure_imgs, valid)</div>
<div class="line">                    figure_loss_fake = self.figure_critic.train_on_batch(gen_figure_imgs, fake)</div>
<div class="line">                    d_figure_loss = <span class="number">0.5</span> * np.add(figure_loss_real, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                print(self.figure_critic.metrics_names,d_figure_loss)</div>
<div class="line">                losses = np.empty(shape=<span class="number">1</span>)</div>
<div class="line">                losses = np.append(losses, figure_loss_real)</div>
<div class="line">                losses = np.append(losses, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line">                <span class="comment">#  Train Generator</span></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line"></div>
<div class="line">                figure_loss = self.figure_EN.train_on_batch([figure_noise,pose_imgs],valid)</div>
<div class="line">                print(self.figure_EN.metrics_names,figure_loss)</div>
<div class="line">                losses = np.append(losses, figure_loss)</div>
<div class="line">                self.write_to_tensorboard(generator_step, summary_writer, losses)</div>
<div class="line">                generator_step += <span class="number">1</span></div>
</pre></td></tr></table></figure>
<h3 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
<div class="line">78</div>
<div class="line">79</div>
<div class="line">80</div>
<div class="line">81</div>
</pre></td><td class="code"><pre><div class="line"></div>
<div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div>
<div class="line"></div>
<div class="line">SUMMARY_DIR = <span class="string">"./graph"</span></div>
<div class="line">BATCH_SIZE = <span class="number">100</span></div>
<div class="line">TRAIN_STEPS = <span class="number">3000</span></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span><span class="params">(var, name)</span>:</span></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</div>
<div class="line">        tf.summary.histogram(name, var)</div>
<div class="line">        mean = tf.reduce_mean(var)</div>
<div class="line">        tf.summary.scalar(<span class="string">'mean/'</span> + name, mean)</div>
<div class="line">        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</div>
<div class="line">        tf.summary.scalar(<span class="string">'stddev/'</span> + name, stddev)</div>
<div class="line"></div>
<div class="line"><span class="comment"># 2. 生成一层全链接的神经网络</span></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_layer</span><span class="params">(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu)</span>:</span></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'weights'</span>):</div>
<div class="line">            weights = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=<span class="number">0.1</span>))</div>
<div class="line">            variable_summaries(weights, layer_name + <span class="string">'/weights'</span>)</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'biases'</span>):</div>
<div class="line">            biases = tf.Variable(tf.constant(<span class="number">0.0</span>, shape=[output_dim]))</div>
<div class="line">            variable_summaries(biases, layer_name + <span class="string">'/biases'</span>)</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'Wx_plus_b'</span>):</div>
<div class="line">            preactivate = tf.matmul(input_tensor, weights) + biases</div>
<div class="line">            tf.summary.histogram(layer_name + <span class="string">'/pre_activations'</span>, preactivate)</div>
<div class="line">        activations = act(preactivate, name=<span class="string">'activation'</span>)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># 记录神经网络节点输出在经过激活函数之后的分布。</span></div>
<div class="line">        tf.summary.histogram(layer_name + <span class="string">'/activations'</span>, activations)</div>
<div class="line">        <span class="keyword">return</span> activations</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div>
<div class="line">    mnist = input_data.read_data_sets(<span class="string">"D:\pyprogram"</span>, one_hot=<span class="keyword">True</span>)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</div>
<div class="line">        x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>], name=<span class="string">'x-input'</span>)</div>
<div class="line">        y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>], name=<span class="string">'y-input'</span>)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'input_reshape'</span>):</div>
<div class="line">        image_shaped_input = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</div>
<div class="line">        tf.summary.image(<span class="string">'input'</span>, image_shaped_input, <span class="number">10</span>)</div>
<div class="line"></div>
<div class="line">    hidden1 = nn_layer(x, <span class="number">784</span>, <span class="number">500</span>, <span class="string">'layer1'</span>)</div>
<div class="line">    y = nn_layer(hidden1, <span class="number">500</span>, <span class="number">10</span>, <span class="string">'layer2'</span>, act=tf.identity)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'cross_entropy'</span>):</div>
<div class="line">        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))</div>
<div class="line">        tf.summary.scalar(<span class="string">'cross_entropy'</span>, cross_entropy)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</div>
<div class="line">        train_step = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cross_entropy)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'correct_prediction'</span>):</div>
<div class="line">            correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div>
<div class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div>
<div class="line">        tf.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div>
<div class="line"></div>
<div class="line">    merged = tf.summary.merge_all()</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div>
<div class="line">        summary_writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)</div>
<div class="line">        tf.global_variables_initializer().run()</div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(TRAIN_STEPS):</div>
<div class="line">            xs, ys = mnist.train.next_batch(BATCH_SIZE)</div>
<div class="line">            <span class="comment"># 运行训练步骤以及所有的日志生成操作，得到这次运行的日志。</span></div>
<div class="line">            summary, _ = sess.run([merged, train_step], feed_dict=&#123;x: xs, y_: ys&#125;)</div>
<div class="line">            <span class="comment"># 将得到的所有日志写入日志文件，这样TensorBoard程序就可以拿到这次运行所对应的</span></div>
<div class="line">            <span class="comment"># 运行信息。</span></div>
<div class="line">            summary_writer.add_summary(summary, i)</div>
<div class="line"></div>
<div class="line">    summary_writer.close()</div>
<div class="line"></div>
<div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div>
<div class="line">    main()</div>
</pre></td></tr></table></figure>
<p><img src="/2018/07/23/Keras/Screen Shot 2019-03-13 at 10.25.34 PM.png" alt="creen Shot 2019-03-13 at 10.25.34 P"></p>
<h1 id="Customerize-Optimizer"><a href="#Customerize-Optimizer" class="headerlink" title="Customerize Optimizer"></a>Customerize Optimizer</h1><p>The following example is an example of modifing the implementation of Adam optimizer, so that it can support differential privacy.</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Optimizer</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_norm</span><span class="params">(g, c, n)</span>:</span></div>
<div class="line">    <span class="keyword">if</span> c &gt; <span class="number">0</span>:</div>
<div class="line">        g = K.switch(n &gt;= c, g * c / n, g)</div>
<div class="line">    <span class="keyword">return</span> g</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoisyAdam</span><span class="params">(Optimizer)</span>:</span></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>,</span></span></div>
<div class="line"><span class="function"><span class="params">                 epsilon=<span class="number">1e-8</span>, decay=<span class="number">0.</span>, noise=<span class="number">0.</span>, **kwargs)</span>:</span></div>
<div class="line">        super(NoisyAdam, self).__init__(**kwargs)</div>
<div class="line">        self.iterations = K.variable(<span class="number">0</span>, name=<span class="string">'iterations'</span>)</div>
<div class="line">        self.lr = K.variable(lr, name=<span class="string">'lr'</span>)</div>
<div class="line">        self.beta_1 = K.variable(beta_1, name=<span class="string">'beta_1'</span>)</div>
<div class="line">        self.beta_2 = K.variable(beta_2, name=<span class="string">'beta_2'</span>)</div>
<div class="line">        self.epsilon = epsilon</div>
<div class="line">        self.decay = K.variable(decay, name=<span class="string">'decay'</span>)</div>
<div class="line">        self.initial_decay = decay</div>
<div class="line">        self.noise = noise</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_gradients</span><span class="params">(self, loss, params)</span>:</span></div>
<div class="line">        grads = K.gradients(loss, params)</div>
<div class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'clipnorm'</span>) <span class="keyword">and</span> self.clipnorm &gt; <span class="number">0</span>:</div>
<div class="line">            norm = K.sqrt(sum([K.sum(K.square(g)) <span class="keyword">for</span> g <span class="keyword">in</span> grads]))</div>
<div class="line">            grads = [clip_norm(g, self.clipnorm, norm) <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'clipvalue'</span>) <span class="keyword">and</span> self.clipvalue &gt; <span class="number">0</span>:</div>
<div class="line">            grads = [K.clip(g, -self.clipvalue, self.clipvalue) <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line"></div>
<div class="line">        <span class="keyword">if</span> self.noise &gt; <span class="number">0</span>:</div>
<div class="line">            grads = [(g + K.random_normal(g.shape, mean=<span class="number">0</span>,</div>
<div class="line">                                          stddev=(self.noise * self.clipnorm)))</div>
<div class="line">                     <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line">        <span class="keyword">return</span> grads</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_updates</span><span class="params">(self, loss,params)</span>:</span></div>
<div class="line">        grads = self.get_gradients(loss, params)</div>
<div class="line">        self.updates = [K.update_add(self.iterations, <span class="number">1</span>)]</div>
<div class="line"></div>
<div class="line">        lr = self.lr</div>
<div class="line">        <span class="keyword">if</span> self.initial_decay &gt; <span class="number">0</span>:</div>
<div class="line">            lr *= (<span class="number">1.</span> / (<span class="number">1.</span> + self.decay * self.iterations))</div>
<div class="line"></div>
<div class="line">        t = self.iterations + <span class="number">1</span></div>
<div class="line">        lr_t = lr * (K.sqrt(<span class="number">1.</span> - K.pow(self.beta_2, t)) /</div>
<div class="line">                     (<span class="number">1.</span> - K.pow(self.beta_1, t)))</div>
<div class="line"></div>
<div class="line">        shapes = [K.get_variable_shape(p) <span class="keyword">for</span> p <span class="keyword">in</span> params]</div>
<div class="line">        ms = [K.zeros(shape) <span class="keyword">for</span> shape <span class="keyword">in</span> shapes]</div>
<div class="line">        vs = [K.zeros(shape) <span class="keyword">for</span> shape <span class="keyword">in</span> shapes]</div>
<div class="line">        self.weights = [self.iterations] + ms + vs</div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> p, g, m, v <span class="keyword">in</span> zip(params, grads, ms, vs):</div>
<div class="line">            m_t = (self.beta_1 * m) + (<span class="number">1.</span> - self.beta_1) * g</div>
<div class="line">            v_t = (self.beta_2 * v) + (<span class="number">1.</span> - self.beta_2) * K.square(g)</div>
<div class="line">            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)</div>
<div class="line"></div>
<div class="line">            self.updates.append(K.update(m, m_t))</div>
<div class="line">            self.updates.append(K.update(v, v_t))</div>
<div class="line">            new_p = p_t</div>
<div class="line">            <span class="comment"># Apply constraints.</span></div>
<div class="line">            <span class="keyword">if</span> getattr(p, <span class="string">'constraint'</span>, <span class="keyword">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div>
<div class="line">                new_p = p.constraint(new_p)</div>
<div class="line"></div>
<div class="line">            self.updates.append(K.update(p, new_p))</div>
<div class="line">        <span class="keyword">return</span> self.updates</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></div>
<div class="line">        config = &#123;<span class="string">'lr'</span>: float(K.get_value(self.lr)),</div>
<div class="line">                  <span class="string">'beta_1'</span>: float(K.get_value(self.beta_1)),</div>
<div class="line">                  <span class="string">'beta_2'</span>: float(K.get_value(self.beta_2)),</div>
<div class="line">                  <span class="string">'decay'</span>: float(K.get_value(self.decay)),</div>
<div class="line">                  <span class="string">'epsilon'</span>: self.epsilon&#125;</div>
<div class="line">        base_config = super(NoisyAdam, self).get_config()</div>
<div class="line">        <span class="keyword">return</span> dict(list(base_config.items()) + list(config.items()))</div>
</pre></td></tr></table></figure>

</div></div>
<h1 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h1><h2 id="VGG-Feature-Loss"><a href="#VGG-Feature-Loss" class="headerlink" title="VGG Feature Loss"></a>VGG Feature Loss</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG19</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vgg</span><span class="params">()</span>:</span></div>
<div class="line">    vgg = VGG19(weights=<span class="string">"imagenet"</span>)</div>
<div class="line">    vgg.outputs = [vgg.layers[<span class="number">9</span>].output]</div>
<div class="line">    img = layers.Input(shape=self.img_shape)</div>
<div class="line">    img_features = vgg(img)</div>
<div class="line">    <span class="keyword">return</span> Model(img, img_features)</div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">vgg = build_vgg()</div>
<div class="line">vgg.trainable = <span class="keyword">False</span></div>
<div class="line">vgg.compile(loss=<span class="string">'mse'</span>,optimizer=optimizer,metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"></div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">fake_pose_vgg_feature = vgg(pose_recons)</div>
<div class="line">pose_ende = Model(pose_img,fake_pose_vgg_feature)</div>
<div class="line"> </div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">pose_real_vgg_feature = vgg.predict(pose_imgs)</div>
<div class="line">pose_loss = pose_ende.train_on_batch(pose_imgs,pose_real_vgg_feature)</div>
</pre></td></tr></table></figure>
<h2 id="Fine-tune-ref"><a href="#Fine-tune-ref" class="headerlink" title="Fine tune ref"></a>Fine tune <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="noopener">ref</a></h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/Keras/" rel="tag"># Keras</a>
          
            <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/22/AutoEncoder/" rel="next" title="AutoEncoder">
                <i class="fa fa-chevron-left"></i> AutoEncoder
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/24/Neural-Network/" rel="prev" title="Neural Network">
                Neural Network <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">76</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras模块结构"><span class="nav-number">1.</span> <span class="nav-text">Keras模块结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras构建神经网络"><span class="nav-number">2.</span> <span class="nav-text">Keras构建神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Layers"><span class="nav-number">3.</span> <span class="nav-text">Layers</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Properties"><span class="nav-number">3.1.</span> <span class="nav-text">Properties</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Get-output-shape"><span class="nav-number">3.1.1.</span> <span class="nav-text">Get output/shape</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Obtain-output-of-an-intermediate-layer"><span class="nav-number">3.1.2.</span> <span class="nav-text">Obtain output of an intermediate layer</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型保存"><span class="nav-number">4.</span> <span class="nav-text">模型保存</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#方法一"><span class="nav-number">4.1.</span> <span class="nav-text">方法一</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型保存-1"><span class="nav-number">4.1.1.</span> <span class="nav-text">模型保存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型载入"><span class="nav-number">4.1.2.</span> <span class="nav-text">模型载入</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方法二"><span class="nav-number">4.2.</span> <span class="nav-text">方法二</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras-Callback"><span class="nav-number">5.</span> <span class="nav-text">Keras-Callback</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ModelCheckpoint"><span class="nav-number">5.1.</span> <span class="nav-text">ModelCheckpoint</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Checkpoint-Neural-Network-Model-Improvements"><span class="nav-number">5.1.1.</span> <span class="nav-text">Checkpoint Neural Network Model Improvements</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loading-a-Check-Pointed-Neural-Network-Model"><span class="nav-number">5.1.2.</span> <span class="nav-text">Loading a Check-Pointed Neural Network Model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LearningRateScheduler"><span class="nav-number">5.2.</span> <span class="nav-text">LearningRateScheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Time-Based-Learning-Rate-Schedule"><span class="nav-number">5.2.1.</span> <span class="nav-text">Time-Based Learning Rate Schedule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Drop-Based-Learning-Rate-Schedule"><span class="nav-number">5.2.2.</span> <span class="nav-text">Drop-Based Learning Rate Schedule</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#History"><span class="nav-number">5.3.</span> <span class="nav-text">History</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Visualize-Model-Training-History-in-Keras"><span class="nav-number">5.3.1.</span> <span class="nav-text">Visualize Model Training History in Keras</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensorboard"><span class="nav-number">5.4.</span> <span class="nav-text">Tensorboard</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorflow"><span class="nav-number">5.4.1.</span> <span class="nav-text">Tensorflow</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Customerize-Optimizer"><span class="nav-number">6.</span> <span class="nav-text">Customerize Optimizer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Feature-Extraction"><span class="nav-number">7.</span> <span class="nav-text">Feature Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#VGG-Feature-Loss"><span class="nav-number">7.1.</span> <span class="nav-text">VGG Feature Loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fine-tune-ref"><span class="nav-number">7.2.</span> <span class="nav-text">Fine tune ref</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
