<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network," />










<meta name="description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network">
<meta property="og:type" content="article">
<meta property="og:title" content="Keras">
<meta property="og:url" content="http://yoursite.com/2018/07/23/Keras/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133932722-715494711.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Screen%20Shot%202019-03-29%20at%201.06.19%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_5151.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_9819.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3682.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_2380.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3682-4504351.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_4790.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3682-4504721.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_8162.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3682-4504809.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_1571.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3682-4504439.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_9447.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_3021.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/cat_0_6028.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Time-Based-Learning-Rate-Schedule.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Drop-Based-Learning-Rate-Schedule-2237380.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/history_training_dataset.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/history_validation_dataset.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Screen%20Shot%202019-03-13%20at%2010.25.34%20PM.png">
<meta property="og:updated_time" content="2019-04-22T15:32:07.760Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keras">
<meta name="twitter:description" content="Keras使用技巧。 TODO  [ ] LSTM [ ] CONV1D [ ] TIMEDISTRIBUTED-VIDEOS [ ] FIT_GENERATOR [ ] STATEFUL_RNN">
<meta name="twitter:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/23/Keras/"/>





  <title>Keras | Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/23/Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Keras</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-23T17:32:39-05:00">
                2018-07-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Keras使用技巧。</p>
<p>TODO</p>
<ul>
<li>[ ] LSTM</li>
<li>[ ] CONV1D</li>
<li>[ ] TIMEDISTRIBUTED-VIDEOS</li>
<li>[ ] FIT_GENERATOR</li>
<li>[ ] STATEFUL_RNN</li>
</ul>
<a id="more"></a>
<h1 id="Keras模块结构"><a href="#Keras模块结构" class="headerlink" title="Keras模块结构"></a>Keras模块结构</h1><p><img src="/2018/07/23/Keras/1119747-20170707133635659-888158147.png" alt="1119747-20170707133635659-888158147"></p>
<h1 id="Keras构建神经网络"><a href="#Keras构建神经网络" class="headerlink" title="Keras构建神经网络"></a>Keras构建神经网络</h1><p><img src="/2018/07/23/Keras/1119747-20170707133932722-715494711.png" alt="1119747-20170707133932722-715494711"></p>
<h1 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h1><p>There are two ways to implement a keras model, Sequential and Model. We will use an image classification example to see how these ways work and their corresponding properties.</p>
<p>We use MNIST hand-written recognition as the example. We will implement a three-layers convolution network, i.e., <code>input_layer -&gt; conv2d -&gt; conv2d -&gt; dense -&gt; output_layer</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Conv2D, Flatten</div>
<div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div>
<div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</div>
<div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div>
<div class="line">X_train = X_train.reshape(<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</div>
<div class="line">X_test = X_test.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</div>
<div class="line">y_train = to_categorical(y_train)</div>
<div class="line">y_test = to_categorical(y_test)</div>
<div class="line">model = Sequential()</div>
<div class="line"><span class="comment">#add model layers</span></div>
<div class="line">model.add(Conv2D(<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),name=<span class="string">'conv1'</span>))</div>
<div class="line">model.add(Conv2D(<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">'relu'</span>,name=<span class="string">'conv2'</span>))</div>
<div class="line">model.add(Flatten(name=<span class="string">'flatten'</span>))</div>
<div class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>,name=<span class="string">'dense'</span>))</div>
<div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
</pre></td></tr></table></figure>
<h2 id="Attributes"><a href="#Attributes" class="headerlink" title="Attributes"></a>Attributes</h2><p><code>model.layers</code>: return a flattened list of the layers comprising the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">print(model.layers)</div>
<div class="line"><span class="comment">##[&lt;keras.layers.convolutional.Conv2D object at 0x11b62a780&gt;, &lt;keras.layers.convolutional.Conv2D object at 0x11b63df98&gt;, &lt;keras.layers.core.Flatten object at 0x11eb17588&gt;, &lt;keras.layers.core.Dense object at 0x11eb170f0&gt;]</span></div>
</pre></td></tr></table></figure>
<p><code>model.inputs</code>: return the list of input tensors of the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">print(model.inputs)</div>
<div class="line"><span class="comment">##[&lt;tf.Tensor 'conv1_input:0' shape=(?, 28, 28, 1) dtype=float32&gt;]</span></div>
</pre></td></tr></table></figure>
<p><code>model.outputs</code>: return the list of output tensors of the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">print(model.outputs)</div>
<div class="line"><span class="comment">##[&lt;tf.Tensor 'dense/Softmax:0' shape=(?, 10) dtype=float32&gt;]</span></div>
</pre></td></tr></table></figure>
<p><code>model.summary</code>: prints a summary representation of the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
</pre></td><td class="code"><pre><div class="line">_________________________________________________________________</div>
<div class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></div>
<div class="line">=================================================================</div>
<div class="line">conv1 (Conv2D)               (<span class="keyword">None</span>, <span class="number">26</span>, <span class="number">26</span>, <span class="number">64</span>)        <span class="number">640</span>       </div>
<div class="line">_________________________________________________________________</div>
<div class="line">conv2 (Conv2D)               (<span class="keyword">None</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">32</span>)        <span class="number">18464</span>     </div>
<div class="line">_________________________________________________________________</div>
<div class="line">flatten (Flatten)            (<span class="keyword">None</span>, <span class="number">18432</span>)             <span class="number">0</span>         </div>
<div class="line">_________________________________________________________________</div>
<div class="line">dense (Dense)                (<span class="keyword">None</span>, <span class="number">10</span>)                <span class="number">184330</span>    </div>
<div class="line">=================================================================</div>
<div class="line">Total params: <span class="number">203</span>,<span class="number">434</span></div>
<div class="line">Trainable params: <span class="number">203</span>,<span class="number">434</span></div>
<div class="line">Non-trainable params: <span class="number">0</span></div>
<div class="line">_________________________________________________________________</div>
</pre></td></tr></table></figure>
<p><code>model.get_weights()</code>: return a list of all weights tensors as Numpy arrays, where weights are stored in model.get_weights()[0] and bias are stored in model.get_weights()[2].</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">print(model.get_weights())</div>
</pre></td></tr></table></figure>
<h2 id="Model-subclassing"><a href="#Model-subclassing" class="headerlink" title="Model subclassing"></a>Model subclassing</h2><p>In addition to these two types of models, you may create your own fully-customizable models by subclassing the <code>Model</code> class and implementing your own forward pass in the <code>call</code> method.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> keras</div>
<div class="line"></div>
<div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleMLP</span><span class="params">(keras.Model)</span>:</span></div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, use_bn=False, use_dp=False, num_classes=<span class="number">10</span>)</span>:</span></div>
<div class="line">        super(SimpleMLP, self).__init__(name=<span class="string">'mlp'</span>)</div>
<div class="line">        self.use_bn = use_bn</div>
<div class="line">        self.use_dp = use_dp</div>
<div class="line">        self.num_classes = num_classes</div>
<div class="line"></div>
<div class="line">        self.dense1 = keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)</div>
<div class="line">        self.dense2 = keras.layers.Dense(num_classes, activation=<span class="string">'softmax'</span>)</div>
<div class="line">        <span class="keyword">if</span> self.use_dp:</div>
<div class="line">            self.dp = keras.layers.Dropout(<span class="number">0.5</span>)</div>
<div class="line">        <span class="keyword">if</span> self.use_bn:</div>
<div class="line">            self.bn = keras.layers.BatchNormalization(axis=<span class="number">-1</span>)</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></div>
<div class="line">        x = self.dense1(inputs)</div>
<div class="line">        <span class="keyword">if</span> self.use_dp:</div>
<div class="line">            x = self.dp(x)</div>
<div class="line">        <span class="keyword">if</span> self.use_bn:</div>
<div class="line">            x = self.bn(x)</div>
<div class="line">        <span class="keyword">return</span> self.dense2(x)</div>
<div class="line"></div>
<div class="line">model = SimpleMLP()</div>
<div class="line">model.compile(...)</div>
<div class="line">model.fit(...)</div>
</pre></td></tr></table></figure>
<p>In <code>call</code>, you may specify custom losses by calling <code>self.add_loss(loss_tensor)</code> (like you would in a custom layer).</p>
<p>But in subclassed models, the following methods and attributes are not available:</p>
<p><img src="/2018/07/23/Keras/Screen Shot 2019-03-29 at 1.06.19 PM.png" alt="creen Shot 2019-03-29 at 1.06.19 P"></p>
<h2 id="Model-class-API"><a href="#Model-class-API" class="headerlink" title="Model class API"></a>Model class API</h2><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><h4 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">compile(optimizer, loss=<span class="keyword">None</span>, metrics=<span class="keyword">None</span>, loss_weights=<span class="keyword">None</span>, sample_weight_mode=<span class="keyword">None</span>, weighted_metrics=<span class="keyword">None</span>, target_tensors=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<h4 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">fit(x=<span class="keyword">None</span>, y=<span class="keyword">None</span>, batch_size=<span class="keyword">None</span>, epochs=<span class="number">1</span>, verbose=<span class="number">1</span>, callbacks=<span class="keyword">None</span>, validation_split=<span class="number">0.0</span>, validation_data=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>, class_weight=<span class="keyword">None</span>, sample_weight=<span class="keyword">None</span>, initial_epoch=<span class="number">0</span>, steps_per_epoch=<span class="keyword">None</span>, validation_steps=<span class="keyword">None</span>, validation_freq=<span class="number">1</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>verbose</strong>: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.</li>
<li>A <code>History</code> object. Its <code>History.history</code> attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).</li>
</ul>
</blockquote>
<h4 id="evaluate"><a href="#evaluate" class="headerlink" title="evaluate"></a>evaluate</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">evaluate(x=<span class="keyword">None</span>, y=<span class="keyword">None</span>, batch_size=<span class="keyword">None</span>, verbose=<span class="number">1</span>, sample_weight=<span class="keyword">None</span>, steps=<span class="keyword">None</span>, callbacks=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<p>Returns scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code>model.metrics_names</code> will give you the display labels for the scalar outputs.</p>
<p>Computation is done in batches.</p>
<ul>
<li><strong>verbose</strong>: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</li>
</ul>
</blockquote>
<h4 id="predict"><a href="#predict" class="headerlink" title="predict"></a>predict</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">predict(x, batch_size=<span class="keyword">None</span>, verbose=<span class="number">0</span>, steps=<span class="keyword">None</span>, callbacks=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li><strong>verbose</strong>: Verbosity mode, 0 or 1.</li>
</ul>
</blockquote>
<h4 id="train-on-batch"><a href="#train-on-batch" class="headerlink" title="train_on_batch"></a>train_on_batch</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">train_on_batch(x, y, sample_weight=<span class="keyword">None</span>, class_weight=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li>Scalar training loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code>model.metrics_names</code> will give you the display labels for the scalar outputs.</li>
<li>Runs a single gradient update on a single batch of data.</li>
</ul>
</blockquote>
<h4 id="test-on-batch"><a href="#test-on-batch" class="headerlink" title="test_on_batch"></a>test_on_batch</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">test_on_batch(x, y, sample_weight=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li>Test the model on a single batch of samples.</li>
<li>Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code>model.metrics_names</code> will give you the display labels for the scalar outputs.</li>
</ul>
</blockquote>
<h4 id="predict-on-batch"><a href="#predict-on-batch" class="headerlink" title="predict_on_batch"></a>predict_on_batch</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">predict_on_batch(x)</div>
</pre></td></tr></table></figure>
<h4 id="fit-generator"><a href="#fit-generator" class="headerlink" title="fit_generator"></a>fit_generator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">fit_generator(generator, steps_per_epoch=<span class="keyword">None</span>, epochs=<span class="number">1</span>, verbose=<span class="number">1</span>, callbacks=<span class="keyword">None</span>, validation_data=<span class="keyword">None</span>, validation_steps=<span class="keyword">None</span>, validation_freq=<span class="number">1</span>, class_weight=<span class="keyword">None</span>, max_queue_size=<span class="number">10</span>, workers=<span class="number">1</span>, use_multiprocessing=<span class="keyword">False</span>, shuffle=<span class="keyword">True</span>, initial_epoch=<span class="number">0</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<ul>
<li><p>Return a <code>History</code> object. Its <code>History.history</code> attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).</p>
</li>
<li><p><strong>generator</strong>: A generator or an instance of <code>Sequence</code> (<code>keras.utils.Sequence</code>) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either</p>
<ul>
<li>a tuple <code>(inputs, targets)</code></li>
<li>a tuple <code>(inputs, targets, sample_weights)</code>.</li>
</ul>
<p>This tuple (a single output of the generator) makes a single batch. Therefore, all arrays in this tuple must have the same length (equal to the size of this batch). Different batches may have different sizes. For example, the last batch of the epoch is commonly smaller than the others, if the size of the dataset is not divisible by the batch size. The generator is expected to loop over its data indefinitely. An epoch finishes when <code>steps_per_epoch</code> batches have been seen by the model.</p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_arrays_from_file</span><span class="params">(path)</span>:</span></div>
<div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div>
<div class="line">        <span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</div>
<div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</div>
<div class="line">                <span class="comment"># create numpy arrays of input data</span></div>
<div class="line">                <span class="comment"># and labels, from each line in the file</span></div>
<div class="line">                x1, x2, y = process_line(line)</div>
<div class="line">                <span class="keyword">yield</span> (&#123;<span class="string">'input_1'</span>: x1, <span class="string">'input_2'</span>: x2&#125;, &#123;<span class="string">'output'</span>: y&#125;)</div>
<div class="line"></div>
<div class="line">model.fit_generator(generate_arrays_from_file(<span class="string">'/my_file.txt'</span>),</div>
<div class="line">                    steps_per_epoch=<span class="number">10000</span>, epochs=<span class="number">10</span>)</div>
</pre></td></tr></table></figure>
<h4 id="evaluate-generator"><a href="#evaluate-generator" class="headerlink" title="evaluate_generator"></a>evaluate_generator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">evaluate_generator(generator, steps=<span class="keyword">None</span>, callbacks=<span class="keyword">None</span>, max_queue_size=<span class="number">10</span>, workers=<span class="number">1</span>, use_multiprocessing=<span class="keyword">False</span>, verbose=<span class="number">0</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<p>Evaluates the model on a data generator.</p>
<p>Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code>model.metrics_names</code> will give you the display labels for the scalar outputs.</p>
</blockquote>
<h4 id="predict-generator"><a href="#predict-generator" class="headerlink" title="predict_generator"></a>predict_generator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">predict_generator(generator, steps=<span class="keyword">None</span>, callbacks=<span class="keyword">None</span>, max_queue_size=<span class="number">10</span>, workers=<span class="number">1</span>, use_multiprocessing=<span class="keyword">False</span>, verbose=<span class="number">0</span>)</div>
</pre></td></tr></table></figure>
<h4 id="get-layer"><a href="#get-layer" class="headerlink" title="get_layer"></a>get_layer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">get_layer(name=<span class="keyword">None</span>, index=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<blockquote>
<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.</p>
<p>Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p>Return a layer instance.</p>
</blockquote>
<h1 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h1><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><h3 id="Get-weights"><a href="#Get-weights" class="headerlink" title="Get weights"></a>Get weights</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">layer.get_weights()</div>
<div class="line">layer.set_weights(weights)</div>
<div class="line">layer.get_config():returns a dictionary containing the configuration of the layer.</div>
</pre></td></tr></table></figure>
<h3 id="Get-input-output-shape"><a href="#Get-input-output-shape" class="headerlink" title="Get input/output/shape"></a>Get input/output/shape</h3><p>Whenever you are calling a layer on some input, you are creating a new tensor (the output of the layer), and you are adding a “node” to the layer, linking the input tensor to the output tensor. When you are calling the same layer multiple times, that layer owns multiple nodes indexed as 0, 1, 2…</p>
<p>In previous versions of Keras, you could obtain the output tensor of a layer instance via <code>layer.get_output()</code>, or its output shape via <code>layer.output_shape</code>. You still can (except <code>get_output()</code> has been replaced by the property <code>output</code>). But what if a layer is connected to multiple inputs?</p>
<p>As long as a layer is only connected to one input, there is no confusion, and <code>.output</code> will return the one output of the layer:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">lstm = LSTM(<span class="number">32</span>)</div>
<div class="line">encoded_a = lstm(a)</div>
<div class="line"><span class="keyword">assert</span> lstm.output == encoded_a</div>
</pre></td></tr></table></figure>
<p>If we have multiple inputs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">b = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</div>
<div class="line">lstm = LSTM(<span class="number">32</span>)</div>
<div class="line">encoded_a = lstm(a)</div>
<div class="line">encoded_b = lstm(b)</div>
<div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">0</span>) == encoded_a</div>
<div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">1</span>) == encoded_b</div>
</pre></td></tr></table></figure>
<p>The same is true for the properties <code>input_shape</code> and <code>output_shape</code>: as long as the layer has only one node, or as long as all nodes have the same input/output shape, then the notion of “layer output/input shape” is well defined, and that one shape will be returned by <code>layer.output_shape</code>/<code>layer.input_shape</code>. But if, for instance, you apply the same <code>Conv2D</code> layer to an input of shape <code>(32, 32, 3)</code>, and then to an input of shape <code>(64, 64, 3)</code>, the layer will have multiple input/output shapes, and you will have to fetch them by specifying the index of the node they belong to:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</div>
<div class="line">b = Input(shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</div>
<div class="line">conv = Conv2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>)</div>
<div class="line">conved_a = conv(a)</div>
<div class="line"><span class="comment"># Only one input so far, the following will work:</span></div>
<div class="line"><span class="keyword">assert</span> conv.input_shape == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line">conved_b = conv(b)</div>
<div class="line"><span class="comment"># now the `.input_shape` property wouldn't work, but this does:</span></div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">0</span>) == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">1</span>) == (<span class="keyword">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</div>
</pre></td></tr></table></figure>
<h3 id="Obtain-output-of-an-intermediate-layer"><a href="#Obtain-output-of-an-intermediate-layer" class="headerlink" title="Obtain output of an intermediate layer"></a>Obtain output of an intermediate layer</h3><p>There are two ways to do it. The first one is to create a new model that outputs the layers we want.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line">complete_model = Model() <span class="comment">#create the original model</span></div>
<div class="line">layer_name = <span class="string">'my_layer'</span></div>
<div class="line">intermediate_layer_model = Model(inputs=complete_model.input,outputs=model.get_layer(layer_name).output)</div>
<div class="line">intermediate_output = intermediate_layer_model.predict(data)</div>
</pre></td></tr></table></figure>
<p>Alternatively, we can build a Keras function that will return the output of a certain layer given a certain input, for example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"><span class="comment"># with a Sequential model</span></div>
<div class="line">get_3rd_layer_output = K.function([model.layers[<span class="number">0</span>].input],</div>
<div class="line">                                  [model.layers[<span class="number">3</span>].output])</div>
<div class="line">layer_output = get_3rd_layer_output([x])[<span class="number">0</span>]</div>
</pre></td></tr></table></figure>
<h2 id="Core-Layers"><a href="#Core-Layers" class="headerlink" title="Core Layers"></a>Core Layers</h2><h3 id="Dense"><a href="#Dense" class="headerlink" title="Dense()"></a>Dense()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Dense(units, activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>It implements the fully-connected multiplication operation: <code>output=activation(dot(input,kernel)+bias)</code>, where <code>activation</code> is the element-wise activation function passed as the <code>activation</code> argument, <code>kernel</code>is a weights matrix and <code>bias</code> is a bias vector.</li>
<li>The input’s shape should be like <code>(batch_size,dim)</code>, otherwise, use <code>Flatten()</code> layer to reshape the input.</li>
<li>The output shape is <code>(batch_size,units)</code></li>
</ul>
<h3 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten()"></a>Flatten()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Flatten()</div>
</pre></td></tr></table></figure>
<ul>
<li>Flattens the input. Does not affect the batch size.</li>
</ul>
<h3 id="Input"><a href="#Input" class="headerlink" title="Input()"></a>Input()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">Input(shape=())</div>
</pre></td></tr></table></figure>
<ul>
<li>It is used to instantiate a Keras tensor.</li>
<li><strong>shape</strong>: A shape tuple (integer), not including the batch size. For instance, <code>shape=(32,)</code> indicates that the expected input will be batches of 32-dimensional vectors.</li>
</ul>
<h3 id="Reshape"><a href="#Reshape" class="headerlink" title="Reshape()"></a>Reshape()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Reshape(target_shape)</div>
</pre></td></tr></table></figure>
<ul>
<li><strong>target_shape</strong>: target shape. Tuple of integers. Does not include the batch axis. Support shape inference using <code>-1</code> as dimension.</li>
<li>The shape of output is like <code>(batch_size,)+target_shape</code></li>
</ul>
<h3 id="Permute"><a href="#Permute" class="headerlink" title="Permute()"></a>Permute()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Permute(dims)</div>
</pre></td></tr></table></figure>
<ul>
<li>Permutes the dimensions of the input according to a given pattern.</li>
</ul>
<h3 id="RepeatVector"><a href="#RepeatVector" class="headerlink" title="RepeatVector()"></a>RepeatVector()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.RepeatVector(n)</div>
</pre></td></tr></table></figure>
<ul>
<li>Repeats the input n times. Input: 2D tensor of shape <code>(num_samples, features)</code>. output shape: 3D tensor of shape <code>(num_samples, n, features)</code>.</li>
</ul>
<h3 id="Conv2D"><a href="#Conv2D" class="headerlink" title="Conv2D()"></a>Conv2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Conv2D(filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>, dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>2D convolution layer (e.g. spatial convolution over images). </li>
<li>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.</li>
</ul>
<h3 id="Conv2DTranspose"><a href="#Conv2DTranspose" class="headerlink" title="Conv2DTranspose()"></a>Conv2DTranspose()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.Conv2DTranspose(filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, output_padding=<span class="keyword">None</span>, data_format=<span class="keyword">None</span>, dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>Transposed convolution layer (sometimes called Deconvolution).</li>
</ul>
<h3 id="UpSampling2D"><a href="#UpSampling2D" class="headerlink" title="UpSampling2D()"></a>UpSampling2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.UpSampling2D(size=(<span class="number">2</span>, <span class="number">2</span>), data_format=<span class="keyword">None</span>, interpolation=<span class="string">'nearest'</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>Repeats the rows and columns of the data by size[0] and size[1] respectively.</li>
<li>input shape <code>(batch_size,rows,cols,channels)</code>, </li>
</ul>
<h3 id="ZeroPadding2D"><a href="#ZeroPadding2D" class="headerlink" title="ZeroPadding2D()"></a>ZeroPadding2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>), data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.</li>
</ul>
<h3 id="MaxPooling2D"><a href="#MaxPooling2D" class="headerlink" title="MaxPooling2D()"></a>MaxPooling2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>If None, it will default to <code>pool_size</code>.</li>
<li>input shape <code>(batch_size, rows, cols, channels)</code>, output shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code></li>
</ul>
<h3 id="AveragePooling2D"><a href="#AveragePooling2D" class="headerlink" title="AveragePooling2D()"></a>AveragePooling2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>input shape <code>(batch_size, rows, cols, channels)</code>, output shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code></li>
</ul>
<h3 id="GlobalMaxPooling2D"><a href="#GlobalMaxPooling2D" class="headerlink" title="GlobalMaxPooling2D()"></a>GlobalMaxPooling2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.GlobalMaxPooling2D(data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>input shape <code>(batch_size, rows, cols, channels)</code>, output shape <code>(batch_size,  channels)</code></li>
</ul>
<h3 id="GlobalAveragePooling2D"><a href="#GlobalAveragePooling2D" class="headerlink" title="GlobalAveragePooling2D()"></a>GlobalAveragePooling2D()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.GlobalAveragePooling2D(data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>input shape <code>(batch_size, rows, cols, channels)</code>, output shape <code>(batch_size,  channels)</code></li>
</ul>
<h1 id="ImageProcessing"><a href="#ImageProcessing" class="headerlink" title="ImageProcessing"></a>ImageProcessing</h1><h2 id="ImageDataGenerator-class"><a href="#ImageDataGenerator-class" class="headerlink" title="ImageDataGenerator class"></a>ImageDataGenerator class</h2><p>In order to make the most of training datasets, somethimes we need to augment the training dataset via a number of random transformations, so that our model can never see the exact same pictures but at the same time we can expand our trianing dataset. This helps prevent overfitting and helps the model generalize better.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.preprocessing.image.ImageDataGenerator(featurewise_center=<span class="keyword">False</span>, samplewise_center=<span class="keyword">False</span>, featurewise_std_normalization=<span class="keyword">False</span>, samplewise_std_normalization=<span class="keyword">False</span>, zca_whitening=<span class="keyword">False</span>, zca_epsilon=<span class="number">1e-06</span>, rotation_range=<span class="number">0</span>, width_shift_range=<span class="number">0.0</span>, height_shift_range=<span class="number">0.0</span>, brightness_range=<span class="keyword">None</span>, shear_range=<span class="number">0.0</span>, zoom_range=<span class="number">0.0</span>, channel_shift_range=<span class="number">0.0</span>, fill_mode=<span class="string">'nearest'</span>, cval=<span class="number">0.0</span>, horizontal_flip=<span class="keyword">False</span>, vertical_flip=<span class="keyword">False</span>, rescale=<span class="keyword">None</span>, preprocessing_function=<span class="keyword">None</span>, data_format=<span class="keyword">None</span>, validation_split=<span class="number">0.0</span>, dtype=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p>In Keras this can be done via the <code>keras.preprocessing.image.ImageDataGenerator</code> class. This class allows you to:</p>
<ol>
<li>configure random transformations and normalization operations to be done on your image data during training</li>
<li>instantiate generators of augmented image batches (and their labels) via <code>.flow(data, labels)</code> or <code>.flow_from_directory(directory)</code>. These generators can then be used with the Keras model methods that accept data generators as inputs, <code>fit_generator</code>, <code>evaluate_generator</code> and <code>predict_generator</code>.</li>
</ol>
<p>Let’s go over these parameters quickly by performing these operations on an image.</p>
<ul>
<li><p><code>rotation_range</code> is a value in degrees (0-180), a range within which to randomly rotate pictures.</p>
<p><img src="/2018/07/23/Keras/cat_0_5151.jpg" alt="at_0_515">  ==========   <img src="/2018/07/23/Keras/cat_0_9819.jpg" alt="at_0_981"></p>
</li>
<li><p><code>width_shift_range</code> Float, 1-D array-like or int</p>
<p><img src="/2018/07/23/Keras/cat_0_3682.jpg" alt="at_0_368">  ==========      <img src="/2018/07/23/Keras/cat_0_2380.jpg" alt="at_0_238"></p>
</li>
</ul>
<ul>
<li><p><code>height_shift_range</code> </p>
<p><img src="/2018/07/23/Keras/cat_0_3682-4504351.jpg" alt="at_0_3682-450435">   ==========    <img src="/2018/07/23/Keras/cat_0_4790.jpg" alt="at_0_479"></p>
</li>
<li><p><code>shear_range</code>: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)</p>
<p><img src="/2018/07/23/Keras/cat_0_3682-4504721.jpg" alt="at_0_3682-450472">    ===========    <img src="/2018/07/23/Keras/cat_0_8162.jpg" alt="at_0_816"></p>
</li>
<li><p><code>zoom_range</code>: Float or [lower, upper]. Range for random zoom. If a float, <code>[lower, upper] = [1-zoom_range, 1+zoom_range]</code></p>
<p><img src="/2018/07/23/Keras/cat_0_3682-4504809.jpg" alt="at_0_3682-450480">     =========== <img src="/2018/07/23/Keras/cat_0_1571.jpg" alt="at_0_157"></p>
</li>
</ul>
<ul>
<li><p><code>**horizontal_flip**</code> Boolean. Randomly flip inputs horizontally.<img src="/2018/07/23/Keras/cat_0_3682-4504439.jpg" alt="at_0_3682-450443">    ==========  <img src="/2018/07/23/Keras/cat_0_9447.jpg" alt="at_0_944"></p>
</li>
<li><p><code>vertical_flip</code> Boolean. Randomly flip inputs vertically.</p>
<p><img src="/2018/07/23/Keras/cat_0_3021.jpg" alt="at_0_302">      =========     <img src="/2018/07/23/Keras/cat_0_6028.jpg" alt="at_0_602"></p>
</li>
<li><p><code>fill_mode</code> is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.</p>
<p>​</p>
</li>
</ul>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator, array_to_img, img_to_array, load_img</div>
<div class="line"><span class="keyword">import</span> cv2</div>
<div class="line">datagen = ImageDataGenerator(</div>
<div class="line">    <span class="comment"># featurewise_center=True,</span></div>
<div class="line">    <span class="comment"># featurewise_std_normalization=False,</span></div>
<div class="line">    <span class="comment"># zca_whitening=True,</span></div>
<div class="line">    <span class="comment"># zca_epsilon=1,</span></div>
<div class="line">    <span class="comment"># rotation_range=100,</span></div>
<div class="line">    <span class="comment"># width_shift_range=220.0,</span></div>
<div class="line">    <span class="comment"># height_shift_range=100.0,</span></div>
<div class="line">    <span class="comment"># brightness_range=None,</span></div>
<div class="line">    <span class="comment"># shear_range=0.0,</span></div>
<div class="line">    <span class="comment"># zoom_range=0.0,</span></div>
<div class="line">    <span class="comment"># channel_shift_range=0.0,</span></div>
<div class="line">    <span class="comment"># fill_mode='nearest',</span></div>
<div class="line">    <span class="comment"># cval=0.0,</span></div>
<div class="line">    <span class="comment"># horizontal_flip=True,</span></div>
<div class="line">    vertical_flip=<span class="keyword">True</span>,</div>
<div class="line">    <span class="comment"># rescale=None,</span></div>
<div class="line">    <span class="comment"># preprocessing_function=None,</span></div>
<div class="line">    <span class="comment"># data_format=None,</span></div>
<div class="line">    <span class="comment"># validation_split=0.0,</span></div>
<div class="line">    dtype=<span class="keyword">None</span>)</div>
<div class="line"></div>
<div class="line">img = load_img(<span class="string">'example.jpg'</span>)  <span class="comment"># this is a PIL image</span></div>
<div class="line">img = img.resize((<span class="number">224</span>,<span class="number">224</span>))</div>
<div class="line">x = img_to_array(img)  <span class="comment"># this is a Numpy array with shape (3, 150, 150)</span></div>
<div class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)  <span class="comment"># this is a Numpy array with shape (1, 3, 150, 150)</span></div>
<div class="line"></div>
<div class="line"><span class="comment"># the .flow() command below generates batches of randomly transformed images</span></div>
<div class="line"><span class="comment"># and saves the results to the `preview/` directory</span></div>
<div class="line">i = <span class="number">0</span></div>
<div class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>,</div>
<div class="line">                          save_to_dir=<span class="string">'preview'</span>, save_prefix=<span class="string">'cat'</span>, save_format=<span class="string">'jpg'</span>):</div>
<div class="line">    i += <span class="number">1</span></div>
<div class="line">    <span class="keyword">if</span> i &gt; <span class="number">1</span>:</div>
<div class="line">        <span class="keyword">break</span>  <span class="comment"># otherwise the generator would loop indefinitely</span></div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h2><h3 id="apply-transform"><a href="#apply-transform" class="headerlink" title="apply_transform"></a>apply_transform</h3><h3 id="fit-1"><a href="#fit-1" class="headerlink" title="fit"></a>fit</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">fit(x,augment=<span class="keyword">False</span>,rounds=<span class="number">1</span>,seed=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p>Once we create the ImageDataGenerator and define the data augment parameters, we can use <code>fit</code> to augment the existing training dataset.</p>
<ul>
<li><strong>x</strong>: Sample data. Should have rank 4, i.e., <code>shape=(sample_num, height, width, channel)</code>. In case of grayscale data, the channels axis should have value 1, in case of RGB data, it should have value 3, and in case of RGBA data, it should have value 4. </li>
</ul>
<h3 id="flow"><a href="#flow" class="headerlink" title="flow"></a>flow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">flow(x, y=<span class="keyword">None</span>, batch_size=<span class="number">32</span>, shuffle=<span class="keyword">True</span>, sample_weight=<span class="keyword">None</span>, seed=<span class="keyword">None</span>, save_to_dir=<span class="keyword">None</span>, save_prefix=<span class="string">''</span>, save_format=<span class="string">'png'</span>, subset=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p>Takes data &amp; label arrays, generates batches of augmented data.</p>
<ul>
<li><strong>x</strong>: Input data. Numpy array of rank 4 or a tuple. If tuple, the first element should contain the images and the second element another numpy array or a list of numpy arrays that gets passed to the output without any modifications. Can be used to feed the model miscellaneous data along with the images. In case of grayscale data, the channels axis of the image array should have value 1, in case of RGB data, it should have value 3, and in case of RGBA data, it should have value 4.</li>
<li><strong>y</strong>: Labels.</li>
<li><strong>batch_size</strong>: Int (default: 32).</li>
<li><strong>shuffle</strong>: Boolean (default: True).</li>
<li><strong>sample_weight</strong>: Sample weights.</li>
<li><strong>seed</strong>: Int (default: None).</li>
<li><strong>save_to_dir</strong>: None or str (default: None). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).</li>
<li><strong>save_prefix</strong>: Str (default: <code>&#39;&#39;</code>). Prefix to use for filenames of saved pictures (only relevant if <code>save_to_dir</code> is set).</li>
<li><strong>save_format</strong>: one of “png”, “jpeg” (only relevant if <code>save_to_dir</code> is set). Default: “png”.</li>
<li><strong>subset</strong>: Subset of data (<code>&quot;training&quot;</code> or <code>&quot;validation&quot;</code>) if <code>validation_split</code> is set in <code>ImageDataGenerator</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p>An <code>Iterator</code> yielding tuples of <code>(x, y)</code> where <code>x</code> is a numpy array of image data (in the case of a single image input) or a list of numpy arrays (in the case with additional inputs) and <code>y</code> is a numpy array of corresponding labels. If ‘sample_weight’ is not None, the yielded tuples are of the form <code>(x, y, sample_weight)</code>. If <code>y</code> is None, only the numpy array <code>x</code> is returned.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
</pre></td><td class="code"><pre><div class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</div>
<div class="line">y_train = np_utils.to_categorical(y_train, num_classes)</div>
<div class="line">y_test = np_utils.to_categorical(y_test, num_classes)</div>
<div class="line"></div>
<div class="line">datagen = ImageDataGenerator(</div>
<div class="line">    featurewise_center=<span class="keyword">True</span>,</div>
<div class="line">    featurewise_std_normalization=<span class="keyword">True</span>,</div>
<div class="line">    rotation_range=<span class="number">20</span>,</div>
<div class="line">    width_shift_range=<span class="number">0.2</span>,</div>
<div class="line">    height_shift_range=<span class="number">0.2</span>,</div>
<div class="line">    horizontal_flip=<span class="keyword">True</span>)</div>
<div class="line"></div>
<div class="line"><span class="comment"># compute quantities required for featurewise normalization</span></div>
<div class="line"><span class="comment"># (std, mean, and principal components if ZCA whitening is applied)</span></div>
<div class="line">datagen.fit(x_train)</div>
<div class="line"></div>
<div class="line"><span class="comment"># fits the model on batches with real-time data augmentation:</span></div>
<div class="line">model.fit_generator(datagen.flow(x_train, y_train, batch_size=<span class="number">32</span>),</div>
<div class="line">                    steps_per_epoch=len(x_train) / <span class="number">32</span>, epochs=epochs)</div>
<div class="line"></div>
<div class="line"><span class="comment"># here's a more "manual" example</span></div>
<div class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</div>
<div class="line">    print(<span class="string">'Epoch'</span>, e)</div>
<div class="line">    batches = <span class="number">0</span></div>
<div class="line">    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> datagen.flow(x_train, y_train, batch_size=<span class="number">32</span>):</div>
<div class="line">        model.fit(x_batch, y_batch)</div>
<div class="line">        batches += <span class="number">1</span></div>
<div class="line">        <span class="keyword">if</span> batches &gt;= len(x_train) / <span class="number">32</span>:</div>
<div class="line">            <span class="comment"># we need to break the loop by hand because</span></div>
<div class="line">            <span class="comment"># the generator loops indefinitely</span></div>
<div class="line">            <span class="keyword">break</span></div>
</pre></td></tr></table></figure>
<h3 id="flow-from-directory"><a href="#flow-from-directory" class="headerlink" title="flow_from_directory"></a>flow_from_directory</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">flow_from_directory(directory, target_size=(<span class="number">256</span>, <span class="number">256</span>), color_mode=<span class="string">'rgb'</span>, classes=<span class="keyword">None</span>, class_mode=<span class="string">'categorical'</span>, batch_size=<span class="number">32</span>, shuffle=<span class="keyword">True</span>, seed=<span class="keyword">None</span>, save_to_dir=<span class="keyword">None</span>, save_prefix=<span class="string">''</span>, save_format=<span class="string">'png'</span>, follow_links=<span class="keyword">False</span>, subset=<span class="keyword">None</span>, interpolation=<span class="string">'nearest'</span>)</div>
</pre></td></tr></table></figure>
<p>Takes the path to a directory &amp; generates batches of augmented data.</p>
<ul>
<li><p><strong>directory</strong>: string, path to the target directory. It should contain one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator. See <a href="https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d" target="_blank" rel="noopener">this script</a> for more details.</p>
</li>
<li><p><strong>target_size</strong>: Tuple of integers <code>(height, width)</code>, default: <code>(256, 256)</code>. The dimensions to which all images found will be resized.</p>
</li>
<li><p><strong>color_mode</strong>: One of “grayscale”, “rgb”, “rgba”. Default: “rgb”. Whether the images will be converted to have 1, 3, or 4 channels.</p>
</li>
<li><p><strong>classes</strong>: Optional list of class subdirectories (e.g. <code>[&#39;dogs&#39;, &#39;cats&#39;]</code>). Default: None. If not provided, the list of classes will be automatically inferred from the subdirectory names/structure under <code>directory</code>, where each subdirectory will be treated as a different class (and the order of the classes, which will map to the label indices, will be alphanumeric). The dictionary containing the mapping from class names to class indices can be obtained via the attribute <code>class_indices</code>.</p>
</li>
<li><p>class_mode</p>
<p>: One of “categorical”, “binary”, “sparse”, “input”, or None. Default: “categorical”. Determines the type of label arrays that are returned:</p>
<ul>
<li>“categorical” will be 2D one-hot encoded labels,</li>
<li>“binary” will be 1D binary labels, “sparse” will be 1D integer labels,</li>
<li>“input” will be images identical to input images (mainly used to work with autoencoders).</li>
<li>If None, no labels are returned (the generator will only yield batches of image data, which is useful to use with <code>model.predict_generator()</code>). Please note that in case of class_mode None, the data still needs to reside in a subdirectory of <code>directory</code> for it to work correctly.</li>
</ul>
</li>
<li><p><strong>batch_size</strong>: Size of the batches of data (default: 32).</p>
</li>
<li><p><strong>shuffle</strong>: Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.</p>
</li>
<li><p><strong>seed</strong>: Optional random seed for shuffling and transformations.</p>
</li>
<li><p><strong>save_to_dir</strong>: None or str (default: None). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).</p>
</li>
<li><p><strong>save_prefix</strong>: Str. Prefix to use for filenames of saved pictures (only relevant if <code>save_to_dir</code> is set).</p>
</li>
<li><p><strong>save_format</strong>: One of “png”, “jpeg” (only relevant if <code>save_to_dir</code> is set). Default: “png”.</p>
</li>
<li><p><strong>follow_links</strong>: Whether to follow symlinks inside class subdirectories (default: False).</p>
</li>
<li><p><strong>subset</strong>: Subset of data (<code>&quot;training&quot;</code> or <code>&quot;validation&quot;</code>) if <code>validation_split</code> is set in <code>ImageDataGenerator</code>.</p>
</li>
<li><p><strong>interpolation</strong>: Interpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are <code>&quot;nearest&quot;</code>, <code>&quot;bilinear&quot;</code>, and <code>&quot;bicubic&quot;</code>. If PIL version 1.1.3 or newer is installed, <code>&quot;lanczos&quot;</code> is also supported. If PIL version 3.4.0 or newer is installed, <code>&quot;box&quot;</code> and <code>&quot;hamming&quot;</code> are also supported. By default, <code>&quot;nearest&quot;</code> is used.</p>
</li>
</ul>
<p><strong>RETURN</strong></p>
<p>A <code>DirectoryIterator</code> yielding tuples of <code>(x, y)</code> where <code>x</code> is a numpy array containing a batch of images with shape <code>(batch_size, *target_size, channels)</code> and <code>y</code> is a numpy array of corresponding labels.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
</pre></td><td class="code"><pre><div class="line">train_datagen = ImageDataGenerator(</div>
<div class="line">        rescale=<span class="number">1.</span>/<span class="number">255</span>,</div>
<div class="line">        shear_range=<span class="number">0.2</span>,</div>
<div class="line">        zoom_range=<span class="number">0.2</span>,</div>
<div class="line">        horizontal_flip=<span class="keyword">True</span>)</div>
<div class="line"></div>
<div class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</div>
<div class="line"></div>
<div class="line">train_generator = train_datagen.flow_from_directory(</div>
<div class="line">        <span class="string">'data/train'</span>,</div>
<div class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</div>
<div class="line">        batch_size=<span class="number">32</span>,</div>
<div class="line">        class_mode=<span class="string">'binary'</span>)</div>
<div class="line"></div>
<div class="line">validation_generator = test_datagen.flow_from_directory(</div>
<div class="line">        <span class="string">'data/validation'</span>,</div>
<div class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</div>
<div class="line">        batch_size=<span class="number">32</span>,</div>
<div class="line">        class_mode=<span class="string">'binary'</span>)</div>
<div class="line"></div>
<div class="line">model.fit_generator(</div>
<div class="line">        train_generator,</div>
<div class="line">        steps_per_epoch=<span class="number">2000</span>,</div>
<div class="line">        epochs=<span class="number">50</span>,</div>
<div class="line">        validation_data=validation_generator,</div>
<div class="line">        validation_steps=<span class="number">800</span>)</div>
</pre></td></tr></table></figure>
<p><strong>Example of transforming images and masks together.</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># we create two instances with the same arguments</span></div>
<div class="line">data_gen_args = dict(featurewise_center=<span class="keyword">True</span>,</div>
<div class="line">                     featurewise_std_normalization=<span class="keyword">True</span>,</div>
<div class="line">                     rotation_range=<span class="number">90</span>,</div>
<div class="line">                     width_shift_range=<span class="number">0.1</span>,</div>
<div class="line">                     height_shift_range=<span class="number">0.1</span>,</div>
<div class="line">                     zoom_range=<span class="number">0.2</span>)</div>
<div class="line">image_datagen = ImageDataGenerator(**data_gen_args)</div>
<div class="line">mask_datagen = ImageDataGenerator(**data_gen_args)</div>
<div class="line"></div>
<div class="line"><span class="comment"># Provide the same seed and keyword arguments to the fit and flow methods</span></div>
<div class="line">seed = <span class="number">1</span></div>
<div class="line">image_datagen.fit(images, augment=<span class="keyword">True</span>, seed=seed)</div>
<div class="line">mask_datagen.fit(masks, augment=<span class="keyword">True</span>, seed=seed)</div>
<div class="line"></div>
<div class="line">image_generator = image_datagen.flow_from_directory(</div>
<div class="line">    <span class="string">'data/images'</span>,</div>
<div class="line">    class_mode=<span class="keyword">None</span>,</div>
<div class="line">    seed=seed)</div>
<div class="line"></div>
<div class="line">mask_generator = mask_datagen.flow_from_directory(</div>
<div class="line">    <span class="string">'data/masks'</span>,</div>
<div class="line">    class_mode=<span class="keyword">None</span>,</div>
<div class="line">    seed=seed)</div>
<div class="line"></div>
<div class="line"><span class="comment"># combine generators into one which yields image and masks</span></div>
<div class="line">train_generator = zip(image_generator, mask_generator)</div>
<div class="line"></div>
<div class="line">model.fit_generator(</div>
<div class="line">    train_generator,</div>
<div class="line">    steps_per_epoch=<span class="number">2000</span>,</div>
<div class="line">    epochs=<span class="number">50</span>)</div>
</pre></td></tr></table></figure>
<p> Since we only have few examples, our number one concern should be <strong>overfitting</strong>. Overfitting happens when a model exposed to too few examples learns patterns that do not generalize to new data, i.e. when the model starts using irrelevant features for making predictions. For instance, if you, as a human, only see three images of people who are lumberjacks, and three, images of people who are sailors, and among them only one lumberjack wears a cap, you might start thinking that wearing a cap is a sign of being a lumberjack as opposed to a sailor. You would then make a pretty lousy lumberjack/sailor classifier.</p>
<p>Data augmentation is one way to fight overfitting, but it isn’t enough since our augmented samples are still highly correlated. Your main focus for fighting overfitting should be the entropic capacity of your model —how much information your model is allowed to store. A model that can store a lot of information has the potential to be more accurate by leveraging more features, but it is also more at risk to start storing irrelevant features. Meanwhile, a model that can only store a few features will have to focus on the most significant features found in the data, and these are more likely to be truly relevant and to generalize better.</p>
<p>There are different ways to modulate entropic capacity. The main one is the choice of the number of parameters in your model, i.e. the number of layers and the size of each layer. Another way is the use of weight regularization, such as L1 or L2 regularization, which consists in forcing model weights to taker smaller values.</p>
<p>In our case we will use a very small convnet with few layers and few filters per layer, alongside data augmentation and dropout. Dropout also helps reduce overfitting, by preventing a layer from seeing twice the exact same pattern, thus acting in a way analoguous to data augmentation (you could say that both dropout and data augmentation tend to disrupt random correlations occuring in your data).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"></div>
<div class="line"></div>
</pre></td></tr></table></figure>
<h1 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h1><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><h3 id="模型保存-1"><a href="#模型保存-1" class="headerlink" title="模型保存"></a>模型保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">json_string = model.to_json()</div>
<div class="line">open(<span class="string">'model.json'</span>, <span class="string">'w'</span>).write(json_string)</div>
<div class="line">model.save_weights(<span class="string">'weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h3 id="模型载入"><a href="#模型载入" class="headerlink" title="模型载入"></a>模型载入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div>
<div class="line">model = model_from_json(open(<span class="string">'keras_modelB/model.json'</span>).read())</div>
<div class="line">model.load_weights(<span class="string">'keras_modelB/weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div>
<div class="line">model.save(<span class="string">'my_model.h5'</span>)</div>
<div class="line">model = load_model(<span class="string">'my_model.h5'</span>)</div>
</pre></td></tr></table></figure>
<h1 id="Keras-Callback"><a href="#Keras-Callback" class="headerlink" title="Keras-Callback"></a>Keras-Callback</h1><h2 id="ModelCheckpoint"><a href="#ModelCheckpoint" class="headerlink" title="ModelCheckpoint"></a><a href="https://machinelearningmastery.com/check-point-deep-learning-models-keras/" target="_blank" rel="noopener">ModelCheckpoint</a></h2><h3 id="Checkpoint-Neural-Network-Model-Improvements"><a href="#Checkpoint-Neural-Network-Model-Improvements" class="headerlink" title="Checkpoint Neural Network Model Improvements"></a>Checkpoint Neural Network Model Improvements</h3><p>Checkpoint is an approach where a snapshot of the state of the system is taken in case of system failure. If there is a problem, not all is lost. The checkpoint may be used directly, or used as the starting point for a new run, picking up where it left off. When training deep learning models, the checkpoint is the weights of the model. These weights can be used to make predictions as is, or used as the basis for ongoing training.</p>
<p>The ModelCheckpoint callback class allows you to define where to checkpoint the model weights, how the file should named and under what circumstances to make a checkpoint of the model. The API allows you to specify which metric to monitor, such as loss or accuracy on the training or validation dataset. You can specify whether to look for an improvement in maximizing or minimizing the score. Finally, the filename that you use to store the weights can include variables like the epoch number or metric. The ModelCheckpoint can then be passed to the training process when calling the fit() function on the model.</p>
<p>Note, you may need to install the <a href="http://www.h5py.org/" target="_blank" rel="noopener">h5py library</a> to output network weights in HDF5 format.</p>
<p>Checkpointing is setup to save the network weights only when there is an improvement in classification accuracy on the validation dataset (monitor=’val_acc’ and mode=’max’). The weights are stored in a file that includes the score in the filename (weights-improvement-{val_acc=.2f}.hdf5).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Checkpoint the weights when validation accuracy improves</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># checkpoint</span></div>
<div class="line">filepath=<span class="string">"weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5"</span></div>
<div class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">'val_acc'</span>, verbose=<span class="number">1</span>, save_best_only=<span class="keyword">True</span>, mode=<span class="string">'max'</span>)</div>
<div class="line">callbacks_list = [checkpoint]</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=callbacks_list, verbose=<span class="number">0</span>)</div>
</pre></td></tr></table></figure>
<p>Running the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
</pre></td><td class="code"><pre><div class="line">...</div>
<div class="line">Epoch <span class="number">00134</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00135</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00136</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00137</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00138</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00139</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00140</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.83465</span> to <span class="number">0.83858</span>, saving model to weights-improvement<span class="number">-140</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00141</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00142</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00143</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00144</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00145</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00146</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.83858</span> to <span class="number">0.84252</span>, saving model to weights-improvement<span class="number">-146</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00147</span>: val_acc did <span class="keyword">not</span> improve</div>
<div class="line">Epoch <span class="number">00148</span>: val_acc improved <span class="keyword">from</span> <span class="number">0.84252</span> to <span class="number">0.84252</span>, saving model to weights-improvement<span class="number">-148</span><span class="number">-0.84</span>.hdf5</div>
<div class="line">Epoch <span class="number">00149</span>: val_acc did <span class="keyword">not</span> improve</div>
</pre></td></tr></table></figure>
<h3 id="Loading-a-Check-Pointed-Neural-Network-Model"><a href="#Loading-a-Check-Pointed-Neural-Network-Model" class="headerlink" title="Loading a Check-Pointed Neural Network Model"></a>Loading a Check-Pointed Neural Network Model</h3><p>Now that you have seen how to checkpoint your deep learning models during training, you need to review how to load and use a checkpointed model. </p>
<p>In the example below, the model structure is known and the best weights are loaded from the previous experiment, stored in the working directory in the weights.best.hdf5 file.</p>
<p>The model is then used to make predictions on the entire dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># How to load and use weights from a checkpoint</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># load weights</span></div>
<div class="line">model.load_weights(<span class="string">"weights.best.hdf5"</span>)</div>
<div class="line"><span class="comment"># Compile model (required to make predictions)</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line">print(<span class="string">"Created model and loaded weights from file"</span>)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># estimate accuracy on whole dataset using loaded weights</span></div>
<div class="line">scores = model.evaluate(X, Y, verbose=<span class="number">0</span>)</div>
<div class="line">print(<span class="string">"%s: %.2f%%"</span> % (model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]*<span class="number">100</span>))</div>
</pre></td></tr></table></figure>
<h2 id="LearningRateScheduler"><a href="#LearningRateScheduler" class="headerlink" title="LearningRateScheduler"></a><a href="https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/" target="_blank" rel="noopener">LearningRateScheduler</a></h2><p>Adapting the learning rate for your stochastic gradient descent optimization procedure can increase performance and reduce training time. The simplest and perhaps most used adaptation of learning rate during training are techniques that reduce the learning rate over time. These have the benefit of making large changes at the beginning of the training procedure when larger learning rate values are used, and decreasing the learning rate such that a smaller rate and therefore smaller training updates are made to weights later in the training procedure.</p>
<p>Two popular and easy to use learning rate schedules are as follows:</p>
<ul>
<li>Decrease the learning rate gradually based on the epoch.</li>
<li>Decrease the learning rate using punctuated large drops at specific epochs.</li>
</ul>
<p>Next, we will look at how you can use each of these learning rate schedules in turn with Keras.</p>
<h3 id="Time-Based-Learning-Rate-Schedule"><a href="#Time-Based-Learning-Rate-Schedule" class="headerlink" title="Time-Based Learning Rate Schedule"></a>Time-Based Learning Rate Schedule</h3><p>Keras has a time-based learning rate schedule built in.</p>
<p>The stochastic gradient descent optimization algorithm implementation in the SGD class has an argument called decay. This argument is used in the time-based learning rate decay schedule equation as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">LearningRate = LearningRate * <span class="number">1</span>/(<span class="number">1</span> + decay * epoch)</div>
</pre></td></tr></table></figure>
<p>When the decay argument is zero (the default), this has no effect on the learning rate.</p>
<p>When the decay argument is specified, it will decrease the learning rate from the previous epoch by the given fixed amount.</p>
<p>For example, if we use the initial learning rate value of 0.1 and the decay of 0.001, the first 5 epochs will adapt the learning rate as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line">Epoch	Learning Rate</div>
<div class="line"><span class="number">1</span>	<span class="number">0.1</span></div>
<div class="line"><span class="number">2</span>	<span class="number">0.0999000999</span></div>
<div class="line"><span class="number">3</span>	<span class="number">0.0997006985</span></div>
<div class="line"><span class="number">4</span>	<span class="number">0.09940249103</span></div>
<div class="line"><span class="number">5</span>	<span class="number">0.09900646517</span></div>
</pre></td></tr></table></figure>
<p>Extending this out to 100 epochs will produce the following graph of learning rate (y axis) versus epoch (x axis):</p>
<p><img src="/2018/07/23/Keras/Time-Based-Learning-Rate-Schedule.png" alt="ime-Based-Learning-Rate-Schedul"></p>
<p>You can create a nice default schedule by setting the decay value as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">Decay = LearningRate / Epochs</div>
<div class="line">Decay = <span class="number">0.1</span> / <span class="number">100</span></div>
<div class="line">Decay = <span class="number">0.001</span></div>
</pre></td></tr></table></figure>
<p>The example below demonstrates using the time-based learning rate adaptation schedule in Keras. The learning rate for stochastic gradient descent has been set to a higher value of 0.1. The model is trained for 50 epochs and the decay argument has been set to 0.002, calculated as 0.1/50. Additionally, it can be a good idea to use momentum when using an adaptive learning rate. In this case we use a momentum value of 0.8.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Time Based Learning Rate Decay</span></div>
<div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div>
<div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load dataset</span></div>
<div class="line">dataframe = read_csv(<span class="string">"ionosphere.csv"</span>, header=<span class="keyword">None</span>)</div>
<div class="line">dataset = dataframe.values</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">34</span>].astype(float)</div>
<div class="line">Y = dataset[:,<span class="number">34</span>]</div>
<div class="line"><span class="comment"># encode class values as integers</span></div>
<div class="line">encoder = LabelEncoder()</div>
<div class="line">encoder.fit(Y)</div>
<div class="line">Y = encoder.transform(Y)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">34</span>, input_dim=<span class="number">34</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">epochs = <span class="number">50</span></div>
<div class="line">learning_rate = <span class="number">0.1</span></div>
<div class="line">decay_rate = learning_rate / epochs</div>
<div class="line">momentum = <span class="number">0.8</span></div>
<div class="line">sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=<span class="keyword">False</span>)</div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=sgd, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=epochs, batch_size=<span class="number">28</span>, verbose=<span class="number">2</span>)</div>
</pre></td></tr></table></figure>
<h3 id="Drop-Based-Learning-Rate-Schedule"><a href="#Drop-Based-Learning-Rate-Schedule" class="headerlink" title="Drop-Based Learning Rate Schedule"></a>Drop-Based Learning Rate Schedule</h3><p>Another popular learning rate schedule used with deep learning models is to systematically drop the learning rate at specific times during training.</p>
<p>Often this method is implemented by dropping the learning rate by half every fixed number of epochs. For example, we may have an initial learning rate of 0.1 and drop it by 0.5 every 10 epochs. The first 10 epochs of training would use a value of 0.1, in the next 10 epochs a learning rate of 0.05 would be used, and so on.</p>
<p>If we plot out the learning rates for this example out to 100 epochs you get the graph below showing learning rate (y axis) versus epoch (x axis).</p>
<p><img src="/2018/07/23/Keras/Drop-Based-Learning-Rate-Schedule-2237380.png" alt="rop-Based-Learning-Rate-Schedule-223738"></p>
<p>We can implement this in Keras using a the <a href="http://keras.io/callbacks/" target="_blank" rel="noopener">LearningRateScheduler</a> callback when fitting the model.</p>
<p>The LearningRateScheduler callback allows us to define a function to call that takes the epoch number as an argument and returns the learning rate to use in stochastic gradient descent. When used, the learning rate specified by stochastic gradient descent is ignored.</p>
<p>In the code below, we use the same example before of a single hidden layer network on the Ionosphere dataset. A new step_decay() function is defined that implements the equation:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop)</div>
</pre></td></tr></table></figure>
<p>Where InitialLearningRate is the initial learning rate such as 0.1, the DropRate is the amount that the learning rate is modified each time it is changed such as 0.5, Epoch is the current epoch number and EpochDrop is how often to change the learning rate such as 10.</p>
<p>Notice that we set the learning rate in the SGD class to 0 to clearly indicate that it is not used. Nevertheless, you can set a momentum term in SGD if you want to use momentum with this learning rate schedule.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Drop-Based Learning Rate Decay</span></div>
<div class="line"><span class="keyword">import</span> pandas</div>
<div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="keyword">import</span> math</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div>
<div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div>
<div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> LearningRateScheduler</div>
<div class="line"></div>
<div class="line"><span class="comment"># learning rate schedule</span></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_decay</span><span class="params">(epoch)</span>:</span></div>
<div class="line">	initial_lrate = <span class="number">0.1</span></div>
<div class="line">	drop = <span class="number">0.5</span></div>
<div class="line">	epochs_drop = <span class="number">10.0</span></div>
<div class="line">	lrate = initial_lrate * math.pow(drop, math.floor((<span class="number">1</span>+epoch)/epochs_drop))</div>
<div class="line">	<span class="keyword">return</span> lrate</div>
<div class="line"></div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load dataset</span></div>
<div class="line">dataframe = read_csv(<span class="string">"ionosphere.csv"</span>, header=<span class="keyword">None</span>)</div>
<div class="line">dataset = dataframe.values</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">34</span>].astype(float)</div>
<div class="line">Y = dataset[:,<span class="number">34</span>]</div>
<div class="line"><span class="comment"># encode class values as integers</span></div>
<div class="line">encoder = LabelEncoder()</div>
<div class="line">encoder.fit(Y)</div>
<div class="line">Y = encoder.transform(Y)</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">34</span>, input_dim=<span class="number">34</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">sgd = SGD(lr=<span class="number">0.0</span>, momentum=<span class="number">0.9</span>, decay=<span class="number">0.0</span>, nesterov=<span class="keyword">False</span>)</div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=sgd, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># learning schedule callback</span></div>
<div class="line">lrate = LearningRateScheduler(step_decay)</div>
<div class="line">callbacks_list = [lrate]</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">50</span>, batch_size=<span class="number">28</span>, callbacks=callbacks_list, verbose=<span class="number">2</span>)</div>
</pre></td></tr></table></figure>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a><a href="https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/" target="_blank" rel="noopener">History</a></h2><p>History callback records training metrics for each epoch. This includes the loss and the accuracy (for classification problems) as well as the loss and accuracy for the validation dataset, if one is set. The history object is returned from calls to the fit() function used to train the model. Metrics are stored in a dictionary in the history member of the object returned.</p>
<p>For example, you can list the metrics collected in a history object using the following snippet of code after a model is trained:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># list all data in history</span></div>
<div class="line">print(history.history.keys())</div>
</pre></td></tr></table></figure>
<p>For example, for a model trained on a classification problem with a validation dataset, this might produce the following listing:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">[<span class="string">'acc'</span>, <span class="string">'loss'</span>, <span class="string">'val_acc'</span>, <span class="string">'val_loss'</span>]</div>
</pre></td></tr></table></figure>
<h3 id="Visualize-Model-Training-History-in-Keras"><a href="#Visualize-Model-Training-History-in-Keras" class="headerlink" title="Visualize Model Training History in Keras"></a>Visualize Model Training History in Keras</h3><p>The example collects the history, returned from training the model and creates two charts:</p>
<ol>
<li>A plot of accuracy on the training and validation datasets over training epochs.</li>
<li>A plot of loss on the training and validation datasets over training epochs.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Visualize training history</span></div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> numpy</div>
<div class="line"><span class="comment"># fix random seed for reproducibility</span></div>
<div class="line">seed = <span class="number">7</span></div>
<div class="line">numpy.random.seed(seed)</div>
<div class="line"><span class="comment"># load pima indians dataset</span></div>
<div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div>
<div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div>
<div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div>
<div class="line">Y = dataset[:,<span class="number">8</span>]</div>
<div class="line"><span class="comment"># create model</span></div>
<div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">8</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div>
<div class="line"><span class="comment"># Compile model</span></div>
<div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># Fit the model</span></div>
<div class="line">history = model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div>
<div class="line"><span class="comment"># list all data in history</span></div>
<div class="line">print(history.history.keys())</div>
<div class="line"><span class="comment"># summarize history for accuracy</span></div>
<div class="line">plt.plot(history.history[<span class="string">'acc'</span>])</div>
<div class="line">plt.plot(history.history[<span class="string">'val_acc'</span>])</div>
<div class="line">plt.title(<span class="string">'model accuracy'</span>)</div>
<div class="line">plt.ylabel(<span class="string">'accuracy'</span>)</div>
<div class="line">plt.xlabel(<span class="string">'epoch'</span>)</div>
<div class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</div>
<div class="line">plt.show()</div>
<div class="line"><span class="comment"># summarize history for loss</span></div>
<div class="line">plt.plot(history.history[<span class="string">'loss'</span>])</div>
<div class="line">plt.plot(history.history[<span class="string">'val_loss'</span>])</div>
<div class="line">plt.title(<span class="string">'model loss'</span>)</div>
<div class="line">plt.ylabel(<span class="string">'loss'</span>)</div>
<div class="line">plt.xlabel(<span class="string">'epoch'</span>)</div>
<div class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</div>
<div class="line">plt.show()</div>
</pre></td></tr></table></figure>
<p>The plots are provided below. The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.</p>
<p>From the plot of accuracy we can see that the model could probably be trained a little more as the trend for accuracy on both datasets is still rising for the last few epochs. We can also see that the model has not yet over-learned the training dataset, showing comparable skill on both datasets.</p>
<p><img src="/2018/07/23/Keras/history_training_dataset.png" alt="istory_training_datase"></p>
<p>From the plot of loss, we can see that the model has comparable performance on both train and validation datasets (labeled test). If these parallel plots start to depart consistently, it might be a sign to stop training at an earlier epoch.</p>
<p><img src="/2018/07/23/Keras/history_validation_dataset.png" alt="istory_validation_datase"></p>
<h2 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h2><p><a href="http://www.moxleystratton.com/tensorflow-visualizing-weights/" target="_blank" rel="noopener">Visualizing Neuron Weights During Training</a> <a href="**https**://www.jianshu.com/p/25e30055d7ac">如何在使用train_on_batch时候调用tensorboard</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_tensorboard</span><span class="params">(self,generator_step, summary_writer,losses)</span>:</span></div>
<div class="line"></div>
<div class="line">        summary = tf.Summary()</div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Real Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Fake Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">3</span>]</div>
<div class="line">        value.tag = <span class="string">'Generator Loss'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] - losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_real - D_fake)'</span></div>
<div class="line"></div>
<div class="line">        value = summary.value.add()</div>
<div class="line">        value.simple_value = losses[<span class="number">1</span>] + losses[<span class="number">2</span>]</div>
<div class="line">        value.tag = <span class="string">'Critic Loss (D_fake + D_real)'</span></div>
<div class="line"></div>
<div class="line">        summary_writer.add_summary(summary, generator_step)</div>
<div class="line">        summary_writer.flush()</div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,epochs,batch_size=<span class="number">10</span>,sample_interval=<span class="number">100</span>)</span>:</span></div>
<div class="line">        summary_writer = tf.summary.FileWriter(<span class="string">'./logs/trainBoth'</span>)</div>
<div class="line">        generator_step = <span class="number">1</span></div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(range(<span class="number">1</span>, epochs + <span class="number">1</span>)):</div>
<div class="line">            <span class="keyword">for</span> e, (figure_imgs, pose_imgs) <span class="keyword">in</span> tqdm(enumerate(self.data_loader.load_batch(batch_size=batch_size))):</div>
<div class="line">                    <span class="comment"># Train the critic</span></div>
<div class="line"></div>
<div class="line">                    figure_loss_real = self.figure_critic.train_on_batch(figure_imgs, valid)</div>
<div class="line">                    figure_loss_fake = self.figure_critic.train_on_batch(gen_figure_imgs, fake)</div>
<div class="line">                    d_figure_loss = <span class="number">0.5</span> * np.add(figure_loss_real, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                print(self.figure_critic.metrics_names,d_figure_loss)</div>
<div class="line">                losses = np.empty(shape=<span class="number">1</span>)</div>
<div class="line">                losses = np.append(losses, figure_loss_real)</div>
<div class="line">                losses = np.append(losses, figure_loss_fake)</div>
<div class="line"></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line">                <span class="comment">#  Train Generator</span></div>
<div class="line">                <span class="comment"># ---------------------</span></div>
<div class="line"></div>
<div class="line">                figure_loss = self.figure_EN.train_on_batch([figure_noise,pose_imgs],valid)</div>
<div class="line">                print(self.figure_EN.metrics_names,figure_loss)</div>
<div class="line">                losses = np.append(losses, figure_loss)</div>
<div class="line">                self.write_to_tensorboard(generator_step, summary_writer, losses)</div>
<div class="line">                generator_step += <span class="number">1</span></div>
</pre></td></tr></table></figure>
<h3 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
<div class="line">78</div>
<div class="line">79</div>
<div class="line">80</div>
<div class="line">81</div>
</pre></td><td class="code"><pre><div class="line"></div>
<div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div>
<div class="line"></div>
<div class="line">SUMMARY_DIR = <span class="string">"./graph"</span></div>
<div class="line">BATCH_SIZE = <span class="number">100</span></div>
<div class="line">TRAIN_STEPS = <span class="number">3000</span></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span><span class="params">(var, name)</span>:</span></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</div>
<div class="line">        tf.summary.histogram(name, var)</div>
<div class="line">        mean = tf.reduce_mean(var)</div>
<div class="line">        tf.summary.scalar(<span class="string">'mean/'</span> + name, mean)</div>
<div class="line">        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</div>
<div class="line">        tf.summary.scalar(<span class="string">'stddev/'</span> + name, stddev)</div>
<div class="line"></div>
<div class="line"><span class="comment"># 2. 生成一层全链接的神经网络</span></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_layer</span><span class="params">(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu)</span>:</span></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'weights'</span>):</div>
<div class="line">            weights = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=<span class="number">0.1</span>))</div>
<div class="line">            variable_summaries(weights, layer_name + <span class="string">'/weights'</span>)</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'biases'</span>):</div>
<div class="line">            biases = tf.Variable(tf.constant(<span class="number">0.0</span>, shape=[output_dim]))</div>
<div class="line">            variable_summaries(biases, layer_name + <span class="string">'/biases'</span>)</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'Wx_plus_b'</span>):</div>
<div class="line">            preactivate = tf.matmul(input_tensor, weights) + biases</div>
<div class="line">            tf.summary.histogram(layer_name + <span class="string">'/pre_activations'</span>, preactivate)</div>
<div class="line">        activations = act(preactivate, name=<span class="string">'activation'</span>)</div>
<div class="line"></div>
<div class="line">        <span class="comment"># 记录神经网络节点输出在经过激活函数之后的分布。</span></div>
<div class="line">        tf.summary.histogram(layer_name + <span class="string">'/activations'</span>, activations)</div>
<div class="line">        <span class="keyword">return</span> activations</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div>
<div class="line">    mnist = input_data.read_data_sets(<span class="string">"D:\pyprogram"</span>, one_hot=<span class="keyword">True</span>)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</div>
<div class="line">        x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>], name=<span class="string">'x-input'</span>)</div>
<div class="line">        y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>], name=<span class="string">'y-input'</span>)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'input_reshape'</span>):</div>
<div class="line">        image_shaped_input = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</div>
<div class="line">        tf.summary.image(<span class="string">'input'</span>, image_shaped_input, <span class="number">10</span>)</div>
<div class="line"></div>
<div class="line">    hidden1 = nn_layer(x, <span class="number">784</span>, <span class="number">500</span>, <span class="string">'layer1'</span>)</div>
<div class="line">    y = nn_layer(hidden1, <span class="number">500</span>, <span class="number">10</span>, <span class="string">'layer2'</span>, act=tf.identity)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'cross_entropy'</span>):</div>
<div class="line">        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))</div>
<div class="line">        tf.summary.scalar(<span class="string">'cross_entropy'</span>, cross_entropy)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</div>
<div class="line">        train_step = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cross_entropy)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'correct_prediction'</span>):</div>
<div class="line">            correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div>
<div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</div>
<div class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div>
<div class="line">        tf.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div>
<div class="line"></div>
<div class="line">    merged = tf.summary.merge_all()</div>
<div class="line"></div>
<div class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div>
<div class="line">        summary_writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)</div>
<div class="line">        tf.global_variables_initializer().run()</div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(TRAIN_STEPS):</div>
<div class="line">            xs, ys = mnist.train.next_batch(BATCH_SIZE)</div>
<div class="line">            <span class="comment"># 运行训练步骤以及所有的日志生成操作，得到这次运行的日志。</span></div>
<div class="line">            summary, _ = sess.run([merged, train_step], feed_dict=&#123;x: xs, y_: ys&#125;)</div>
<div class="line">            <span class="comment"># 将得到的所有日志写入日志文件，这样TensorBoard程序就可以拿到这次运行所对应的</span></div>
<div class="line">            <span class="comment"># 运行信息。</span></div>
<div class="line">            summary_writer.add_summary(summary, i)</div>
<div class="line"></div>
<div class="line">    summary_writer.close()</div>
<div class="line"></div>
<div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div>
<div class="line">    main()</div>
</pre></td></tr></table></figure>
<p><img src="/2018/07/23/Keras/Screen Shot 2019-03-13 at 10.25.34 PM.png" alt="creen Shot 2019-03-13 at 10.25.34 P"></p>
<h1 id="Customerize-Optimizer"><a href="#Customerize-Optimizer" class="headerlink" title="Customerize Optimizer"></a>Customerize Optimizer</h1><p>The following example is an example of modifing the implementation of Adam optimizer, so that it can support differential privacy.</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Optimizer</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_norm</span><span class="params">(g, c, n)</span>:</span></div>
<div class="line">    <span class="keyword">if</span> c &gt; <span class="number">0</span>:</div>
<div class="line">        g = K.switch(n &gt;= c, g * c / n, g)</div>
<div class="line">    <span class="keyword">return</span> g</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoisyAdam</span><span class="params">(Optimizer)</span>:</span></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>,</span></span></div>
<div class="line"><span class="function"><span class="params">                 epsilon=<span class="number">1e-8</span>, decay=<span class="number">0.</span>, noise=<span class="number">0.</span>, **kwargs)</span>:</span></div>
<div class="line">        super(NoisyAdam, self).__init__(**kwargs)</div>
<div class="line">        self.iterations = K.variable(<span class="number">0</span>, name=<span class="string">'iterations'</span>)</div>
<div class="line">        self.lr = K.variable(lr, name=<span class="string">'lr'</span>)</div>
<div class="line">        self.beta_1 = K.variable(beta_1, name=<span class="string">'beta_1'</span>)</div>
<div class="line">        self.beta_2 = K.variable(beta_2, name=<span class="string">'beta_2'</span>)</div>
<div class="line">        self.epsilon = epsilon</div>
<div class="line">        self.decay = K.variable(decay, name=<span class="string">'decay'</span>)</div>
<div class="line">        self.initial_decay = decay</div>
<div class="line">        self.noise = noise</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_gradients</span><span class="params">(self, loss, params)</span>:</span></div>
<div class="line">        grads = K.gradients(loss, params)</div>
<div class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'clipnorm'</span>) <span class="keyword">and</span> self.clipnorm &gt; <span class="number">0</span>:</div>
<div class="line">            norm = K.sqrt(sum([K.sum(K.square(g)) <span class="keyword">for</span> g <span class="keyword">in</span> grads]))</div>
<div class="line">            grads = [clip_norm(g, self.clipnorm, norm) <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'clipvalue'</span>) <span class="keyword">and</span> self.clipvalue &gt; <span class="number">0</span>:</div>
<div class="line">            grads = [K.clip(g, -self.clipvalue, self.clipvalue) <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line"></div>
<div class="line">        <span class="keyword">if</span> self.noise &gt; <span class="number">0</span>:</div>
<div class="line">            grads = [(g + K.random_normal(g.shape, mean=<span class="number">0</span>,</div>
<div class="line">                                          stddev=(self.noise * self.clipnorm)))</div>
<div class="line">                     <span class="keyword">for</span> g <span class="keyword">in</span> grads]</div>
<div class="line">        <span class="keyword">return</span> grads</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_updates</span><span class="params">(self, loss,params)</span>:</span></div>
<div class="line">        grads = self.get_gradients(loss, params)</div>
<div class="line">        self.updates = [K.update_add(self.iterations, <span class="number">1</span>)]</div>
<div class="line"></div>
<div class="line">        lr = self.lr</div>
<div class="line">        <span class="keyword">if</span> self.initial_decay &gt; <span class="number">0</span>:</div>
<div class="line">            lr *= (<span class="number">1.</span> / (<span class="number">1.</span> + self.decay * self.iterations))</div>
<div class="line"></div>
<div class="line">        t = self.iterations + <span class="number">1</span></div>
<div class="line">        lr_t = lr * (K.sqrt(<span class="number">1.</span> - K.pow(self.beta_2, t)) /</div>
<div class="line">                     (<span class="number">1.</span> - K.pow(self.beta_1, t)))</div>
<div class="line"></div>
<div class="line">        shapes = [K.get_variable_shape(p) <span class="keyword">for</span> p <span class="keyword">in</span> params]</div>
<div class="line">        ms = [K.zeros(shape) <span class="keyword">for</span> shape <span class="keyword">in</span> shapes]</div>
<div class="line">        vs = [K.zeros(shape) <span class="keyword">for</span> shape <span class="keyword">in</span> shapes]</div>
<div class="line">        self.weights = [self.iterations] + ms + vs</div>
<div class="line"></div>
<div class="line">        <span class="keyword">for</span> p, g, m, v <span class="keyword">in</span> zip(params, grads, ms, vs):</div>
<div class="line">            m_t = (self.beta_1 * m) + (<span class="number">1.</span> - self.beta_1) * g</div>
<div class="line">            v_t = (self.beta_2 * v) + (<span class="number">1.</span> - self.beta_2) * K.square(g)</div>
<div class="line">            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)</div>
<div class="line"></div>
<div class="line">            self.updates.append(K.update(m, m_t))</div>
<div class="line">            self.updates.append(K.update(v, v_t))</div>
<div class="line">            new_p = p_t</div>
<div class="line">            <span class="comment"># Apply constraints.</span></div>
<div class="line">            <span class="keyword">if</span> getattr(p, <span class="string">'constraint'</span>, <span class="keyword">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div>
<div class="line">                new_p = p.constraint(new_p)</div>
<div class="line"></div>
<div class="line">            self.updates.append(K.update(p, new_p))</div>
<div class="line">        <span class="keyword">return</span> self.updates</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></div>
<div class="line">        config = &#123;<span class="string">'lr'</span>: float(K.get_value(self.lr)),</div>
<div class="line">                  <span class="string">'beta_1'</span>: float(K.get_value(self.beta_1)),</div>
<div class="line">                  <span class="string">'beta_2'</span>: float(K.get_value(self.beta_2)),</div>
<div class="line">                  <span class="string">'decay'</span>: float(K.get_value(self.decay)),</div>
<div class="line">                  <span class="string">'epsilon'</span>: self.epsilon&#125;</div>
<div class="line">        base_config = super(NoisyAdam, self).get_config()</div>
<div class="line">        <span class="keyword">return</span> dict(list(base_config.items()) + list(config.items()))</div>
</pre></td></tr></table></figure>

</div></div>
<h1 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h1><h2 id="VGG-Feature-Loss"><a href="#VGG-Feature-Loss" class="headerlink" title="VGG Feature Loss"></a>VGG Feature Loss</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG19</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vgg</span><span class="params">()</span>:</span></div>
<div class="line">    vgg = VGG19(weights=<span class="string">"imagenet"</span>)</div>
<div class="line">    vgg.outputs = [vgg.layers[<span class="number">9</span>].output]</div>
<div class="line">    img = layers.Input(shape=self.img_shape)</div>
<div class="line">    img_features = vgg(img)</div>
<div class="line">    <span class="keyword">return</span> Model(img, img_features)</div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">vgg = build_vgg()</div>
<div class="line">vgg.trainable = <span class="keyword">False</span></div>
<div class="line">vgg.compile(loss=<span class="string">'mse'</span>,optimizer=optimizer,metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"></div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">fake_pose_vgg_feature = vgg(pose_recons)</div>
<div class="line">pose_ende = Model(pose_img,fake_pose_vgg_feature)</div>
<div class="line"> </div>
<div class="line"><span class="comment">##########################################</span></div>
<div class="line">pose_real_vgg_feature = vgg.predict(pose_imgs)</div>
<div class="line">pose_loss = pose_ende.train_on_batch(pose_imgs,pose_real_vgg_feature)</div>
</pre></td></tr></table></figure>
<h2 id="Fine-tune-ref"><a href="#Fine-tune-ref" class="headerlink" title="Fine tune ref"></a>Fine tune <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="noopener">ref</a></h2><h1 id="Print-Gradients-ref"><a href="#Print-Gradients-ref" class="headerlink" title="Print Gradients ref"></a>Print Gradients <a href="http://sujitpal.blogspot.com/2017/10/debugging-keras-networks.html" target="_blank" rel="noopener">ref</a></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_gradients</span><span class="params">(self,inputs, groundtruth, model)</span>:</span></div>
<div class="line">    opt = model.optimizer</div>
<div class="line">    loss = model.total_loss</div>
<div class="line">    weights = model.weights</div>
<div class="line">    grads = opt.get_gradients(loss, weights)</div>
<div class="line">    grad_fn = K.function(inputs=[model.inputs[<span class="number">0</span>],</div>
<div class="line">                                 model.sample_weights[<span class="number">0</span>],</div>
<div class="line">                                 model.targets[<span class="number">0</span>],</div>
<div class="line">                                 K.learning_phase()],</div>
<div class="line">                         outputs=grads)</div>
<div class="line">    grad_values = grad_fn([inputs, np.ones(len(inputs)), groundtruth, <span class="number">1</span>])</div>
<div class="line">    <span class="keyword">return</span> grad_values</div>
</pre></td></tr></table></figure>
<p>Then in the main function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">gradients = self.get_gradients(imgs,valid,self.discriminator)</div>
<div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(gradients)):</div>
<div class="line">    print(i, np.shape(gradients[i]))</div>
</pre></td></tr></table></figure>
<h1 id="HyperparametersSearching"><a href="#HyperparametersSearching" class="headerlink" title="HyperparametersSearching"></a>HyperparametersSearching</h1><p><a href="https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/tune_mnist_keras.py" target="_blank" rel="noopener">source</a></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
<div class="line">33</div>
<div class="line">34</div>
<div class="line">35</div>
<div class="line">36</div>
<div class="line">37</div>
<div class="line">38</div>
<div class="line">39</div>
<div class="line">40</div>
<div class="line">41</div>
<div class="line">42</div>
<div class="line">43</div>
<div class="line">44</div>
<div class="line">45</div>
<div class="line">46</div>
<div class="line">47</div>
<div class="line">48</div>
<div class="line">49</div>
<div class="line">50</div>
<div class="line">51</div>
<div class="line">52</div>
<div class="line">53</div>
<div class="line">54</div>
<div class="line">55</div>
<div class="line">56</div>
<div class="line">57</div>
<div class="line">58</div>
<div class="line">59</div>
<div class="line">60</div>
<div class="line">61</div>
<div class="line">62</div>
<div class="line">63</div>
<div class="line">64</div>
<div class="line">65</div>
<div class="line">66</div>
<div class="line">67</div>
<div class="line">68</div>
<div class="line">69</div>
<div class="line">70</div>
<div class="line">71</div>
<div class="line">72</div>
<div class="line">73</div>
<div class="line">74</div>
<div class="line">75</div>
<div class="line">76</div>
<div class="line">77</div>
<div class="line">78</div>
<div class="line">79</div>
<div class="line">80</div>
<div class="line">81</div>
<div class="line">82</div>
<div class="line">83</div>
<div class="line">84</div>
<div class="line">85</div>
<div class="line">86</div>
<div class="line">87</div>
<div class="line">88</div>
<div class="line">89</div>
<div class="line">90</div>
<div class="line">91</div>
<div class="line">92</div>
<div class="line">93</div>
<div class="line">94</div>
<div class="line">95</div>
<div class="line">96</div>
<div class="line">97</div>
<div class="line">98</div>
<div class="line">99</div>
<div class="line">100</div>
<div class="line">101</div>
<div class="line">102</div>
<div class="line">103</div>
<div class="line">104</div>
<div class="line">105</div>
<div class="line">106</div>
<div class="line">107</div>
<div class="line">108</div>
<div class="line">109</div>
<div class="line">110</div>
<div class="line">111</div>
<div class="line">112</div>
<div class="line">113</div>
<div class="line">114</div>
<div class="line">115</div>
<div class="line">116</div>
<div class="line">117</div>
<div class="line">118</div>
<div class="line">119</div>
<div class="line">120</div>
<div class="line">121</div>
<div class="line">122</div>
<div class="line">123</div>
<div class="line">124</div>
<div class="line">125</div>
<div class="line">126</div>
<div class="line">127</div>
<div class="line">128</div>
<div class="line">129</div>
<div class="line">130</div>
<div class="line">131</div>
<div class="line">132</div>
<div class="line">133</div>
<div class="line">134</div>
<div class="line">135</div>
<div class="line">136</div>
<div class="line">137</div>
<div class="line">138</div>
<div class="line">139</div>
<div class="line">140</div>
<div class="line">141</div>
<div class="line">142</div>
<div class="line">143</div>
<div class="line">144</div>
<div class="line">145</div>
<div class="line">146</div>
<div class="line">147</div>
<div class="line">148</div>
<div class="line">149</div>
<div class="line">150</div>
<div class="line">151</div>
<div class="line">152</div>
<div class="line">153</div>
<div class="line">154</div>
<div class="line">155</div>
<div class="line">156</div>
<div class="line">157</div>
<div class="line">158</div>
<div class="line">159</div>
<div class="line">160</div>
<div class="line">161</div>
<div class="line">162</div>
<div class="line">163</div>
<div class="line">164</div>
<div class="line">165</div>
<div class="line">166</div>
<div class="line">167</div>
<div class="line">168</div>
<div class="line">169</div>
<div class="line">170</div>
<div class="line">171</div>
<div class="line">172</div>
<div class="line">173</div>
<div class="line">174</div>
<div class="line">175</div>
<div class="line">176</div>
<div class="line">177</div>
<div class="line">178</div>
<div class="line">179</div>
<div class="line">180</div>
<div class="line">181</div>
<div class="line">182</div>
<div class="line">183</div>
<div class="line">184</div>
<div class="line">185</div>
<div class="line">186</div>
<div class="line">187</div>
<div class="line">188</div>
<div class="line">189</div>
<div class="line">190</div>
<div class="line">191</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Original Code here:</span></div>
<div class="line"><span class="comment"># https://github.com/pytorch/examples/blob/master/mnist/main.py</span></div>
<div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div>
<div class="line"></div>
<div class="line"><span class="keyword">import</span> argparse</div>
<div class="line"><span class="keyword">import</span> torch</div>
<div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div>
<div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div>
<div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div>
<div class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</div>
<div class="line"></div>
<div class="line"><span class="comment"># Training settings</span></div>
<div class="line">parser = argparse.ArgumentParser(description=<span class="string">"PyTorch MNIST Example"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--batch-size"</span>,</div>
<div class="line">    type=int,</div>
<div class="line">    default=<span class="number">64</span>,</div>
<div class="line">    metavar=<span class="string">"N"</span>,</div>
<div class="line">    help=<span class="string">"input batch size for training (default: 64)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--test-batch-size"</span>,</div>
<div class="line">    type=int,</div>
<div class="line">    default=<span class="number">1000</span>,</div>
<div class="line">    metavar=<span class="string">"N"</span>,</div>
<div class="line">    help=<span class="string">"input batch size for testing (default: 1000)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--epochs"</span>,</div>
<div class="line">    type=int,</div>
<div class="line">    default=<span class="number">1</span>,</div>
<div class="line">    metavar=<span class="string">"N"</span>,</div>
<div class="line">    help=<span class="string">"number of epochs to train (default: 1)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--lr"</span>,</div>
<div class="line">    type=float,</div>
<div class="line">    default=<span class="number">0.01</span>,</div>
<div class="line">    metavar=<span class="string">"LR"</span>,</div>
<div class="line">    help=<span class="string">"learning rate (default: 0.01)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--momentum"</span>,</div>
<div class="line">    type=float,</div>
<div class="line">    default=<span class="number">0.5</span>,</div>
<div class="line">    metavar=<span class="string">"M"</span>,</div>
<div class="line">    help=<span class="string">"SGD momentum (default: 0.5)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--no-cuda"</span>,</div>
<div class="line">    action=<span class="string">"store_true"</span>,</div>
<div class="line">    default=<span class="keyword">False</span>,</div>
<div class="line">    help=<span class="string">"disables CUDA training"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--seed"</span>,</div>
<div class="line">    type=int,</div>
<div class="line">    default=<span class="number">1</span>,</div>
<div class="line">    metavar=<span class="string">"S"</span>,</div>
<div class="line">    help=<span class="string">"random seed (default: 1)"</span>)</div>
<div class="line">parser.add_argument(</div>
<div class="line">    <span class="string">"--smoke-test"</span>, action=<span class="string">"store_true"</span>, help=<span class="string">"Finish quickly for testing"</span>)</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_mnist</span><span class="params">(args, config, reporter)</span>:</span></div>
<div class="line">    vars(args).update(config)</div>
<div class="line">    args.cuda = <span class="keyword">not</span> args.no_cuda <span class="keyword">and</span> torch.cuda.is_available()</div>
<div class="line"></div>
<div class="line">    torch.manual_seed(args.seed)</div>
<div class="line">    <span class="keyword">if</span> args.cuda:</div>
<div class="line">        torch.cuda.manual_seed(args.seed)</div>
<div class="line"></div>
<div class="line">    kwargs = &#123;<span class="string">"num_workers"</span>: <span class="number">1</span>, <span class="string">"pin_memory"</span>: <span class="keyword">True</span>&#125; <span class="keyword">if</span> args.cuda <span class="keyword">else</span> &#123;&#125;</div>
<div class="line">    train_loader = torch.utils.data.DataLoader(</div>
<div class="line">        datasets.MNIST(</div>
<div class="line">            <span class="string">"~/data"</span>,</div>
<div class="line">            train=<span class="keyword">True</span>,</div>
<div class="line">            download=<span class="keyword">False</span>,</div>
<div class="line">            transform=transforms.Compose([</div>
<div class="line">                transforms.ToTensor(),</div>
<div class="line">                transforms.Normalize((<span class="number">0.1307</span>, ), (<span class="number">0.3081</span>, ))</div>
<div class="line">            ])),</div>
<div class="line">        batch_size=args.batch_size,</div>
<div class="line">        shuffle=<span class="keyword">True</span>,</div>
<div class="line">        **kwargs)</div>
<div class="line">    test_loader = torch.utils.data.DataLoader(</div>
<div class="line">        datasets.MNIST(</div>
<div class="line">            <span class="string">"~/data"</span>,</div>
<div class="line">            train=<span class="keyword">False</span>,</div>
<div class="line">            transform=transforms.Compose([</div>
<div class="line">                transforms.ToTensor(),</div>
<div class="line">                transforms.Normalize((<span class="number">0.1307</span>, ), (<span class="number">0.3081</span>, ))</div>
<div class="line">            ])),</div>
<div class="line">        batch_size=args.test_batch_size,</div>
<div class="line">        shuffle=<span class="keyword">True</span>,</div>
<div class="line">        **kwargs)</div>
<div class="line"></div>
<div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></div>
<div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div>
<div class="line">            super(Net, self).__init__()</div>
<div class="line">            self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</div>
<div class="line">            self.conv2 = nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</div>
<div class="line">            self.conv2_drop = nn.Dropout2d()</div>
<div class="line">            self.fc1 = nn.Linear(<span class="number">320</span>, <span class="number">50</span>)</div>
<div class="line">            self.fc2 = nn.Linear(<span class="number">50</span>, <span class="number">10</span>)</div>
<div class="line"></div>
<div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div>
<div class="line">            x = F.relu(F.max_pool2d(self.conv1(x), <span class="number">2</span>))</div>
<div class="line">            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), <span class="number">2</span>))</div>
<div class="line">            x = x.view(<span class="number">-1</span>, <span class="number">320</span>)</div>
<div class="line">            x = F.relu(self.fc1(x))</div>
<div class="line">            x = F.dropout(x, training=self.training)</div>
<div class="line">            x = self.fc2(x)</div>
<div class="line">            <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</div>
<div class="line"></div>
<div class="line">    model = Net()</div>
<div class="line">    <span class="keyword">if</span> args.cuda:</div>
<div class="line">        model.cuda()</div>
<div class="line"></div>
<div class="line">    optimizer = optim.SGD(</div>
<div class="line">        model.parameters(), lr=args.lr, momentum=args.momentum)</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epoch)</span>:</span></div>
<div class="line">        model.train()</div>
<div class="line">        <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</div>
<div class="line">            <span class="keyword">if</span> args.cuda:</div>
<div class="line">                data, target = data.cuda(), target.cuda()</div>
<div class="line">            optimizer.zero_grad()</div>
<div class="line">            output = model(data)</div>
<div class="line">            loss = F.nll_loss(output, target)</div>
<div class="line">            loss.backward()</div>
<div class="line">            optimizer.step()</div>
<div class="line"></div>
<div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></div>
<div class="line">        model.eval()</div>
<div class="line">        test_loss = <span class="number">0</span></div>
<div class="line">        correct = <span class="number">0</span></div>
<div class="line">        <span class="keyword">with</span> torch.no_grad():</div>
<div class="line">            <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</div>
<div class="line">                <span class="keyword">if</span> args.cuda:</div>
<div class="line">                    data, target = data.cuda(), target.cuda()</div>
<div class="line">                output = model(data)</div>
<div class="line">                <span class="comment"># sum up batch loss</span></div>
<div class="line">                test_loss += F.nll_loss(output, target, reduction=<span class="string">"sum"</span>).item()</div>
<div class="line">                <span class="comment"># get the index of the max log-probability</span></div>
<div class="line">                pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</div>
<div class="line">                correct += pred.eq(</div>
<div class="line">                    target.data.view_as(pred)).long().cpu().sum()</div>
<div class="line"></div>
<div class="line">        test_loss = test_loss / len(test_loader.dataset)</div>
<div class="line">        accuracy = correct.item() / len(test_loader.dataset)</div>
<div class="line">        reporter(mean_loss=test_loss, mean_accuracy=accuracy)</div>
<div class="line"></div>
<div class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</div>
<div class="line">        train(epoch)</div>
<div class="line">        test()</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div>
<div class="line">    datasets.MNIST(<span class="string">"~/data"</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>)</div>
<div class="line">    args = parser.parse_args()</div>
<div class="line"></div>
<div class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line">    <span class="keyword">import</span> ray</div>
<div class="line">    <span class="keyword">from</span> ray <span class="keyword">import</span> tune</div>
<div class="line">    <span class="keyword">from</span> ray.tune.schedulers <span class="keyword">import</span> AsyncHyperBandScheduler</div>
<div class="line"></div>
<div class="line">    ray.init()</div>
<div class="line">    sched = AsyncHyperBandScheduler(</div>
<div class="line">        time_attr=<span class="string">"training_iteration"</span>,</div>
<div class="line">        reward_attr=<span class="string">"neg_mean_loss"</span>,</div>
<div class="line">        max_t=<span class="number">400</span>,</div>
<div class="line">        grace_period=<span class="number">20</span>)</div>
<div class="line">    tune.register_trainable(</div>
<div class="line">        <span class="string">"TRAIN_FN"</span>,</div>
<div class="line">        <span class="keyword">lambda</span> config, reporter: train_mnist(args, config, reporter))</div>
<div class="line">    tune.run(</div>
<div class="line">        <span class="string">"TRAIN_FN"</span>,</div>
<div class="line">        name=<span class="string">"exp"</span>,</div>
<div class="line">        scheduler=sched,</div>
<div class="line">        **&#123;</div>
<div class="line">            <span class="string">"stop"</span>: &#123;</div>
<div class="line">                <span class="string">"mean_accuracy"</span>: <span class="number">0.98</span>,</div>
<div class="line">                <span class="string">"training_iteration"</span>: <span class="number">1</span> <span class="keyword">if</span> args.smoke_test <span class="keyword">else</span> <span class="number">20</span></div>
<div class="line">            &#125;,</div>
<div class="line">            <span class="string">"resources_per_trial"</span>: &#123;</div>
<div class="line">                <span class="string">"cpu"</span>: <span class="number">3</span>,</div>
<div class="line">                <span class="string">"gpu"</span>: int(<span class="keyword">not</span> args.no_cuda)</div>
<div class="line">            &#125;,</div>
<div class="line">            <span class="string">"num_samples"</span>: <span class="number">1</span> <span class="keyword">if</span> args.smoke_test <span class="keyword">else</span> <span class="number">10</span>,</div>
<div class="line">            <span class="string">"config"</span>: &#123;</div>
<div class="line">                <span class="string">"lr"</span>: tune.sample_from(</div>
<div class="line">                    <span class="keyword">lambda</span> spec: np.random.uniform(<span class="number">0.001</span>, <span class="number">0.1</span>)),</div>
<div class="line">                <span class="string">"momentum"</span>: tune.sample_from(</div>
<div class="line">                    <span class="keyword">lambda</span> spec: np.random.uniform(<span class="number">0.1</span>, <span class="number">0.9</span>)),</div>
<div class="line">            &#125;</div>
<div class="line">        &#125;)</div>
</pre></td></tr></table></figure>

</div></div>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/Keras/" rel="tag"># Keras</a>
          
            <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/22/AutoEncoder/" rel="next" title="AutoEncoder">
                <i class="fa fa-chevron-left"></i> AutoEncoder
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/24/Neural-Network/" rel="prev" title="Neural Network">
                Neural Network <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">82</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">63</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras模块结构"><span class="nav-number">1.</span> <span class="nav-text">Keras模块结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras构建神经网络"><span class="nav-number">2.</span> <span class="nav-text">Keras构建神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Models"><span class="nav-number">3.</span> <span class="nav-text">Models</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Attributes"><span class="nav-number">3.1.</span> <span class="nav-text">Attributes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-subclassing"><span class="nav-number">3.2.</span> <span class="nav-text">Model subclassing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-class-API"><span class="nav-number">3.3.</span> <span class="nav-text">Model class API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Methods"><span class="nav-number">3.3.1.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#compile"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">compile</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fit"><span class="nav-number">3.3.1.2.</span> <span class="nav-text">fit</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#evaluate"><span class="nav-number">3.3.1.3.</span> <span class="nav-text">evaluate</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#predict"><span class="nav-number">3.3.1.4.</span> <span class="nav-text">predict</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#train-on-batch"><span class="nav-number">3.3.1.5.</span> <span class="nav-text">train_on_batch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-on-batch"><span class="nav-number">3.3.1.6.</span> <span class="nav-text">test_on_batch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#predict-on-batch"><span class="nav-number">3.3.1.7.</span> <span class="nav-text">predict_on_batch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fit-generator"><span class="nav-number">3.3.1.8.</span> <span class="nav-text">fit_generator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#evaluate-generator"><span class="nav-number">3.3.1.9.</span> <span class="nav-text">evaluate_generator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#predict-generator"><span class="nav-number">3.3.1.10.</span> <span class="nav-text">predict_generator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#get-layer"><span class="nav-number">3.3.1.11.</span> <span class="nav-text">get_layer</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Layers"><span class="nav-number">4.</span> <span class="nav-text">Layers</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Properties"><span class="nav-number">4.1.</span> <span class="nav-text">Properties</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Get-weights"><span class="nav-number">4.1.1.</span> <span class="nav-text">Get weights</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Get-input-output-shape"><span class="nav-number">4.1.2.</span> <span class="nav-text">Get input/output/shape</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Obtain-output-of-an-intermediate-layer"><span class="nav-number">4.1.3.</span> <span class="nav-text">Obtain output of an intermediate layer</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Core-Layers"><span class="nav-number">4.2.</span> <span class="nav-text">Core Layers</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dense"><span class="nav-number">4.2.1.</span> <span class="nav-text">Dense()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flatten"><span class="nav-number">4.2.2.</span> <span class="nav-text">Flatten()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Input"><span class="nav-number">4.2.3.</span> <span class="nav-text">Input()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reshape"><span class="nav-number">4.2.4.</span> <span class="nav-text">Reshape()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Permute"><span class="nav-number">4.2.5.</span> <span class="nav-text">Permute()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RepeatVector"><span class="nav-number">4.2.6.</span> <span class="nav-text">RepeatVector()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conv2D"><span class="nav-number">4.2.7.</span> <span class="nav-text">Conv2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conv2DTranspose"><span class="nav-number">4.2.8.</span> <span class="nav-text">Conv2DTranspose()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UpSampling2D"><span class="nav-number">4.2.9.</span> <span class="nav-text">UpSampling2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ZeroPadding2D"><span class="nav-number">4.2.10.</span> <span class="nav-text">ZeroPadding2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MaxPooling2D"><span class="nav-number">4.2.11.</span> <span class="nav-text">MaxPooling2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AveragePooling2D"><span class="nav-number">4.2.12.</span> <span class="nav-text">AveragePooling2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GlobalMaxPooling2D"><span class="nav-number">4.2.13.</span> <span class="nav-text">GlobalMaxPooling2D()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GlobalAveragePooling2D"><span class="nav-number">4.2.14.</span> <span class="nav-text">GlobalAveragePooling2D()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ImageProcessing"><span class="nav-number">5.</span> <span class="nav-text">ImageProcessing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ImageDataGenerator-class"><span class="nav-number">5.1.</span> <span class="nav-text">ImageDataGenerator class</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods-1"><span class="nav-number">5.2.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#apply-transform"><span class="nav-number">5.2.1.</span> <span class="nav-text">apply_transform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fit-1"><span class="nav-number">5.2.2.</span> <span class="nav-text">fit</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flow"><span class="nav-number">5.2.3.</span> <span class="nav-text">flow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flow-from-directory"><span class="nav-number">5.2.4.</span> <span class="nav-text">flow_from_directory</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型保存"><span class="nav-number">6.</span> <span class="nav-text">模型保存</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#方法一"><span class="nav-number">6.1.</span> <span class="nav-text">方法一</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型保存-1"><span class="nav-number">6.1.1.</span> <span class="nav-text">模型保存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型载入"><span class="nav-number">6.1.2.</span> <span class="nav-text">模型载入</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方法二"><span class="nav-number">6.2.</span> <span class="nav-text">方法二</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras-Callback"><span class="nav-number">7.</span> <span class="nav-text">Keras-Callback</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ModelCheckpoint"><span class="nav-number">7.1.</span> <span class="nav-text">ModelCheckpoint</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Checkpoint-Neural-Network-Model-Improvements"><span class="nav-number">7.1.1.</span> <span class="nav-text">Checkpoint Neural Network Model Improvements</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loading-a-Check-Pointed-Neural-Network-Model"><span class="nav-number">7.1.2.</span> <span class="nav-text">Loading a Check-Pointed Neural Network Model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LearningRateScheduler"><span class="nav-number">7.2.</span> <span class="nav-text">LearningRateScheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Time-Based-Learning-Rate-Schedule"><span class="nav-number">7.2.1.</span> <span class="nav-text">Time-Based Learning Rate Schedule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Drop-Based-Learning-Rate-Schedule"><span class="nav-number">7.2.2.</span> <span class="nav-text">Drop-Based Learning Rate Schedule</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#History"><span class="nav-number">7.3.</span> <span class="nav-text">History</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Visualize-Model-Training-History-in-Keras"><span class="nav-number">7.3.1.</span> <span class="nav-text">Visualize Model Training History in Keras</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensorboard"><span class="nav-number">7.4.</span> <span class="nav-text">Tensorboard</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorflow"><span class="nav-number">7.4.1.</span> <span class="nav-text">Tensorflow</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Customerize-Optimizer"><span class="nav-number">8.</span> <span class="nav-text">Customerize Optimizer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Feature-Extraction"><span class="nav-number">9.</span> <span class="nav-text">Feature Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#VGG-Feature-Loss"><span class="nav-number">9.1.</span> <span class="nav-text">VGG Feature Loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fine-tune-ref"><span class="nav-number">9.2.</span> <span class="nav-text">Fine tune ref</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Print-Gradients-ref"><span class="nav-number">10.</span> <span class="nav-text">Print Gradients ref</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HyperparametersSearching"><span class="nav-number">11.</span> <span class="nav-text">HyperparametersSearching</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
