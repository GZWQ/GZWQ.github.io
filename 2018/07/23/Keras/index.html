<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network," />










<meta name="description" content="本文参考了Keras入门">
<meta name="keywords" content="Deep Learning,CNN,Keras,Neural Network">
<meta property="og:type" content="article">
<meta property="og:title" content="Keras">
<meta property="og:url" content="http://yoursite.com/2018/07/23/Keras/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:description" content="本文参考了Keras入门">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Screen%20Shot%202018-07-26%20at%2011.18.59%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133932722-715494711.png">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Keras/CNNArchitecture.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170809132648824-260187979.png">
<meta property="og:updated_time" content="2019-01-30T21:55:45.172Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keras">
<meta name="twitter:description" content="本文参考了Keras入门">
<meta name="twitter:image" content="http://yoursite.com/2018/07/23/Keras/1119747-20170707133635659-888158147.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/23/Keras/"/>





  <title>Keras | Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/23/Keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Keras</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-23T17:32:39-05:00">
                2018-07-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文参考了<a href="http://www.cnblogs.com/lc1217/p/7132364.html" target="_blank" rel="noopener">Keras入门</a></p>
<a id="more"></a>
<h1 id="Keras模块结构"><a href="#Keras模块结构" class="headerlink" title="Keras模块结构"></a>Keras模块结构</h1><p><img src="/2018/07/23/Keras/1119747-20170707133635659-888158147.png" alt="1119747-20170707133635659-888158147"></p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="序贯（Sequential）模型"><a href="#序贯（Sequential）模型" class="headerlink" title="序贯（Sequential）模型"></a><a href="https://keras-cn.readthedocs.io/en/latest/getting_started/sequential_model/" target="_blank" rel="noopener">序贯（Sequential）模型</a></h3><h3 id="网络构造"><a href="#网络构造" class="headerlink" title="网络构造"></a>网络构造</h3><p>序贯模型是多个网络层的线性堆叠，也就是“一条路走到黑”。通过<code>.add()</code>将layer加入网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">model = Sequential()</div>
<div class="line">model.add(Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)))</div>
<div class="line">model.add(Activation(<span class="string">'relu'</span>))</div>
</pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>在训练模型之前，我们需要通过<code>compile</code>来对学习过程进行配置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">model.compile(optimizer=<span class="string">''</span>,loss=<span class="string">''</span>,metrics=[])</div>
</pre></td></tr></table></figure>
<ul>
<li>优化器optimizer：该参数可指定为已预定义的优化器名，如<code>rmsprop</code>、<code>adagrad</code>，或一个<code>Optimizer</code>类的对象</li>
<li>损失函数loss：该参数为模型试图最小化的目标函数，它可为预定义的损失函数名，如<code>categorical_crossentropy</code>、<code>mse</code>，也可以为一个损失函数</li>
<li>指标列表metrics：对分类问题，我们一般将该列表设置为<code>metrics=[&#39;accuracy&#39;]</code>。指标可以是一个预定义指标的名字,也可以是一个用户定制的函数.指标函数应该返回单个张量,</li>
</ul>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>Keras以Numpy数组作为输入数据和标签的数据类型。训练模型一般使用<code>fit</code>函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">model.fit(data, labels, epochs=xx, batch_size=xx)</div>
</pre></td></tr></table></figure>
<ul>
<li><p>训练数据data：numpy.array()类型</p>
</li>
<li><p>标签label：可以是numpy.array()类型，labels = np.random.randint(2, size=(1000, 1))  </p>
<p>也可以是独热向量，labels = keras.utils.to_categorical(labels, num_classes=10)</p>
</li>
</ul>
<h3 id="函数式（Functional）模型"><a href="#函数式（Functional）模型" class="headerlink" title="函数式（Functional）模型"></a><a href="https://keras-cn.readthedocs.io/en/latest/getting_started/functional_API/" target="_blank" rel="noopener">函数式（Functional）模型</a></h3><p>Keras函数式模型接口是用户定义多输出模型、非循环有向模型或具有共享层的模型等复杂模型的途径。一句话，只要你的模型不是类似VGG一样一条路走到黑的模型，或者你的模型需要多于一个的输出，那么你总应该选择函数式模型。函数式模型是最广泛的一类模型，序贯模型（Sequential）只是它的一种特殊情况。</p>
<h4 id="应用场景1：全连接网络"><a href="#应用场景1：全连接网络" class="headerlink" title="应用场景1：全连接网络"></a>应用场景1：全连接网络</h4><p><code>Sequential</code>当然是实现全连接网络的最好方式，但我们从简单的全连接网络开始学习函数式模型。</p>
<p>之前，需要清楚的是：</p>
<ul>
<li>层对象接受张量为参数，返回一个张量。</li>
<li>输入是张量，输出也是张量的一个框架就是一个模型，通过<code>Model</code>定义。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line"><span class="comment"># This returns a tensor</span></div>
<div class="line">inputs = Input(shape=(<span class="number">784</span>,))</div>
<div class="line"><span class="comment"># a layer instance is callable on a tensor, and returns a tensor</span></div>
<div class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(inputs)</div>
<div class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</div>
<div class="line">predictions = Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(x)</div>
<div class="line"><span class="comment"># This creates a model that includes</span></div>
<div class="line"><span class="comment"># the Input layer and three Dense layers</span></div>
<div class="line">model = Model(inputs=inputs, outputs=predictions)</div>
<div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div>
<div class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</div>
<div class="line">              metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line">model.fit(data, labels)  <span class="comment"># starts training</span></div>
</pre></td></tr></table></figure>
<p>利用函数式模型的接口，我们可以很容易的重用已经训练好的模型：你可以把模型当作一个层一样，通过提供一个tensor来调用它。注意当你调用一个模型时，你不仅仅重用了它的结构，也重用了它的权重。</p>
<p>这种方式可以允许你快速的创建能处理序列信号的模型，你可以很快将一个图像分类的模型变为一个对视频分类的模型，只需要一行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> TimeDistributed</div>
<div class="line"></div>
<div class="line"><span class="comment"># Input tensor for sequences of 20 timesteps,</span></div>
<div class="line"><span class="comment"># each containing a 784-dimensional vector</span></div>
<div class="line">input_sequences = Input(shape=(<span class="number">20</span>, <span class="number">784</span>))</div>
<div class="line"></div>
<div class="line"><span class="comment"># This applies our previous model to every timestep in the input sequences.</span></div>
<div class="line"><span class="comment"># the output of the previous model was a 10-way softmax,</span></div>
<div class="line"><span class="comment"># so the output of the layer below will be a sequence of 20 vectors of size 10.</span></div>
<div class="line">processed_sequences = TimeDistributed(model)(input_sequences)</div>
</pre></td></tr></table></figure>
<h4 id="应用场景2：多输入多输出模型"><a href="#应用场景2：多输入多输出模型" class="headerlink" title="应用场景2：多输入多输出模型"></a>应用场景2：多输入多输出模型</h4><p>使用函数式模型的一个典型场景是搭建多输入、多输出的模型。</p>
<p><img src="/2018/07/23/Keras/Screen Shot 2018-07-26 at 11.18.59 AM.png" alt="Screen Shot 2018-07-26 at 11.18.59 AM"></p>
<p>首先构造<code>main_input</code>，<code>embedding_1</code>和<code>lstm_1</code>层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Embedding, LSTM, Dense</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line"></div>
<div class="line"><span class="comment"># Headline input: meant to receive sequences of 100 integers, between 1 and 10000.</span></div>
<div class="line"><span class="comment"># Note that we can name any layer by passing it a "name" argument.</span></div>
<div class="line">main_input = Input(shape=(<span class="number">100</span>,), dtype=<span class="string">'int32'</span>, name=<span class="string">'main_input'</span>)</div>
<div class="line"></div>
<div class="line"><span class="comment"># This embedding layer will encode the input sequence</span></div>
<div class="line"><span class="comment"># into a sequence of dense 512-dimensional vectors.</span></div>
<div class="line">x = Embedding(output_dim=<span class="number">512</span>, input_dim=<span class="number">10000</span>, input_length=<span class="number">100</span>)(main_input)</div>
<div class="line"></div>
<div class="line"><span class="comment"># A LSTM will transform the vector sequence into a single vector,</span></div>
<div class="line"><span class="comment"># containing information about the entire sequence</span></div>
<div class="line">lstm_out = LSTM(<span class="number">32</span>)(x)</div>
</pre></td></tr></table></figure>
<p>然后定义额外的输出<code>aux_output</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">auxiliary_output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'aux_output'</span>)(lstm_out)</div>
</pre></td></tr></table></figure>
<p>接着定义另一个输入<code>aux_input</code>，联合<code>lstm_1</code>作为共同输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">auxiliary_input = Input(shape=(<span class="number">5</span>,), name=<span class="string">'aux_input'</span>)</div>
<div class="line">x = keras.layers.concatenate([lstm_out, auxiliary_input])</div>
</pre></td></tr></table></figure>
<p>将输入连接之后，定义三个全连接层<code>dense_1</code>，<code>dense_2</code>，<code>dense_3</code>和输出层<code>main_output</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># We stack a deep densely-connected network on top</span></div>
<div class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</div>
<div class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</div>
<div class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</div>
<div class="line"></div>
<div class="line"><span class="comment"># And finally we add the main logistic regression layer</span></div>
<div class="line">main_output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'main_output'</span>)(x)</div>
</pre></td></tr></table></figure>
<p>最后通过函数式模型组装</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])</div>
</pre></td></tr></table></figure>
<p>模型定义完毕，下一步编译模型。我们给额外的损失赋0.2的权重。我们可以通过关键字参数<code>loss_weights</code>或<code>loss</code>来为不同的输出设置不同的损失函数或权值。这两个参数均可为Python的列表或字典。这里我们给<code>loss</code>传递单个损失函数，这个损失函数会被应用于所有输出上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>,</div>
<div class="line">              loss_weights=[<span class="number">1.</span>, <span class="number">0.2</span>])</div>
</pre></td></tr></table></figure>
<p>编译完成后，我们通过传递训练数据和目标值训练该模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">model.fit([headline_data, additional_data], [labels, labels],</div>
<div class="line">          epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>)</div>
</pre></td></tr></table></figure>
<p> 因为我们输入和输出是被命名过的（在定义时传递了“name”参数），我们也可以用下面的方式编译和训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div>
<div class="line">              loss=&#123;<span class="string">'main_output'</span>: <span class="string">'binary_crossentropy'</span>, <span class="string">'aux_output'</span>: <span class="string">'binary_crossentropy'</span>&#125;,</div>
<div class="line">              loss_weights=&#123;<span class="string">'main_output'</span>: <span class="number">1.</span>, <span class="string">'aux_output'</span>: <span class="number">0.2</span>&#125;)</div>
<div class="line"></div>
<div class="line"><span class="comment"># And trained it via:</span></div>
<div class="line">model.fit(&#123;<span class="string">'main_input'</span>: headline_data, <span class="string">'aux_input'</span>: additional_data&#125;,</div>
<div class="line">          &#123;<span class="string">'main_output'</span>: labels, <span class="string">'aux_output'</span>: labels&#125;,</div>
<div class="line">          epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>)</div>
</pre></td></tr></table></figure>
<h4 id="应用场景3：共享层"><a href="#应用场景3：共享层" class="headerlink" title="应用场景3：共享层"></a>应用场景3：共享层</h4><p>另一个使用函数式模型的场合是使用共享层的时候。</p>
<p>考虑微博数据，我们希望建立模型来判别两条微博是否是来自同一个用户，这个需求同样可以用来判断一个用户的两条微博的相似性。一种实现方式是，我们建立一个模型，它分别将两条微博的数据映射到两个特征向量上，然后将特征向量串联并加一个logistic回归层，输出它们来自同一个用户的概率。这种模型的训练数据是一对对的微博。因为这个问题是对称的，所以处理第一条微博的模型当然也能重用于处理第二条微博。所以这里我们使用一个共享的LSTM层来进行映射。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> keras</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, LSTM, Dense</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line"></div>
<div class="line">tweet_a = Input(shape=(<span class="number">140</span>, <span class="number">256</span>))</div>
<div class="line">tweet_b = Input(shape=(<span class="number">140</span>, <span class="number">256</span>))</div>
</pre></td></tr></table></figure>
<p>若要对不同的输入共享同一层，就初始化该层一次，然后多次调用它</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># This layer can take as input a matrix</span></div>
<div class="line"><span class="comment"># and will return a vector of size 64</span></div>
<div class="line">shared_lstm = LSTM(<span class="number">64</span>)</div>
<div class="line"></div>
<div class="line"><span class="comment"># When we reuse the same layer instance</span></div>
<div class="line"><span class="comment"># multiple times, the weights of the layer</span></div>
<div class="line"><span class="comment"># are also being reused</span></div>
<div class="line"><span class="comment"># (it is effectively *the same* layer)</span></div>
<div class="line">encoded_a = shared_lstm(tweet_a)</div>
<div class="line">encoded_b = shared_lstm(tweet_b)</div>
<div class="line"></div>
<div class="line"><span class="comment"># We can then concatenate the two vectors:</span></div>
<div class="line">merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=<span class="number">-1</span>)</div>
<div class="line"></div>
<div class="line"><span class="comment"># And add a logistic regression on top</span></div>
<div class="line">predictions = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(merged_vector)</div>
<div class="line"></div>
<div class="line"><span class="comment"># We define a trainable model linking the</span></div>
<div class="line"><span class="comment"># tweet inputs to the predictions</span></div>
<div class="line">model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)</div>
<div class="line"></div>
<div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div>
<div class="line">              loss=<span class="string">'binary_crossentropy'</span>,</div>
<div class="line">              metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line">model.fit([data_a, data_b], labels, epochs=<span class="number">10</span>)</div>
</pre></td></tr></table></figure>
<h5 id="层“节点”的概念"><a href="#层“节点”的概念" class="headerlink" title="层“节点”的概念"></a>层“节点”的概念</h5><p>无论何时，当你在某个输入上调用层时，你就创建了一个新的张量（即该层的输出），同时你也在为这个层增加一个“（计算）节点”。这个节点将输入张量映射为输出张量。当你多次调用该层时，这个层就有了多个节点，其下标分别为0，1，2…在上一版本的Keras中，你可以通过<code>layer.get_output()</code>方法来获得层的输出张量，或者通过<code>layer.output_shape</code>获得其输出张量的shape。这个版本的Keras你仍然可以这么做（除了<code>layer.get_output()</code>被<code>output</code>替换）。但如果一个层与多个输入相连，会出现什么情况呢？如果层只与一个输入相连，那没有任何困惑的地方。<code>.output</code>将会返回该层唯一的输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">140</span>, <span class="number">256</span>))  lstm = LSTM(<span class="number">32</span>) encoded_a = lstm(a)  <span class="keyword">assert</span> lstm.output == encoded_a</div>
</pre></td></tr></table></figure>
<p>当层与多个输入相连时,</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">0</span>) == encoded_a </div>
<div class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">1</span>) == encoded_b</div>
</pre></td></tr></table></figure>
<p>对于<code>input_shape</code>和<code>output_shape</code>也是一样，如果一个层只有一个节点，或所有的节点都有相同的输入或输出shape，那么<code>input_shape</code>和<code>output_shape</code>都是没有歧义的，并也只返回一个值。但是，例如你把一个相同的<code>Conv2D</code>应用于一个大小为(32,32,3)的数据，然后又将其应用于一个(64,64,3)的数据，那么此时该层就具有了多个输入和输出的shape，你就需要显式的指定节点的下标，来表明你想取的是哪个了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
</pre></td><td class="code"><pre><div class="line">a = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</div>
<div class="line">b = Input(shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</div>
<div class="line"></div>
<div class="line">conv = Conv2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>)</div>
<div class="line">conved_a = conv(a)</div>
<div class="line"></div>
<div class="line"><span class="comment"># Only one input so far, the following will work:</span></div>
<div class="line"><span class="keyword">assert</span> conv.input_shape == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line"></div>
<div class="line">conved_b = conv(b)</div>
<div class="line"><span class="comment"># now the `.input_shape` property wouldn't work, but this does:</span></div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">0</span>) == (<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</div>
<div class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">1</span>) == (<span class="keyword">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</div>
</pre></td></tr></table></figure>
<h2 id="Keras网络层"><a href="#Keras网络层" class="headerlink" title="Keras网络层"></a>Keras网络层</h2><p>所有的Keras层对象都有如下方法:</p>
<ul>
<li><code>layer.get_weights()</code>：返回层的权重（numpy array）</li>
<li><code>layer.set_weights(weights)</code>：从numpy array中将权重加载到该层中，要求numpy array的形状与<code>layer.get_weights()</code>的形状相同</li>
<li><code>layer.get_config()</code>：返回当前层配置信息的字典，层也可以借由配置信息重构</li>
</ul>
<p>如果层仅有一个计算节点（即该层不是共享层），则可以通过下列方法获得输入张量、输出张量、输入数据的形状和输出数据的形状：</p>
<ul>
<li><code>layer.input</code></li>
<li><code>layer.output</code></li>
<li><code>layer.input_shape</code></li>
<li><code>layer.output_shape</code></li>
</ul>
<p>如果该层有多个计算节点。可以使用下面的方法</p>
<ul>
<li><code>layer.get_input_at(node_index)</code></li>
<li><code>layer.get_output_at(node_index)</code></li>
<li><code>layer.get_input_shape_at(node_index)</code></li>
<li><code>layer.get_output_shape_at(node_index)</code> </li>
</ul>
<h3 id="常用层"><a href="#常用层" class="headerlink" title="常用层"></a><a href="https://keras-cn.readthedocs.io/en/latest/layers/core_layer/" target="_blank" rel="noopener">常用层</a></h3><h4 id="Dense层"><a href="#Dense层" class="headerlink" title="Dense层"></a>Dense层</h4><p>Dense就是常用的全连接层，所实现的运算是<code>output = activation(dot(input, kernel)+bias)</code>。其中<code>activation</code>是逐元素计算的激活函数，<code>kernel</code>是本层的权值矩阵，<code>bias</code>为偏置向量，只有当<code>use_bias=True</code>才会添加。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.core.Dense(units, activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p><strong>参数</strong></p>
<ul>
<li>units：大于0的整数，代表该层的输出维度</li>
<li>activation：激活函数，默认不使用任何激活函数(即使用线性激活函数：a(x)=x)</li>
<li>use_bias: 布尔值，是否使用偏置项</li>
<li>kernel_initializer：权值初始化方法</li>
<li>bias_initializer：偏置向量初始化方法</li>
<li>kernel_regularizer | bias_regularizer | activity_regularizer：施加在 权重 | 偏置向量 | 输出 上的正则项</li>
<li>kernel_constraints | bias_constraints：施加在 权重 | 偏置上的约束项</li>
</ul>
<p><strong>输入</strong></p>
<ul>
<li>形如(batch_size, …, input_dim)的nD张量，最常见的情况为(batch_size, input_dim)的2D张量</li>
</ul>
<p><strong>输出</strong></p>
<ul>
<li>形如(batch_size, …, units)的nD张量，最常见的情况为(batch_size, units)的2D张量</li>
</ul>
<h4 id="Dropout层"><a href="#Dropout层" class="headerlink" title="Dropout层"></a>Dropout层</h4><p>为输入数据施加Dropout。Dropout将在训练过程中每次更新参数时按一定概率（rate）随机断开输入神经元，Dropout层用于防止过拟合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.core.Dropout(rate, noise_shape=<span class="keyword">None</span>, seed=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p><strong>参数</strong></p>
<ul>
<li>rate：0~1的浮点数，控制需要断开的神经元的比例</li>
</ul>
<h4 id="Flatten层"><a href="#Flatten层" class="headerlink" title="Flatten层"></a>Flatten层</h4><p>Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line">model = Sequential()</div>
<div class="line">model.add(Convolution2D(<span class="number">64</span>, <span class="number">3</span>, <span class="number">3</span>,</div>
<div class="line">            border_mode=<span class="string">'same'</span>,</div>
<div class="line">            input_shape=(<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)))</div>
<div class="line"><span class="comment"># now: model.output_shape == (None, 64, 32, 32)</span></div>
<div class="line"></div>
<div class="line">model.add(Flatten())</div>
<div class="line"><span class="comment"># now: model.output_shape == (None, 65536) # 65536 = 64*32*32</span></div>
</pre></td></tr></table></figure>
<h4 id="Lambda层"><a href="#Lambda层" class="headerlink" title="Lambda层"></a>Lambda层</h4><p>本函数用以对上一层的输出施以任何Theano/TensorFlow表达式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.core.Lambda(function, output_shape=<span class="keyword">None</span>, mask=<span class="keyword">None</span>, arguments=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p><strong>参数</strong></p>
<ul>
<li>function：要实现的函数，该函数仅接受一个变量，即上一层的输出</li>
<li>output_shape：函数应该返回的值的shape，可以是一个tuple，也可以是一个根据输入shape计算输出shape的函数</li>
<li>arguments：可选，字典，用来记录向函数中传递的其他关键字参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># add a x -&gt; x^2 layer</span></div>
<div class="line">model.add(Lambda(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>))</div>
</pre></td></tr></table></figure>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a><a href="https://keras-cn.readthedocs.io/en/latest/layers/convolutional_layer/" target="_blank" rel="noopener">卷积层</a></h3><h4 id="Conv2D层"><a href="#Conv2D层" class="headerlink" title="Conv2D层"></a>Conv2D层</h4><p>二维卷积层，即对图像的空域卷积。该层对二维输入进行滑动窗卷积，当使用该层作为第一层时，应提供<code>input_shape</code>参数。例如<code>input_shape = (128,128,3)</code>代表128*128的彩色RGB图像（<code>data_format=&#39;channels_last&#39;</code>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>, dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<p><strong>参数</strong></p>
<ul>
<li>filters：卷积核的数目（即输出的维度）</li>
<li>kernel_size：单个整数或由两个整数构成的list/tuple，卷积核的宽度和长度。如为单个整数，则表示在各个空间维度的相同长度。</li>
<li>strides：单个整数或由两个整数构成的list/tuple，为卷积的步长。如为单个整数，则表示在各个空间维度的相同步长。</li>
<li>padding：补0策略，为“valid”, “same” 。“valid”代表只进行有效的卷积，即对边界数据不处理。“same”代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同。</li>
<li>activation：激活函数，默认不使用激活函数</li>
<li>dilation_rate：单个整数或由两个个整数构成的list/tuple，指定dilated convolution中的膨胀比例。任何不为1的dilation_rate均与任何不为1的strides均不兼容。</li>
<li>data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。该参数是Keras 1.x中的image_dim_ordering，“channels_last”对应原本的“tf”，“channels_first”对应原本的“th”。以128x128的RGB图像为例，“channels_first”应将数据组织为（3,128,128），而“channels_last”应将数据组织为（128,128,3）。该参数的默认值是<code>~/.keras/keras.json</code>中设置的值，若从未设置过，为“channels_last”。</li>
</ul>
<p><strong>输入</strong></p>
<p>‘channels_first’模式下，输入形如（samples,channels，rows，cols）的4D张量</p>
<p>‘channels_last’模式下，输入形如（samples，rows，cols，channels）的4D张量</p>
<p>注意这里的输入shape指的是函数内部实现的输入shape，而非函数接口应指定的<code>input_shape</code></p>
<p><strong>输出</strong></p>
<p>‘channels_first’模式下，为形如（samples，nb_filter, new_rows, new_cols）的4D张量</p>
<p>‘channels_last’模式下，为形如（samples，new_rows, new_cols，nb_filter）的4D张量</p>
<p>输出的行列数可能会因为填充方法而改变</p>
<h4 id="Conv2DTranspose层"><a href="#Conv2DTranspose层" class="headerlink" title="Conv2DTranspose层"></a>Conv2DTranspose层</h4><p>该层是转置的卷积操作（反卷积）。需要反卷积的情况通常发生在用户想要对一个普通卷积的结果做反方向的变换。例如，将具有该卷积层输出shape的tensor转换为具有该卷积层输入shape的tensor。同时保留与卷积层兼容的连接模式。</p>
<p>当使用该层作为第一层时，应提供<code>input_shape</code>参数。例如<code>input_shape = (3,128,128)</code>代表128*128的彩色RGB图像</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.convolutional.Conv2DTranspose(filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>, activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a><a href="https://keras-cn.readthedocs.io/en/latest/layers/pooling_layer/" target="_blank" rel="noopener">池化层</a></h3><h4 id="MaxPooling2D层"><a href="#MaxPooling2D层" class="headerlink" title="MaxPooling2D层"></a>MaxPooling2D层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.pooling.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>pool_size：整数或长为2的整数tuple，代表在两个方向（竖直，水平）上的下采样因子，如取（2，2）将使图片在两个维度上均变为原长的一半。为整数意为各个维度值相同且为该数字。</li>
<li>strides：整数或长为2的整数tuple，或者None，步长值。</li>
<li>border_mode：‘valid’或者‘same’</li>
<li>data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。默认“channels_last”</li>
</ul>
<h4 id="AveragePooling2D层"><a href="#AveragePooling2D层" class="headerlink" title="AveragePooling2D层"></a>AveragePooling2D层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.pooling.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<h3 id="批正则化"><a href="#批正则化" class="headerlink" title="批正则化"></a><a href="https://keras-cn.readthedocs.io/en/latest/layers/normalization_layer/" target="_blank" rel="noopener">批正则化</a></h3><h4 id="BatchNormalization层"><a href="#BatchNormalization层" class="headerlink" title="BatchNormalization层"></a>BatchNormalization层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.layers.normalization.BatchNormalization(axis=<span class="number">-1</span>, momentum=<span class="number">0.99</span>, epsilon=<span class="number">0.001</span>, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>, beta_initializer=<span class="string">'zeros'</span>, gamma_initializer=<span class="string">'ones'</span>, moving_mean_initializer=<span class="string">'zeros'</span>, moving_variance_initializer=<span class="string">'ones'</span>, beta_regularizer=<span class="keyword">None</span>, gamma_regularizer=<span class="keyword">None</span>, beta_constraint=<span class="keyword">None</span>, gamma_constraint=<span class="keyword">None</span>)</div>
</pre></td></tr></table></figure>
<ul>
<li>momentum: 动态均值的动量</li>
<li>epsilon：大于0的小浮点数，用于防止除0错误</li>
<li>center: 若设为True，将会将beta作为偏置加上去，否则忽略参数beta</li>
</ul>
<blockquote>
<p>BN层的作用</p>
<p>（1）加速收敛 （2）控制过拟合，可以少用或不用Dropout和正则 （3）降低网络对初始化权重不敏感 （4）允许使用较大的学习率</p>
</blockquote>
<h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h2><h3 id="损失函数loss"><a href="#损失函数loss" class="headerlink" title="损失函数loss"></a>损失函数loss</h3><p>目标函数，或称损失函数，是编译一个模型必须的两个参数之一：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'sgd'</span>)</div>
</pre></td></tr></table></figure>
<p>自定义的损失函数：只接受两个参数</p>
<ul>
<li>y_true：真实的数据标签，Theano/TensorFlow张量</li>
<li>y_pred：预测值，与y_true相同shape的Theano/TensorFlow张量</li>
</ul>
<p>返回在各个数据点得到的损失函数值之和的均值</p>
<p><strong>部分可用的目标函数</strong></p>
<ul>
<li><p>mean_squared_error或mse</p>
</li>
<li><p>mean_absolute_error或mae</p>
</li>
<li><p>binary_crossentropy（亦称作对数损失，logloss）</p>
</li>
<li><p>categorical_crossentropy：亦称作多类的对数损失，注意使用该目标函数时，需要将标签转化为形如<code>(nb_samples, nb_classes)</code>的二值序列</p>
<blockquote>
<p><strong>注意</strong>: 当使用”categorical_crossentropy”作为目标函数时,标签应该为多类模式,即one-hot编码的向量,而不是单个数值. 可以使用工具中的<code>to_categorical</code>函数完成该转换.示例如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">&gt; <span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</div>
<div class="line">&gt; </div>
<div class="line">&gt; categorical_labels = to_categorical(int_labels, num_classes=<span class="keyword">None</span>)</div>
<div class="line">&gt;</div>
</pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<h3 id="优化器optimizers"><a href="#优化器optimizers" class="headerlink" title="优化器optimizers"></a>优化器optimizers</h3><p>优化器是编译Keras模型必要的另一个参数</p>
<p>可以在调用<code>model.compile()</code>之前初始化一个优化器对象，然后传入该函数，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="keyword">True</span>)</div>
<div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=sgd)</div>
</pre></td></tr></table></figure>
<p>也可以在调用<code>model.compile()</code>时传递一个预定义优化器名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># pass optimizer by name: default parameters will be used</span></div>
<div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'sgd'</span>)</div>
</pre></td></tr></table></figure>
<p>参数<code>clipnorm</code>和<code>clipvalue</code>是所有优化器都可以使用的参数,用于对梯度进行裁剪</p>
<h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.optimizers.SGD(lr=<span class="number">0.01</span>, momentum=<span class="number">0.0</span>, decay=<span class="number">0.0</span>, nesterov=<span class="keyword">False</span>, clipnorm=<span class="number">1.</span>)</div>
</pre></td></tr></table></figure>
<p>随机梯度下降法，支持动量参数，支持学习衰减率，支持Nesterov动量</p>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.optimizers.Adam(lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="number">1e-08</span>)</div>
</pre></td></tr></table></figure>
<h3 id="激活函数Activations"><a href="#激活函数Activations" class="headerlink" title="激活函数Activations"></a>激活函数Activations</h3><p>激活函数可以通过设置单独的<a href="https://keras-cn.readthedocs.io/en/latest/layers/core_layer/#activation" target="_blank" rel="noopener">激活层</a>实现，也可以在构造层对象时通过传递<code>activation</code>参数实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation, Dense</div>
<div class="line">model.add(Dense(<span class="number">64</span>))</div>
<div class="line">model.add(Activation(<span class="string">'tanh'</span>))</div>
</pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">'tanh'</span>))</div>
</pre></td></tr></table></figure>
<p><strong>预定义激活函数</strong></p>
<ul>
<li>softmax：对输入数据的最后一维进行softmax，输入数据应形如<code>(nb_samples, nb_timesteps, nb_dims)</code>或<code>(nb_samples,nb_dims)</code></li>
<li>elu</li>
<li>selu: 可伸缩的指数线性单元（Scaled Exponential Linear Unit），参考<a href="https://arxiv.org/abs/1706.02515" target="_blank" rel="noopener">Self-Normalizing Neural Networks</a></li>
<li>softplus</li>
<li>softsign</li>
<li>relu</li>
<li>tanh</li>
<li>sigmoid</li>
<li>hard_sigmoid</li>
<li>linear</li>
</ul>
<h3 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h3><p>性能评估模块提供了一系列用于模型性能评估的函数,这些函数在模型编译时由<code>metrics</code>关键字设置</p>
<p>可以通过字符串来使用域定义的性能评估函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>,</div>
<div class="line">              optimizer=<span class="string">'sgd'</span>,</div>
<div class="line">              metrics=[<span class="string">'mae'</span>, <span class="string">'acc'</span>])</div>
</pre></td></tr></table></figure>
<p>也可以自定义一个Theano/TensorFlow函数并使用之</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> metrics</div>
<div class="line"></div>
<div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>,</div>
<div class="line">              optimizer=<span class="string">'sgd'</span>,</div>
<div class="line">              metrics=[metrics.mae, metrics.categorical_accuracy])</div>
</pre></td></tr></table></figure>
<h3 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h3><p>初始化方法定义了对Keras层设置初始化权重的方法</p>
<p>不同的层可能使用不同的关键字来传递初始化方法，一般来说指定初始化方法的关键字是<code>kernel_initializer</code> 和 <code>bias_initializer</code>，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">model.add(Dense(<span class="number">64</span>,</div>
<div class="line">                kernel_initializer=<span class="string">'random_uniform'</span>,</div>
<div class="line">                bias_initializer=<span class="string">'zeros'</span>))</div>
</pre></td></tr></table></figure>
<p><strong>预定义初始化方法</strong></p>
<ul>
<li>Zeros</li>
<li>Ones</li>
<li>Constant</li>
<li>RandomNormal</li>
<li>RandomUniform</li>
</ul>
<h3 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a><a href="https://keras-cn.readthedocs.io/en/latest/other/callbacks/" target="_blank" rel="noopener">回调函数</a></h3><p>回调函数是一组在训练的特定阶段被调用的函数集，你可以使用回调函数来观察训练过程中网络内部的状态和统计信息。通过传递回调函数列表到模型的<code>.fit()</code>中，即可在给定的训练阶段调用该函数集中的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
</pre></td><td class="code"><pre><div class="line">keras.callbacks.Callback()</div>
</pre></td></tr></table></figure>
<p>这是回调函数的抽象类，定义新的回调函数必须继承自该类</p>
<h3 id="类属性"><a href="#类属性" class="headerlink" title="类属性"></a>类属性</h3><ul>
<li>params：字典，训练参数集（如信息显示方法verbosity，batch大小，epoch数）</li>
<li>model：<code>keras.models.Model</code>对象，为正在训练的模型的引用</li>
</ul>
<p>回调函数以字典<code>logs</code>为参数，该字典包含了一系列与当前batch或epoch相关的信息。</p>
<p>目前，模型的<code>.fit()</code>中有下列参数会被记录到<code>logs</code>中：</p>
<ul>
<li>在每个epoch的结尾处（on_epoch_end），<code>logs</code>将包含训练的正确率和误差，<code>acc</code>和<code>loss</code>，如果指定了验证集，还会包含验证集正确率和误差<code>val_acc)</code>和<code>val_loss</code>，<code>val_acc</code>还额外需要在<code>.compile</code>中启用<code>metrics=[&#39;accuracy&#39;]</code>。</li>
<li>在每个batch的开始处（on_batch_begin）：<code>logs</code>包含<code>size</code>，即当前batch的样本数</li>
<li>在每个batch的结尾处（on_batch_end）：<code>logs</code>包含<code>loss</code>，若启用<code>accuracy</code>则还包含<code>acc</code></li>
</ul>
<h2 id="Keras后端"><a href="#Keras后端" class="headerlink" title="Keras后端"></a><a href="https://keras-cn.readthedocs.io/en/latest/backend/" target="_blank" rel="noopener">Keras后端</a></h2><h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><h4 id="模型保存-1"><a href="#模型保存-1" class="headerlink" title="模型保存"></a>模型保存</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">json_string = model.to_json()</div>
<div class="line">open(<span class="string">'model.json'</span>, <span class="string">'w'</span>).write(json_string)</div>
<div class="line">model.save_weights(<span class="string">'weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h4 id="模型载入"><a href="#模型载入" class="headerlink" title="模型载入"></a>模型载入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div>
<div class="line">model = model_from_json(open(<span class="string">'keras_modelB/model.json'</span>).read())</div>
<div class="line">model.load_weights(<span class="string">'keras_modelB/weights.h5'</span>)</div>
</pre></td></tr></table></figure>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div>
<div class="line">model.save(<span class="string">'my_model.h5'</span>)</div>
<div class="line">model = load_model(<span class="string">'my_model.h5'</span>)</div>
</pre></td></tr></table></figure>
<h1 id="Keras构建神经网络"><a href="#Keras构建神经网络" class="headerlink" title="Keras构建神经网络"></a>Keras构建神经网络</h1><p><img src="/2018/07/23/Keras/1119747-20170707133932722-715494711.png" alt="1119747-20170707133932722-715494711"></p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="符号计算-数据流图"><a href="#符号计算-数据流图" class="headerlink" title="符号计算(数据流图)"></a>符号计算(数据流图)</h2><p>Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。</p>
<h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p>张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。</p>
<p>0阶张量,即标量,是一个数。</p>
<p>1阶张量,即向量,一组有序排列的数</p>
<p>2阶张量,即矩阵,一组向量有序的排列起来</p>
<p>3阶张量，即立方体，一组矩阵上下排列起来</p>
<p>4阶张量……</p>
<h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><p>目前主要有两种方式来表示张量：</p>
<ol>
<li>th模式或channels_first模式，Theano和caffe使用此模式。</li>
<li>tf模式或channels_last模式，TensorFlow使用此模式。</li>
</ol>
<p>下面举例说明两种模式的区别：<br>对于100张RGB3通道的16×32（高为16宽为32）彩色图，<br>th表示方式：（100,3,16,32）<br>tf表示方式：（100,16,32,3）<br>唯一的区别就是表示通道个数3的位置不一样。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。           </p>
<ol>
<li>序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单           </li>
<li>函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。</li>
</ol>
<h1 id="Example：手写数字识别"><a href="#Example：手写数字识别" class="headerlink" title="Example：手写数字识别"></a>Example：手写数字识别</h1><p><img src="/2018/07/23/Keras/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Keras/CNNArchitecture.jpg" alt="CNNArchitecture"></p>
<ol>
<li><p>基本库导入</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div>
<div class="line"><span class="keyword">import</span> keras</div>
<div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
</pre></td></tr></table></figure>

</div></div>
</li>
<li><p>参数设置</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
<div class="line">32</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># batch_size 太小会导致训练慢，过拟合等问题，太大会导致欠拟合。所以要适当选择</span></div>
<div class="line">batch_size = <span class="number">128</span></div>
<div class="line"><span class="comment"># 0-9手写数字一个有10个类别</span></div>
<div class="line">num_classes = <span class="number">10</span></div>
<div class="line"><span class="comment"># 12次完整迭代，差不多够了</span></div>
<div class="line">epochs = <span class="number">12</span></div>
<div class="line"><span class="comment"># 输入的图片是28*28像素的灰度图</span></div>
<div class="line">img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span></div>
<div class="line"><span class="comment"># 训练集，测试集收集非常方便</span></div>
<div class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># keras输入数据有两种格式，一种是通道数放在前面，一种是通道数放在后面，</span></div>
<div class="line"><span class="comment"># 其实就是格式差别而已</span></div>
<div class="line"><span class="keyword">if</span> K.image_data_format() == <span class="string">'channels_first'</span>:</div>
<div class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</div>
<div class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</div>
<div class="line">    input_shape = (<span class="number">1</span>, img_rows, img_cols)</div>
<div class="line"><span class="keyword">else</span>:</div>
<div class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</div>
<div class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</div>
<div class="line">    input_shape = (img_rows, img_cols, <span class="number">1</span>)</div>
<div class="line"><span class="comment"># 把数据变成float32更精确</span></div>
<div class="line">x_train = x_train.astype(<span class="string">'float32'</span>)</div>
<div class="line">x_test = x_test.astype(<span class="string">'float32'</span>)</div>
<div class="line">x_train /= <span class="number">255</span></div>
<div class="line">x_test /= <span class="number">255</span></div>
<div class="line">print(<span class="string">'x_train shape:'</span>, x_train.shape)</div>
<div class="line">print(x_train.shape[<span class="number">0</span>], <span class="string">'train samples'</span>)</div>
<div class="line">print(x_test.shape[<span class="number">0</span>], <span class="string">'test samples'</span>)</div>
<div class="line"><span class="comment"># 把类别0-9变成2进制，方便训练</span></div>
<div class="line">y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)</div>
<div class="line">y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)</div>
</pre></td></tr></table></figure>

</div></div>
</li>
<li><p>构建网络层</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
<div class="line">28</div>
<div class="line">29</div>
<div class="line">30</div>
<div class="line">31</div>
</pre></td><td class="code"><pre><div class="line">model = Sequential()</div>
<div class="line"><span class="comment"># 加上一个2D卷积层， 32个输出（也就是卷积通道），激活函数选用relu，</span></div>
<div class="line"><span class="comment"># 卷积核的窗口选用3*3像素窗口</span></div>
<div class="line">model.add(Conv2D(<span class="number">32</span>,</div>
<div class="line">                 activation=<span class="string">'relu'</span>,</div>
<div class="line">                 input_shape=input_shape,</div>
<div class="line">                 nb_row=<span class="number">3</span>,</div>
<div class="line">                 nb_col=<span class="number">3</span>))</div>
<div class="line"><span class="comment"># 64个通道的卷积层</span></div>
<div class="line">model.add(Conv2D(<span class="number">64</span>, activation=<span class="string">'relu'</span>,</div>
<div class="line">                 nb_row=<span class="number">3</span>,</div>
<div class="line">                 nb_col=<span class="number">3</span>))</div>
<div class="line"><span class="comment"># 池化层是2*2像素的</span></div>
<div class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div>
<div class="line"><span class="comment"># 对于池化层的输出，采用0.35概率的Dropout</span></div>
<div class="line">model.add(Dropout(<span class="number">0.35</span>))</div>
<div class="line"><span class="comment"># 展平所有像素，比如[28*28] -&gt; [784]</span></div>
<div class="line">model.add(Flatten())</div>
<div class="line"><span class="comment"># 对所有像素使用全连接层，输出为128，激活函数选用relu</span></div>
<div class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div>
<div class="line"><span class="comment"># 对输入采用0.5概率的Dropout</span></div>
<div class="line">model.add(Dropout(<span class="number">0.5</span>))</div>
<div class="line"><span class="comment"># 对刚才Dropout的输出采用softmax激活函数，得到最后结果0-9</span></div>
<div class="line">model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div>
<div class="line"><span class="comment"># 模型我们使用交叉熵损失函数，最优化方法选用Adadelta</span></div>
<div class="line">model.compile(loss=keras.metrics.categorical_crossentropy,</div>
<div class="line">              optimizer=keras.optimizers.Adadelta(),</div>
<div class="line">              metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line"><span class="comment"># 令人兴奋的训练过程</span></div>
<div class="line">model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,</div>
<div class="line">          verbose=<span class="number">1</span>, validation_data=(x_test, y_test))</div>
</pre></td></tr></table></figure>

</div></div>
</li>
<li><p>模型预测</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</div>
<div class="line">print(<span class="string">'Test loss:'</span>, score[<span class="number">0</span>])</div>
<div class="line">print(<span class="string">'Test accuracy:'</span>, score[<span class="number">1</span>])</div>
</pre></td></tr></table></figure>

</div></div>
</li>
</ol>
<h1 id="Example：CNN"><a href="#Example：CNN" class="headerlink" title="Example：CNN"></a>Example：CNN</h1><p><img src="/2018/07/23/Keras/1119747-20170809132648824-260187979.png" alt="1119747-20170809132648824-260187979"></p>
<ol>
<li><p>模块导入</p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div>
<div class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Convolution2D, ZeroPadding2D, MaxPooling2D</div>
<div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div>
</pre></td></tr></table></figure>

</div></div>
</li>
<li></li>
</ol>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>

<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>

<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">

</div></div>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/Keras/" rel="tag"># Keras</a>
          
            <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/22/AutoEncoder/" rel="next" title="AutoEncoder">
                <i class="fa fa-chevron-left"></i> AutoEncoder
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/24/Neural-Network/" rel="prev" title="Neural Network">
                Neural Network <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">68</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras模块结构"><span class="nav-number">1.</span> <span class="nav-text">Keras模块结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#模型"><span class="nav-number">1.1.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#序贯（Sequential）模型"><span class="nav-number">1.1.1.</span> <span class="nav-text">序贯（Sequential）模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络构造"><span class="nav-number">1.1.2.</span> <span class="nav-text">网络构造</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编译"><span class="nav-number">1.1.3.</span> <span class="nav-text">编译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-number">1.1.4.</span> <span class="nav-text">训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#函数式（Functional）模型"><span class="nav-number">1.1.5.</span> <span class="nav-text">函数式（Functional）模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#应用场景1：全连接网络"><span class="nav-number">1.1.5.1.</span> <span class="nav-text">应用场景1：全连接网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用场景2：多输入多输出模型"><span class="nav-number">1.1.5.2.</span> <span class="nav-text">应用场景2：多输入多输出模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用场景3：共享层"><span class="nav-number">1.1.5.3.</span> <span class="nav-text">应用场景3：共享层</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#层“节点”的概念"><span class="nav-number">1.1.5.3.1.</span> <span class="nav-text">层“节点”的概念</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keras网络层"><span class="nav-number">1.2.</span> <span class="nav-text">Keras网络层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#常用层"><span class="nav-number">1.2.1.</span> <span class="nav-text">常用层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Dense层"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">Dense层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dropout层"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">Dropout层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flatten层"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">Flatten层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Lambda层"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">Lambda层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层"><span class="nav-number">1.2.2.</span> <span class="nav-text">卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Conv2D层"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Conv2D层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conv2DTranspose层"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">Conv2DTranspose层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层"><span class="nav-number">1.2.3.</span> <span class="nav-text">池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MaxPooling2D层"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">MaxPooling2D层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AveragePooling2D层"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">AveragePooling2D层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#批正则化"><span class="nav-number">1.2.4.</span> <span class="nav-text">批正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BatchNormalization层"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">BatchNormalization层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络配置"><span class="nav-number">1.3.</span> <span class="nav-text">网络配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数loss"><span class="nav-number">1.3.1.</span> <span class="nav-text">损失函数loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化器optimizers"><span class="nav-number">1.3.2.</span> <span class="nav-text">优化器optimizers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SGD"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">SGD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adam"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">Adam</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数Activations"><span class="nav-number">1.3.3.</span> <span class="nav-text">激活函数Activations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#性能评估"><span class="nav-number">1.3.4.</span> <span class="nav-text">性能评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#初始化方法"><span class="nav-number">1.3.5.</span> <span class="nav-text">初始化方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#回调函数"><span class="nav-number">1.3.6.</span> <span class="nav-text">回调函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#类属性"><span class="nav-number">1.3.7.</span> <span class="nav-text">类属性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keras后端"><span class="nav-number">1.4.</span> <span class="nav-text">Keras后端</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型保存"><span class="nav-number">1.5.</span> <span class="nav-text">模型保存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#方法一"><span class="nav-number">1.5.1.</span> <span class="nav-text">方法一</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型保存-1"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">模型保存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型载入"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">模型载入</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方法二"><span class="nav-number">1.5.2.</span> <span class="nav-text">方法二</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keras构建神经网络"><span class="nav-number">2.</span> <span class="nav-text">Keras构建神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本概念"><span class="nav-number">3.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#符号计算-数据流图"><span class="nav-number">3.1.</span> <span class="nav-text">符号计算(数据流图)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#张量"><span class="nav-number">3.2.</span> <span class="nav-text">张量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据格式"><span class="nav-number">3.3.</span> <span class="nav-text">数据格式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型-1"><span class="nav-number">3.4.</span> <span class="nav-text">模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Example：手写数字识别"><span class="nav-number">4.</span> <span class="nav-text">Example：手写数字识别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Example：CNN"><span class="nav-number">5.</span> <span class="nav-text">Example：CNN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">6.</span> <span class="nav-text"> </span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
