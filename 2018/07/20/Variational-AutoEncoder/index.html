<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,Variational AutoEncoder," />










<meta name="description" content="AutoEncoder（自编码器）本质上是数据特定的数据压缩。虽然自编码器中的重构损失函数确保了编码过程原始数据不会丢失过多，但是没有对约束特征$z$做出约束。 作为一种无监督的学习方法，VAE（Variational Auto-Encoder，变分自编码器）是一个产生式模型，其在ae的基础上约束潜变量$z$服从于某个已知的先验分布$p(z|x)$，比如希望$z$的每个特征相互独立并且符合高斯分">
<meta name="keywords" content="Deep Learning,Variational AutoEncoder">
<meta property="og:type" content="article">
<meta property="og:title" content="Variational AutoEncoder">
<meta property="og:url" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:description" content="AutoEncoder（自编码器）本质上是数据特定的数据压缩。虽然自编码器中的重构损失函数确保了编码过程原始数据不会丢失过多，但是没有对约束特征$z$做出约束。 作为一种无监督的学习方法，VAE（Variational Auto-Encoder，变分自编码器）是一个产生式模型，其在ae的基础上约束潜变量$z$服从于某个已知的先验分布$p(z|x)$，比如希望$z$的每个特征相互独立并且符合高斯分">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/v2-0533fd3dc73184f807038b4f08e8681a_hd.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/v2-89c7d409bcb7a8218c80b3134b015818_hd.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/Screen%20Shot%202018-07-24%20at%201.05.03%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Variational-AutoEncoder/2689906124.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/8da0009b298c462b9dba190f21f594f5.jpeg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/Screen%20Shot%202018-07-23%20at%2011.15.34%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/Screen%20Shot%202018-07-23%20at%2011.16.40%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/Screen%20Shot%202018-07-22%20at%201.12.06%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/11.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/20161214175120686.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/20161214175146348.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/20161214175029514.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/image-20180724163307750.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/image-20180724163319485.png">
<meta property="og:updated_time" content="2019-08-10T22:55:49.031Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Variational AutoEncoder">
<meta name="twitter:description" content="AutoEncoder（自编码器）本质上是数据特定的数据压缩。虽然自编码器中的重构损失函数确保了编码过程原始数据不会丢失过多，但是没有对约束特征$z$做出约束。 作为一种无监督的学习方法，VAE（Variational Auto-Encoder，变分自编码器）是一个产生式模型，其在ae的基础上约束潜变量$z$服从于某个已知的先验分布$p(z|x)$，比如希望$z$的每个特征相互独立并且符合高斯分">
<meta name="twitter:image" content="http://yoursite.com/2018/07/20/Variational-AutoEncoder/v2-0533fd3dc73184f807038b4f08e8681a_hd.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/20/Variational-AutoEncoder/"/>





  <title>Variational AutoEncoder | Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/20/Variational-AutoEncoder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Variational AutoEncoder</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-20T16:23:15+08:00">
                2018-07-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p> AutoEncoder（自编码器）本质上是数据特定的数据压缩。虽然自编码器中的重构损失函数确保了编码过程原始数据不会丢失过多，但是没有对约束特征$z$做出约束。</p>
<p>作为一种无监督的学习方法，VAE（Variational Auto-Encoder，变分自编码器）是一个产生式模型，其在ae的基础上约束潜变量$z$服从于某个已知的先验分布$p(z|x)$，比如希望$z$的每个特征相互独立并且符合高斯分布等。</p>
<a id="more"></a>
<h1 id="判别式模型-VS-生成式模型"><a href="#判别式模型-VS-生成式模型" class="headerlink" title="判别式模型 VS 生成式模型"></a>判别式模型 VS 生成式模型</h1><p><a href="http://www.cnblogs.com/kemaswill/p/3427422.html" target="_blank" rel="noopener">ref1</a> <a href="https://blog.csdn.net/heyc861221/article/details/80130968" target="_blank" rel="noopener">ref2</a> </p>
<blockquote>
<p>给定数据样本$D=\{x_1,x_2,…,x_n\}$，及其对应的标签$\{y_1,y_2,…,y_n\}$.</p>
<p>判别式模型：直接对$p(y|x)$进行建模</p>
<p>生成式模型：对$x$和$y$的联合分布$p(x,y)$进行建模，然后通过贝叶斯公式来求得$p(y|x)$，最后选择使$p(y|x)$最大的$y_i$。</p>
</blockquote>
<p>判别式模型大多有下面的规律：已知观察变量X，和隐含变量z，判别式模型对p(z|X)进行建模，它根据输入的观察变量x得到隐含变量z出现的可能性。生成式模型则是将两者的顺序反过来，它要对p(X|z)进行建模，输入是隐含变量，输出是观察变量的概率。</p>
<p>可以想象，不同的模型结构自然有不同的用途。判别模型在判别工作上更适合，生成模型在分布估计等问题上更有优势。如果想用生成式模型去解决判别问题，就需要利用贝叶斯公式把这个问题转换成适合自己处理的样子：</p>
<script type="math/tex; mode=display">
p(z | X)=\frac{p(X | z) p(z)}{p(X)}</script><p>对于一些简单的问题，上面的公式还是比较容易解出的，但对于一些复杂的问题，找出从隐含变量到观察变量之间的关系是一件很困难的事情，生成式模型的建模过程会非常困难，所以对于判别类问题，判别式模型一般更适合。</p>
<p>但对于“随机生成满足某些隐含变量特点的数据”这样的问题来说，判别式模型就会显得力不从心。如果用判别式模型生成数据，就要通过类似于下面这种方式的方法进行。</p>
<p>第一步，利用简单随机一个X。</p>
<p>第二步，用判别式模型计算p(z|X)概率，如果概率满足，则找到了这个观察数据，如果不满足，返回第一步。</p>
<p>这样用判别式模型生成数据的效率可能会十分低下。而生成式模型解决这个问题就十分简单，首先确定好z的取值，然后根据p(X|z)的分布进行随机采样就行了</p>
<h1 id="Intuition-behind-VAE"><a href="#Intuition-behind-VAE" class="headerlink" title="Intuition behind VAE"></a>Intuition behind VAE</h1><p>该部分参考了<a href="https://zhuanlan.zhihu.com/p/25269592" target="_blank" rel="noopener">ZhiHu-VAE</a>.</p>
<p>考虑MNIST数据集，数据集里有10种数字，每种数字下有几千个不同的样本，我们能不能照猫画虎，模仿已有的数字生成一个同样可辨识，但却与现有的样本都不同的的数字呢？</p>
<p>要解决这个问题，需要对数字的分布进行建模。我们需要知道一个数字“一般而言长什么样”。如果我们得到了数据集X的分布P(X)，那么数据集中的每个图片，也不过就是从P(X)采样得到的一个样本而已。可以说掌握了P(X)，我们就算把这个数据集的底裤都扒下来了，到时候搓扁捏圆，任君所愿。</p>
<p>然而从有限的样本中估计出数据原来的分布情况，却不是一件容易的事，别说更复杂的数据集了，就是MNIST你也做不好。为了能估计P(X)，我们做一个隐变量假设，假设数据集X实际上是由一组我们观察不到的隐变量Z经过某个复杂的映射$P(z|x)$产生的，给定一个z，我就能通过某种方法生成一个样本$\hat x$。如果能得到z的分布和$P(z|x)$，那P(X)我们也算知道了。</p>
<p>这个假设是有道理的，z尽管是隐变量，但不妨碍我们对它的物理含义做出猜测。比方说z里面有控制笔画粗细的变量，有控制笔划角度的变量，有控制数字大小的变量等等。这些变量一旦确定，写出来的数字大致长什么样就确定了。</p>
<p>但是，P(X)分布的形式未知这点很好理解，但凭什么P(Z)能服从标准n维高斯分布呢？比方z里面有个控制比划粗细的变量，它怎么可能是高斯分布呢？答案隐藏在$P(z|x)$中：<strong>对于任意d维随机变量，不管他们实际上服从什么分布，我总可以用d个服从标准高斯分布的随机变量通过一个足够复杂的函数去逼近它。</strong>我们可以这样理解，z其实是“隐变量的隐变量”，函数$P(z|x)$实际上首先将z映射到某一组隐变量z’，这个z’可能就是上面说的笔划粗细啊，角度什么的有物理含义的东西，然后接着再把z’映射到X得到样本。</p>
<h1 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h1><p><img src="/2018/07/20/Variational-AutoEncoder/v2-0533fd3dc73184f807038b4f08e8681a_hd.jpg" alt="v2-0533fd3dc73184f807038b4f08e8681a_hd"></p>
<p>变分编码器和自动编码器的区别就在于，传统自动编码器的隐变量z的分布是不知道的，因此我们无法采样得到新的z，也就无法通过解码器得到新的x。下面我们来变分，我们现在不要从x中直接得到z，而是得到z的均值和方差，然后再迫使它逼近正态分布的均值和方差，则网络变成下面的样子：</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/v2-89c7d409bcb7a8218c80b3134b015818_hd.jpg" alt="v2-89c7d409bcb7a8218c80b3134b015818_hd"></p>
<p>看上去不错，从Q(z|x)估计出来的值跟标准正态分布不一样没关系，训练过程中慢慢逼近就行了。假定z服从高斯分布的好处之一在这里就能体现出来，只要估计均值和方差，我们就完全了解这个高斯分布了，也就能从其中采样了。</p>
<p>然而上面这个网络最大的问题是，它是<strong>断开</strong>的。前半截是从数据集估计z的分布，后半截是从一个z的样本重构输入。最关键的采样这一步，恰好不是一个我们传统意义上的操作。这个网络没法求导，因为梯度传到f(z)以后没办法往前走了。</p>
<p>为了使得整个网络得以训练，使用一种叫<strong>reparemerization</strong>的trick，使得网络对均值和方差可导，把网络连起来。这个trick的idea见下图：</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/Screen Shot 2018-07-24 at 1.05.03 PM.png" alt="Screen Shot 2018-07-24 at 1.05.03 PM"></p>
<h1 id="Math-in-VAE"><a href="#Math-in-VAE" class="headerlink" title="Math in VAE"></a>Math in VAE</h1><p><a href="https://spaces.ac.cn/archives/5253" target="_blank" rel="noopener">REF</a> </p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>假设我们有一批数据样本$\left\{X_{1}, \ldots, X_{n}\}\right.$, 其整体用$X$来描述，我们想用$\left\{X_{1}, \ldots, X_{n}\}\right.$得到$X$的分布$p(X)$，如果可以实现的话，那我们就可以根据$p(X)$来采样，就可能得到所有可能的$X$了，包括$\left\{X_{1}, \ldots, X_{n}\}\right.$以外的样本，这就是一个生成模型了。但是这个很难去实现，于是我们将分布改一下：</p>
<script type="math/tex; mode=display">
p(X)=\sum_{Z} p(X | Z) p(Z)</script><p>此时$p(X|Z)$描述了一个由$Z$生成$X$的模型，如果我们假设$Z$服从标准正态分布，即$p(Z)=\mathcal{N}(0, I)$ 。</p>
<p>如果这个实现，我们就可以先从标准正态分布中采样一个$Z$，然后根据$Z$来算一个$X$，也是一个很棒的生成模型。接下来就是结合自编码器来实现重构，保证有效信息没有丢失，再加上一系列的推导，最后把模型实现。框架的示意图如下：</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Variational-AutoEncoder/2689906124.png" alt="68990612"></p>
<p>但是，在整个VAE模型中，我们并没有去使用$p(Z)$（隐变量空间的分布）是正态分布的假设，我们用的是假设$p(Z|X)$（后验分布）是正态分布！！</p>
<p>具体来说，给定一个真实样本$Xk$，我们假设存在一个专属于$Xk$的分布$p(Z|X_k)$（学名叫后验分布），并进一步假设这个分布是（独立的、多元的）正态分布。为什么要强调“专属”呢？因为我们后面要训练一个生成器$X=g(Z)$，希望能够把从分布$p(Z|X_k)$采样出来的一个$Z_k$还原为$X_k$。如果假设$p(Z)$是正态分布，然后从$p(Z)$中采样一个$Z$，那么我们怎么知道这个$Z$对应于哪个真实的$X$呢？现在$p(Z|X_k)$专属于$X_k$，我们有理由说从这个分布采样出来的ZZ应该要还原到$X_k$中去。</p>
<p>这时候每一个$X_k$都配上了一个专属的正态分布，才方便后面的生成器做还原。但这样有多少个$X$就有多少个正态分布了。我们知道正态分布有两组参数：均值$\mu$和方差$\sigma^2$（多元的话，它们都是向量），那我怎么找出专属于$X_k$的正态分布$p(Z|X_k)$的均值和方差呢？用神经网络来拟合出来吧！</p>
<p>于是我们构建两个神经网络$\mu_k=f_1(X_k),log\sigma^{2}_k=f_2(X_k)$来算它们了。我们选择拟合$log\sigma^2_k$而不是直接拟合$\sigma^2_k$，是因为$\sigma^2_k$总是非负的，需要加激活函数处理，而拟合$log\sigma^2_k$不需要加激活函数，因为它可正可负。到这里，我能知道专属于$X_k$的均值和方差了，也就知道它的正态分布长什么样了，然后从这个专属分布中采样一个$Z_k$出来，然后经过一个生成器得到$\hat X_k=g(Z_k)$，现在我们可以放心地最小化$\mathcal{D}\left(\hat{X}_{k}, X_{k}\right)^{2}$，因为$Z_k$是从专属$X_k$的分布中采样出来的，这个生成器应该要把开始的$X_k$还原回来。于是可以画出VAE的示意图</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/8da0009b298c462b9dba190f21f594f5.jpeg" alt="8da0009b298c462b9dba190f21f594f5"></p>
<p>让我们来思考一下，根据上图的训练过程，最终会得到什么结果。</p>
<p>首先，我们希望重构$X$，也就是最小化$\mathcal{D}\left(\hat{X}_{k}, X_{k}\right)^{2}$，但是这个重构过程受到噪声的影响，因为$Z_k$是通过重新采样过的，不是直接由encoder算出来的。显然噪声会增加重构的难度，不过好在这个噪声强度（也就是方差）通过一个神经网络算出来的，所以最终模型为了重构得更好，肯定会想尽办法让方差为0。而方差为0的话，也就没有随机性了，所以不管怎么采样其实都只是得到确定的结果（也就是均值），只拟合一个当然比拟合多个要容易，而均值是通过另外一个神经网络算出来的。</p>
<p>说白了，模型会慢慢退化成普通的AutoEncoder，噪声不再起作用。</p>
<p>这样不就白费力气了吗？说好的生成模型呢？</p>
<p>别急别急，其实<strong>VAE还让所有的$p(Z|X)$都向标准正态分布看齐</strong>，这样就防止了噪声为零，同时保证了模型具有生成能力。怎么理解“保证了生成能力”呢？如果所有的$p(Z|X)$都很接近标准正态分布$N(0,I)$，那么根据定义</p>
<script type="math/tex; mode=display">
p(Z)=\sum_{X} p(Z | X) p(X)=\sum_{X} \mathcal{N}(0, I) p(X)=\mathcal{N}(0, I) \sum_{X} p(X)=\mathcal{N}(0, I)</script><p>这样我们就能达到我们的先验假设：$p(Z)$是标准正态分布。然后我们就可以放心地从$N(0,I)$中采样来生成图像了。</p>
<p>那如何让$p(Z|X)$接近标准正态分布$N(0,I)$呢？其实最直接的方法应该是在重构误差的基础上中加入额外的loss：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\mu}=\left\|f_{1}\left(X_{k}\right)\right\|^{2} \quad \mathbb{and}  \quad \mathcal{L}_{\sigma^{2}}=\left\|f_{2}\left(X_{k}\right)\right\|^{2}</script><p>因为它们分别代表了均值$\mu_k$和方差的对数$\log \sigma_{k}^{2}$，达到$N(0,I)$就是希望二者尽量接近0。不过，这又会面临着这两个损失的比例要怎么选取的问题，选取得不好，生成的图像会比较模糊。所以，原论文直接算了一般（各分量独立的）正态分布与标准正态分布的KL散度$K L\left(N\left(\mu, \sigma^{2}\right) | N(0, I)\right)$作为这个额外的loss，计算结果为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\mu, \sigma^{2}}=\frac{1}{2} \sum_{i=1}^{d}\left(\mu_{(i)}^{2}+\sigma_{(i)}^{2}-\log \sigma_{(i)}^{2}-1\right)</script><p>这里$d$是隐变量$Z$的维度，而$\mu_{(i)}$和$\log \sigma_{(i)}^{2}$分别代表一般正态分布的均值向量和方差向量的第$i$个分量。直接用这个式子做补充loss，就不用考虑均值损失和方差损失的相对比例问题了。显然，这个loss也可以分两部分理解：</p>
<script type="math/tex; mode=display">
\begin{array}{l}{\mathcal{L}_{\mu, \sigma^{2}}=\mathcal{L}_{\mu}+\mathcal{L}_{\sigma^{2}}} \\ {\mathcal{L}_{\mu}=\frac{1}{2} \sum_{i=1}^{d} \mu_{(i)}^{2}=\frac{1}{2}\left\|f_{1}(X)\right\|^{2}} \\ {\mathcal{L}_{\sigma^{2}}=\frac{1}{2} \sum_{i=1}^{d}\left(\sigma_{(i)}^{2}-\log \sigma_{(i)}^{2}-1\right)}\end{array}</script><blockquote>
<p>推导</p>
<p>由于我们考虑的是各分量独立的多元正态分布，因此只需要推导一元正态分布的情形即可，根据定义我们可以写出</p>
<script type="math/tex; mode=display">
\begin{aligned} & K L\left(N\left(\mu, \sigma^{2}\right) \| N(0,1)\right) \\=& \int \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-(x-\mu)^{2} / 2 \sigma^{2}}\left(\log \frac{e^{-(x-\mu)^{2} / 2 \sigma^{2}} / \sqrt{2 \pi \sigma^{2}}}{e^{-x^{2} / 2} / \sqrt{2 \pi}}\right) d x \\=& \int \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-(x-\mu)^{2} / 2 \sigma^{2}} \log \left\{\frac{1}{\sqrt{\sigma^{2}}} \exp \left\{\frac{1}{2}\left[x^{2}-(x-\mu)^{2} / \sigma^{2}\right]\right\}\right\} d x \\=& \frac{1}{2} \int \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-(x-\mu)^{2} / 2 \sigma^{2}}\left[-\log \sigma^{2}+x^{2}-(x-\mu)^{2} / \sigma^{2}\right] d x \end{aligned}</script><p>整个结果分为三项积分，第一项实际上就是$-\log \sigma^{2}$乘以概率密度的积分（也就是1），所以结果是$-\log \sigma^{2}$; 第二项实际是正态分布的二阶矩，熟悉正态分布的朋友应该都清楚正态分布的二阶矩为$\mu^{2}+\sigma^{2}$；而根据定义，第三项实际上就是“-方差除以方差=-1”。所以总结果就是</p>
<script type="math/tex; mode=display">
K L\left(N\left(\mu, \sigma^{2}\right) \| N(0,1)\right)=\frac{1}{2}\left(-\log \sigma^{2}+\mu^{2}+\sigma^{2}-1\right)</script></blockquote>
<h3 id="Reparemerization-重参"><a href="#Reparemerization-重参" class="headerlink" title="Reparemerization(重参)"></a>Reparemerization(重参)</h3><p>其实很简单，就是我们要从$p(Z|X_k)$中采样一个$Z_k$出来，尽管我们知道了$p(Z|X_k)$是正态分布，但是均值方差都是靠模型算出来的，我们要靠这个过程反过来优化均值方差的模型，但是“采样”这个操作是不可导的，而采样的结果是可导的。我们利用</p>
<script type="math/tex; mode=display">
\begin{aligned} & \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(z-\mu)^{2}}{2 \sigma^{2}}\right) d z \\=& \frac{1}{\sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(\frac{z-\mu}{\sigma}\right)^{2}\right] d\left(\frac{z-\mu}{\sigma}\right) \end{aligned}</script><p>这说明$(z-\mu) / \sigma=\varepsilon$是服从均值为0、方差为1的标准正态分布的，要同时把$dz$考虑进去，是因为乘上$dz$才算是概率，去掉$dz$是概率密度而不是概率。这时候我们得到：</p>
<p>从$\mathcal{N}\left(\mu, \sigma^{2}\right)$ 中采样一个$Z$，相当于从$N(0,I)$中采样一个$\boldsymbol{\varepsilon}$ ，然后让$Z=\mu+\varepsilon \times c$。 </p>
<p>于是，我们将从$\mathcal{N}\left(\mu, \sigma^{2}\right)$采样变成了从$N(0,I)$中采样，然后通过参数变换得到从$\mathcal{N}\left(\mu, \sigma^{2}\right)$ 中采样的结果。这样一来，“采样”这个操作就不用参与梯度下降了，改为采样的结果参与，使得整个模型可训练了。</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/Screen Shot 2018-07-23 at 11.15.34 PM.png" alt="Screen Shot 2018-07-23 at 11.15.34 PM"></p>
<blockquote>
<p><a href="https://spaces.ac.cn/archives/5253" target="_blank" rel="noopener">intuition</a> </p>
<ul>
<li><p>采样操作是不可导，采样之后的加减操作是可导，所以利用了重参技巧？</p>
<p>可以参考这篇<a href="http://lib.csdn.net/article/deeplearning/68143?knId=1748" target="_blank" rel="noopener">文章</a>. 如下图，左边是直接sample隐变量，显然，无法对这个“动作”进行任何数学计算；但是，使用了重参，即右边部分将隐变量的sample变成了一个数学计算，$z = \epsilon*\sigma+\mu$，显然可导。</p>
</li>
<li><p>​</p>
</li>
</ul>
</blockquote>
<p><img src="/2018/07/20/Variational-AutoEncoder/Screen Shot 2018-07-23 at 11.16.40 PM.png" alt="Screen Shot 2018-07-23 at 11.16.40 PM"></p>
<blockquote>
<ol>
<li>由于训练过程只用到 X（同时作为输入和目标输出），而与 X的标签无关，因此，这是无监督学习。</li>
<li>​</li>
</ol>
</blockquote>
<p><img src="/2018/07/20/Variational-AutoEncoder/Screen Shot 2018-07-22 at 1.12.06 AM.png" alt="Screen Shot 2018-07-22 at 1.12.06 AM"></p>
<blockquote>
<p>The generated image is linear combination of existing images.</p>
</blockquote>
<p><a href="http://www.360doc.com/content/17/0930/22/99071_691460743.shtml" target="_blank" rel="noopener">VAE数据流动和损失计算</a> </p>
<p><img src="/2018/07/20/Variational-AutoEncoder/11.jpg" alt="11"></p>
<h1 id="VAE的Keras实现"><a href="#VAE的Keras实现" class="headerlink" title="VAE的Keras实现"></a>VAE的Keras实现</h1><p><a href="https://blog.csdn.net/A_a_ron/article/details/79004163" target="_blank" rel="noopener">detailed explanation</a> </p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
</pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</div>
<div class="line"> </div>
<div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, Lambda</div>
<div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div>
<div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> objectives</div>
<div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div>
<div class="line"><span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</div>
<div class="line"><span class="keyword">import</span> sys</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>输入是$n$维，输出$x\times m$维</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/20161214175120686.png" alt="20161214175120686"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
</pre></td><td class="code"><pre><div class="line">batch_size = <span class="number">100</span></div>
<div class="line">original_dim = <span class="number">784</span>  <span class="comment"># 28*28</span></div>
<div class="line">latent_dim = <span class="number">2</span> <span class="comment"># encoder output size</span></div>
<div class="line">intermediate_dim = <span class="number">256</span> <span class="comment"># neural number of hidden layer</span></div>
<div class="line">nb_epoch = <span class="number">50</span></div>
<div class="line">epsilon_std = <span class="number">1.0</span> </div>
<div class="line"></div>
<div class="line">x = Input(batch_shape=(batch_size, original_dim))</div>
<div class="line">h = Dense(intermediate_dim, activation=<span class="string">'relu'</span>)(x)</div>
<div class="line">z_mean = Dense(latent_dim)(h)</div>
<div class="line">z_log_var = Dense(latent_dim)(h)</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>将encoder的大小为$(2\times m)$的输出视作$m$个高斯多元分布的均值$z_{mean}$和方差的对数$z _ log _ var$</p>
<p><img src="/2018/07/20/Variational-AutoEncoder/20161214175146348.png" alt="20161214175146348"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sampling</span><span class="params">(args)</span>:</span></div>
<div class="line">  z_mean, z_log_var = args</div>
<div class="line">  epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=<span class="number">0.</span>,stddev=epsilon_std)</div>
<div class="line">  <span class="keyword">return</span> z_mean + K.exp(z_log_var / <span class="number">2</span>) * epsilon</div>
<div class="line"></div>
<div class="line">z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p><img src="/2018/07/20/Variational-AutoEncoder/20161214175029514.png" alt="20161214175029514"></p>
<div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">decoder_h = Dense(intermediate_dim, activation=<span class="string">'relu'</span>)</div>
<div class="line">decoder_mean = Dense(original_dim, activation=<span class="string">'sigmoid'</span>)</div>
<div class="line">h_decoded = decoder_h(z)</div>
<div class="line">x_decoded_mean = decoder_mean(h_decoded)</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vae_loss</span><span class="params">(x, x_decoded_mean)</span>:</span></div>
<div class="line">  <span class="comment"># my tips:logloss</span></div>
<div class="line">  xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)</div>
<div class="line">  <span class="comment"># my tips:see paper's appendix B</span></div>
<div class="line">  kl_loss = - <span class="number">0.5</span> * K.sum(<span class="number">1</span> + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=<span class="number">-1</span>)</div>
<div class="line">  <span class="keyword">return</span> xent_loss + kl_loss</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
</pre></td><td class="code"><pre><div class="line">vae = Model(x, x_decoded_mean)</div>
<div class="line">vae.compile(optimizer=<span class="string">'rmsprop'</span>, loss=vae_loss)</div>
<div class="line"></div>
<div class="line"><span class="comment"># train the VAE on MNIST digits</span></div>
<div class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data(path=<span class="string">'mnist.pkl.gz'</span>)</div>
<div class="line"></div>
<div class="line">x_train = x_train.astype(<span class="string">'float32'</span>) / <span class="number">255.</span> <span class="comment"># input normalization</span></div>
<div class="line">x_test = x_test.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></div>
<div class="line">x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[<span class="number">1</span>:])))</div>
<div class="line">x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[<span class="number">1</span>:])))</div>
<div class="line"></div>
<div class="line">vae.fit(x_train, <span class="comment"># regarded as "x", which is "training data"</span></div>
<div class="line">        x_train, <span class="comment"># regarded as "y", which is "target/label data"</span></div>
<div class="line">        shuffle=<span class="keyword">True</span>,</div>
<div class="line">        nb_epoch=nb_epoch,</div>
<div class="line">        verbose=<span class="number">2</span>,<span class="comment"># Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.</span></div>
<div class="line">        batch_size=batch_size,</div>
<div class="line">        validation_data=(x_test, x_test))</div>
</pre></td></tr></table></figure>

</div></div>
<h2 id="Latent-space-display"><a href="#Latent-space-display" class="headerlink" title="Latent space display"></a>Latent space display</h2><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># build a model to project inputs on the latent space</span></div>
<div class="line">encoder = Model(x, z_mean)</div>
<div class="line"><span class="comment"># display a 2D plot of the digit classes in the latent space</span></div>
<div class="line">x_test_encoded = encoder.predict(x_test, batch_size=batch_size)</div>
<div class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</div>
<div class="line">plt.scatter(x_test_encoded[:, <span class="number">0</span>], x_test_encoded[:, <span class="number">1</span>], c=y_test)</div>
<div class="line">plt.colorbar()</div>
<div class="line">plt.show()</div>
</pre></td></tr></table></figure>

</div></div>
<p><img src="/2018/07/20/Variational-AutoEncoder/image-20180724163307750.png" alt="image-20180724163307750"></p>
<h2 id="Generated-pics-display"><a href="#Generated-pics-display" class="headerlink" title="Generated pics display"></a>Generated pics display</h2><div><div class="fold_hider"><div class="close hider_title">点击显/隐内容</div></div><div class="fold">
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
<div class="line">10</div>
<div class="line">11</div>
<div class="line">12</div>
<div class="line">13</div>
<div class="line">14</div>
<div class="line">15</div>
<div class="line">16</div>
<div class="line">17</div>
<div class="line">18</div>
<div class="line">19</div>
<div class="line">20</div>
<div class="line">21</div>
<div class="line">22</div>
<div class="line">23</div>
<div class="line">24</div>
<div class="line">25</div>
<div class="line">26</div>
<div class="line">27</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># build a digit generator that can sample from the learned distribution</span></div>
<div class="line">decoder_input = Input(shape=(latent_dim,))</div>
<div class="line">_h_decoded = decoder_h(decoder_input)</div>
<div class="line">_x_decoded_mean = decoder_mean(_h_decoded)</div>
<div class="line">generator = Model(decoder_input, _x_decoded_mean)</div>
<div class="line"></div>
<div class="line"><span class="comment"># display a 2D manifold of the digits</span></div>
<div class="line">n = <span class="number">15</span>  <span class="comment"># figure with 15x15 digit pics</span></div>
<div class="line">digit_size = <span class="number">28</span> <span class="comment"># size of the pic is 28*28</span></div>
<div class="line">figure = np.zeros((digit_size * n, digit_size * n))</div>
<div class="line"></div>
<div class="line">xy = np.linspace(<span class="number">0.05</span>, <span class="number">0.95</span>, n) <span class="comment"># generate n number in range(0.05,0.95)</span></div>
<div class="line">grid_x = norm.ppf(xy) <span class="comment"># ppf is a inverse function of CDF, e.g. xy=0.1,then ppf return x such that p(X&lt;x)=0.1</span></div>
<div class="line">grid_y = norm.ppf(xy)</div>
<div class="line"></div>
<div class="line"><span class="comment">#plotting</span></div>
<div class="line"><span class="keyword">for</span> i, yi <span class="keyword">in</span> enumerate(grid_x):</div>
<div class="line">    <span class="keyword">for</span> j, xi <span class="keyword">in</span> enumerate(grid_y):</div>
<div class="line">        z_sample = np.array([[xi, yi]])<span class="comment">#1*2</span></div>
<div class="line">        x_decoded = generator.predict(z_sample)</div>
<div class="line">        digit = x_decoded[<span class="number">0</span>].reshape(digit_size, digit_size)<span class="comment">#the generated image</span></div>
<div class="line">        figure[i * digit_size: (i + <span class="number">1</span>) * digit_size,</div>
<div class="line">               j * digit_size: (j + <span class="number">1</span>) * digit_size] = digit</div>
<div class="line"></div>
<div class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</div>
<div class="line">plt.imshow(figure, cmap=<span class="string">'Greys_r'</span>)</div>
<div class="line">plt.show()</div>
</pre></td></tr></table></figure>

</div></div>
<p><img src="/2018/07/20/Variational-AutoEncoder/image-20180724163319485.png" alt="image-20180724163319485"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.cnblogs.com/huangshiyu13/p/6209016.html" target="_blank" rel="noopener">AE to VAE</a> <a href="https://www.cnblogs.com/wangxiaocvpr/p/6231019.html" target="_blank" rel="noopener">AE vs VAE</a> <a href="http://chengjunwen.github.io/2017/01/02/VAE/" target="_blank" rel="noopener">intuition3</a> <a href="https://zhuanlan.zhihu.com/p/25269592" target="_blank" rel="noopener">gotcha</a> </p>
<p><a href="https://blog.csdn.net/jackytintin/article/details/53641885" target="_blank" rel="noopener">ref1</a> <a href="https://blog.csdn.net/u011534057/article/details/78911902" target="_blank" rel="noopener">ref2</a> <a href="http://lib.csdn.net/article/deeplearning/68143?knId=1748" target="_blank" rel="noopener">ref3</a> <a href="http://www.dengfanxin.cn/?p=334" target="_blank" rel="noopener">ref4</a> <a href="https://yq.aliyun.com/articles/68410" target="_blank" rel="noopener">[intuition about learn latent gaussian distribution]</a> <a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/" target="_blank" rel="noopener">ref7</a> <a href="https://blog.csdn.net/heyc861221/article/details/80130968" target="_blank" rel="noopener">VAE vs GAN</a> </p>
<p><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ" target="_blank" rel="noopener">video1</a> <a href="https://zhuanlan.zhihu.com/p/25401928" target="_blank" rel="noopener">公式</a> </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Variational-AutoEncoder/" rel="tag"># Variational AutoEncoder</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/17/Density-Map/" rel="next" title="Density Map">
                <i class="fa fa-chevron-left"></i> Density Map
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/20/Generative-Adversarial-Networks/" rel="prev" title="Generative Adversarial Networks">
                Generative Adversarial Networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">90</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">68</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#判别式模型-VS-生成式模型"><span class="nav-number">1.</span> <span class="nav-text">判别式模型 VS 生成式模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Intuition-behind-VAE"><span class="nav-number">2.</span> <span class="nav-text">Intuition behind VAE</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Network-Structure"><span class="nav-number">3.</span> <span class="nav-text">Network Structure</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Math-in-VAE"><span class="nav-number">4.</span> <span class="nav-text">Math in VAE</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Intro"><span class="nav-number">4.1.</span> <span class="nav-text">Intro</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reparemerization-重参"><span class="nav-number">4.1.1.</span> <span class="nav-text">Reparemerization(重参)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VAE的Keras实现"><span class="nav-number">5.</span> <span class="nav-text">VAE的Keras实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Encoder"><span class="nav-number">5.1.</span> <span class="nav-text">Encoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sampling"><span class="nav-number">5.2.</span> <span class="nav-text">Sampling</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decoder"><span class="nav-number">5.3.</span> <span class="nav-text">Decoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-Function"><span class="nav-number">5.4.</span> <span class="nav-text">Loss Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training"><span class="nav-number">5.5.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Latent-space-display"><span class="nav-number">5.6.</span> <span class="nav-text">Latent space display</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generated-pics-display"><span class="nav-number">5.7.</span> <span class="nav-text">Generated pics display</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
