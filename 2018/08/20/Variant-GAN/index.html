<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,GAN,Variant GAN," />










<meta name="description" content="我们之前介绍了GAN模型，在本章中，将介绍一些GAN的变体模型。">
<meta name="keywords" content="Deep Learning,GAN,Variant GAN">
<meta property="og:type" content="article">
<meta property="og:title" content="Variant GAN">
<meta property="og:url" content="http://yoursite.com/2018/08/20/Variant-GAN/index.html">
<meta property="og:site_name" content="Blog of Qing">
<meta property="og:description" content="我们之前介绍了GAN模型，在本章中，将介绍一些GAN的变体模型。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/p.jpg">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.33.12%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.36.15%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.36.22%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-04%20at%204.19.29%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%2010.00.41%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%2010.03.51%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.51.26%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.51.35%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.29.24%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.29.48%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%203.34.27%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.44.58%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%205.11.30%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%205.11.57%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-02%20at%207.59.25%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%209.46.02%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.44.58%20PM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/9dd87e799b054c538ead26df0d7394fb_th.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/ac5b965024b647a8954ade2c6bdf22d3_th.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/84bbfddafa9c4d9cb3c2b5aa2ec2e3f2_th.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/u_net.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/86c9fccb701d4bc8b4011fa4bc259f6a_th.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/4.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/6.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/4.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/schematic.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Screen%20Shot%202018-09-03%20at%209.51.47%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Screen%20Shot%202018-09-03%20at%2010.09.37%20AM.png">
<meta property="og:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Screen%20Shot%202018-09-03%20at%2010.10.36%20AM.png">
<meta property="og:updated_time" content="2018-11-16T14:58:05.966Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Variant GAN">
<meta name="twitter:description" content="我们之前介绍了GAN模型，在本章中，将介绍一些GAN的变体模型。">
<meta name="twitter:image" content="http://yoursite.com/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/p.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/08/20/Variant-GAN/"/>





  <title>Variant GAN | Blog of Qing</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog of Qing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/20/Variant-GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qing Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog of Qing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Variant GAN</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-20T10:54:39+08:00">
                2018-08-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>我们之前介绍了GAN模型，在本章中，将介绍一些GAN的变体模型。</p>
<a id="more"></a>
<p><a href="https://github.com/wiseodd/generative-models" target="_blank" rel="noopener">CODE in TENSORFLOW</a> <a href="https://www.sohu.com/a/143961544_741733" target="_blank" rel="noopener">summary</a> <a href="https://github.com/eriklindernoren/Keras-GAN" target="_blank" rel="noopener">CODE in KERAS</a> </p>
<p>原始的GAN模型存在着无约束、不可控、噪声信号z很难解释等问，近年来，在原始GAN模型的基础上衍生出了很多种模型，如：条——CGAN、卷积——DCGAN等等</p>
<h2 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h2><p><a href="https://zhuanlan.zhihu.com/p/27012520" target="_blank" rel="noopener">REF1</a> <a href="https://www.leiphone.com/news/201701/yZvIqK8VbxoYejLl.html?viewType=weixin" target="_blank" rel="noopener">GAN vs DCGAN</a> </p>
<p>DCGAN的原理和GAN是一样的，它只是把上述的G和D换成了两个卷积神经网络（CNN）。但不是直接换就可以了，DCGAN对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度，这些改变有：</p>
<ul>
<li>取消所有pooling层。G网络中使用转置卷积（transposed convolutional layer）进行上采样，D网络中用加入stride的卷积代替pooling。</li>
<li>在D和G中均使用batch normalization</li>
<li>去掉FC层，使网络变为全卷积网络</li>
<li>G网络中使用ReLU作为激活函数，最后一层使用tanh</li>
<li>D网络中使用LeakyReLU作为激活函数</li>
</ul>
<p>DCGAN极大的提升了GAN训练的稳定性以及生成结果质量。<a href="https://blog.csdn.net/qq_25737169/article/details/78857788" target="_blank" rel="noopener">Ref</a> </p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/p.jpg" alt="p"></p>
<p>DCGAN的生成器网络结构如上图所示，相较原始的GAN，DCGAN几乎完全使用了卷积层代替全链接层，判别器几乎是和生成器对称的，从上图中我们可以看到，整个网络没有pooling层和上采样层的存在，实际上是使用了带步长（fractional-strided）的卷积代替了上采样，以增加训练的稳定性。</p>
<h3 id="Experiment-Settings"><a href="#Experiment-Settings" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h3><p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.33.12%20PM.png" alt="Screen Shot 2018-08-06 at 4.33.12 PM"></p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.36.15%20PM.png" alt="Screen Shot 2018-08-06 at 4.36.15 PM"></p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.36.22%20PM.png" alt="Screen Shot 2018-08-06 at 4.36.22 PM"></p>
<h2 id="LS-GAN"><a href="#LS-GAN" class="headerlink" title="LS-GAN"></a>LS-GAN</h2><p><a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/lsgan/lsgan.py" target="_blank" rel="noopener">code</a> <a href="http://www.myzaker.com/article/58bbd2171bc8e0892800000f/" target="_blank" rel="noopener">ref1</a> </p>
<p>最小二乘GAN，在gan的基础上将目标函数变成一个平方误差。实现上直接在gan的基础上修改loss函数</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-04%20at%204.19.29%20PM.png" alt="Screen Shot 2018-08-04 at 4.19.29 PM"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">self.discriminator.compile(loss=<span class="string">'mse'</span>,</div>
<div class="line">            optimizer=optimizer,</div>
<div class="line">            metrics=[<span class="string">'accuracy'</span>])</div>
<div class="line">self.combined.compile(loss=<span class="string">'mse'</span>, optimizer=optimizer)</div>
</pre></td></tr></table></figure>
<h2 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h2><p><a href="https://blog.csdn.net/wspba/article/details/54666907" target="_blank" rel="noopener">ref1</a> </p>
<p>生成对抗网络：Generative Adversarial Networks，通过generator和discriminator的对抗学习，最终可以得到一个与real data分布一致的fake data，但是由于generator的输入z是一个连续的噪声信号，并且没有任何约束，我们很难通过控制z中某数的大小变化让生成的图像发生变化。</p>
<p>GAN中输入是随机的数据，没有太多意义，那么我们很自然的会想到能否用输入改成一个有意义的数据，最简单的就是数字字体生成，能否输入一个数字，然后输出对应的字体。这就是CGAN要做的事。</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%2010.00.41%20AM.png" alt="Screen Shot 2018-07-31 at 10.00.41 AM"></p>
<p>To include conditional constrain into the cycleGAN network, the adversarial<br>loss is modified to include the conditional feature vector as part of the input of the generator and<br>discriminator</p>
<p>在生成器模型中，条件变量y实际上是作为一个额外的输入层（additional input layer），它与生成器的噪声输入p(z)组合形成了一个联合的隐层表达；在判别器模型中，y与真实数据x也是作为输入，并输入到一个判别函数当中。实际上就是将z和x分别于y进行concat，分别作为生成器和判别器的输入，再来进行训练。</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%2010.03.51%20AM.png" alt="Screen Shot 2018-07-31 at 10.03.51 AM"></p>
<p>训练方式几乎就是不变的，但是从GAN的无监督变成了有监督。只是大家可以看到，这里和传统的图像分类这样的任务正好反过来了，图像分类是输入图片，然后对图像进行分类，而这里是输入分类，要反过来输出图像。</p>
<h3 id="Experiment-Settings-1"><a href="#Experiment-Settings-1" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h3><p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.51.26%20PM.png" alt="Screen Shot 2018-08-06 at 4.51.26 PM"></p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%204.51.35%20PM.png" alt="Screen Shot 2018-08-06 at 4.51.35 PM"></p>
<h2 id="Info-GAN"><a href="#Info-GAN" class="headerlink" title="Info-GAN"></a>Info-GAN</h2><p><a href="http://www.360doc.com/content/17/0930/22/99071_691460743.shtml" target="_blank" rel="noopener">REF1</a> <a href="https://blog.csdn.net/wspba/article/details/54808833" target="_blank" rel="noopener">REF2</a> <a href="https://blog.csdn.net/hjimce/article/details/55657325" target="_blank" rel="noopener">GOTTA</a> <a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/infogan/infogan.py" target="_blank" rel="noopener">CODE in KERAS</a> <a href="https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/" target="_blank" rel="noopener">to-do</a> </p>
<p>有了CGAN，我们可以有一个单一输入y，然后通过调整z输出不同的图像。但是CGAN是有监督的，我们需要指定y。那么有没有可能实现无监督的CGAN？这个想法本身就比较疯狂，要实现无监督的CGAN，意味着需要让神经网络不但通过学习提取了特征，还需要把特征表达出来。对于MNIST，如何通过无监督学习让神经网络知道你输入y=2时就输出2的字体？或者用一个连续的值来调整字的粗细，方向？</p>
<p>怎么做呢？作者引入了信息论的知识，也就是mutual information互信息。作者的思路就是G网络的输入除了z之外同样类似CGAN输入一个c变量，这个变量一开始神经网络并不知道是什么含义，但是没关系，我们希望c与G网络输出的x之间的互信息最大化，也就是让神经网络自己去训练c与输出之间的关系。</p>
<p>为了引入c，作者利用互信息来对c进行约束，这是因为如果c对于生成数据G(z,c)具有可解释性，那么c和G(z,c)应该具有高度相关性，即互信息大，而如果是无约束的话，那么它们之间没有特定的关系，即互信息接近于0。因此我们希望c与G(z,c)的互信息I(c;G(z,c))越大越好，mutual information在文章中定义如下：</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.29.24%20PM.png" alt="Screen Shot 2018-07-31 at 4.29.24 PM"></p>
<p>基于I，整个GAN的训练目标变成：</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.29.48%20PM.png" alt="Screen Shot 2018-07-31 at 4.29.48 PM"></p>
<blockquote>
<ol>
<li>超参数$\lambda$设置为1</li>
<li>相当于在原始gan模型上加了一个互信息的正则化项</li>
<li>对于c，如果是categorical latent code，可以使用softmax的非线性输出来代表Q(c|x)；如果是continuous latent code，可以使用高斯分布来表示。</li>
</ol>
</blockquote>
<p>在最后实现的时候，infoGAN可以看成三个网络：(1)生成网络$x=G(c,z)$；(2)判别真伪网络$y_1=D_1(x)$；(3)判别类别$c$网络$y_2=D_2(x)$(当$c$代表类别信息的时候，网络最后一层是softmax层，且$D_1,D_2$共享网络参数，除了网络的最后一层外)；</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%203.34.27%20PM.png" alt="Screen Shot 2018-07-31 at 3.34.27 PM"></p>
<p>相比CGAN，InfoGAN在网络上做了一定改变：</p>
<p>（1）D网络的输入只有x，不加c。</p>
<p>（2）Q网络和D网络共享同一个网络，只是到最后一层独立输出。</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.44.58%20PM.png" alt="Screen Shot 2018-07-31 at 4.44.58 PM"></p>
<h3 id="Experiment-Setup"><a href="#Experiment-Setup" class="headerlink" title="Experiment Setup"></a>Experiment Setup</h3><p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%205.11.30%20PM.png" alt="Screen Shot 2018-08-06 at 5.11.30 PM"></p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%205.11.57%20PM.png" alt="Screen Shot 2018-08-06 at 5.11.57 PM"></p>
<h2 id="AC-GAN"><a href="#AC-GAN" class="headerlink" title="AC-GAN"></a>AC-GAN</h2><p><a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py" target="_blank" rel="noopener">ac-gan in keras</a> </p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-02%20at%207.59.25%20PM.png" alt="Screen Shot 2018-08-02 at 7.59.25 PM"></p>
<p><strong>Generator Input  [ noise , label ]</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line">noise = Input(shape=(self.latent_dim,))</div>
<div class="line">        label = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>)</div>
<div class="line">        label_embedding = Flatten()(Embedding(self.num_classes, <span class="number">100</span>)(label))</div>
<div class="line">        model_input = multiply([noise, label_embedding])</div>
<div class="line">        img = model(model_input)</div>
</pre></td></tr></table></figure>
<p><strong>Discriminator Output [ real/fake , prediction label ]</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">validity = Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)(features)</div>
<div class="line">label = Dense(self.num_classes+<span class="number">1</span>, activation=<span class="string">"softmax"</span>)(features)</div>
</pre></td></tr></table></figure>
<h3 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup"></a>Experiment setup</h3><p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-08-06%20at%209.46.02%20PM.png" alt="Screen Shot 2018-08-06 at 9.46.02 PM"></p>
<h2 id="Context-GAN"><a href="#Context-GAN" class="headerlink" title="Context-GAN"></a>Context-GAN</h2><p><a href="https://arxiv.org/pdf/1604.07379.pdf" target="_blank" rel="noopener">PAPER</a> <a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/context_encoder/context_encoder.py" target="_blank" rel="noopener">CODE</a> </p>
<h2 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h2><p><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">REF1</a> <a href="http://www.sohu.com/a/148114422_500659" target="_blank" rel="noopener">ref2</a> <a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py" target="_blank" rel="noopener">code</a> </p>
<p>限制discriminator的权重范围$[-0.01,0.01]$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Clip critic weights</span></div>
<div class="line"><span class="keyword">for</span> l <span class="keyword">in</span> self.critic.layers:</div>
<div class="line">    weights = l.get_weights()</div>
<div class="line">    weights = [np.clip(w, -self.clip_value,self.clip_value) <span class="keyword">for</span> w <span class="keyword">in</span> weights]</div>
<div class="line">    l.set_weights(weights)</div>
</pre></td></tr></table></figure>
<p>损失函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">wasserstein_loss</span><span class="params">(self, y_true, y_pred)</span>:</span></div>
<div class="line">    <span class="keyword">return</span> K.mean(y_true * y_pred)</div>
</pre></td></tr></table></figure>
<p>ground-truth</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line"><span class="comment"># Adversarial ground truths</span></div>
<div class="line">valid = -np.ones((batch_size, <span class="number">1</span>))</div>
<div class="line">fake = np.ones((batch_size, <span class="number">1</span>))</div>
</pre></td></tr></table></figure>
<h1 id="GAN-IN-KERAS"><a href="#GAN-IN-KERAS" class="headerlink" title="GAN_IN_KERAS"></a>GAN_IN_KERAS</h1><p>构造网络</p>
<p>虽然训练的时候是基于batch大小，但是在设计网络的时候，考虑的是只训练一个样本的网络，Keras有两种形式设置一个神经网络，Model和Sequential。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
</pre></td><td class="code"><pre><div class="line">input_shape = (img_rows, img_cols, channel)</div>
<div class="line">x_input = Input(input_shape) <span class="comment">#如果有多个输入，则写多个Input函数</span></div>
<div class="line">h = Conv2D(<span class="number">256</span>, (k, k), strides=(<span class="number">2</span>, <span class="number">2</span>), border_mode=<span class="string">'same'</span>)(x)</div>
<div class="line">h = BatchNormalization(momentum=<span class="number">0.8</span>)(h)</div>
<div class="line">h = LeakyReLU(<span class="number">0.2</span>)(h)</div>
<div class="line">....</div>
<div class="line">y_output = Dense(<span class="number">10</span>)(h)</div>
<div class="line">model = Model([x_input], [y_output]) <span class="comment">#指明网络的输入，输出，需要与train_on_batch相对应</span></div>
</pre></td></tr></table></figure>
<p>损失函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
</pre></td><td class="code"><pre><div class="line">loss = </div>
<div class="line">model.add_loss(loss)</div>
<div class="line">discriminator.compile(optimizer=opt, loss = <span class="keyword">None</span>)</div>
<div class="line">discriminator.summary()</div>
</pre></td></tr></table></figure>
<p>训练</p>
<p>一般我们先训练discriminator，它的输入正常情况下是真假图片，真图片来自于训练集，假图片来自于generator输出，我们利用generator模型的prediction函数生成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">imgs_batch = x_train[idx,:,:,:]</div>
<div class="line">generated_imgs = generator.predict(imgs_batch)</div>
</pre></td></tr></table></figure>
<p>这样我们就有了真假图片，就可以训练了，函数是model_name.train_on_batch(x,y)，其中$x$就是神经网络的训练集输入，$y$是训练集的ground-truth，看discriminator的输出。</p>
<p>训练discriminator时，它的输入就是一张图片，输出就是真假概率，所以</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
</pre></td><td class="code"><pre><div class="line">discriminator.train_on_batch( x = imgs_batch, y = np.ones(shape=(batch_size,<span class="number">1</span>)) ) </div>
<div class="line"></div>
<div class="line">discriminator.train_on_batch( x = generated_imgs, y = np.zeros(shape=(batch_size,<span class="number">1</span>)) )</div>
</pre></td></tr></table></figure>
<p>训练generate模型，则输入是noise，x = np.random.uniform(0,1,size=(batch_size,100))，它的ground_truth是y=np.ones(shape=(batch_size,1))。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">generator.train_on_batch(x = np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,size=(batch_size,<span class="number">100</span>)),</div>
<div class="line">                         y=np.ones(shape=(batch_size,<span class="number">1</span>)) )</div>
</pre></td></tr></table></figure>
<blockquote>
<p>如果是cgan或者info-gan，那么会有额外的输入和输出，如下图：</p>
<p><img src="/2018/08/20/Variant-GAN/Users/daniel/Downloads/Nutstore/Git-PersonalWeb/QingWebsite/website/source/_posts/Generative-Adversarial-Networks/Screen%20Shot%202018-07-31%20at%204.44.58%20PM.png" alt="Screen Shot 2018-07-31 at 4.44.58 PM"></p>
<p>这是info-gan，可以看到，在gan基础上有了一个额外输入$c(latent)$，有了一个额外的输出$c$。所以generator的input是x = np.concatenate( z , c )，输出是y = ( f_r_label , c ) ，每一个输出都需要一个ground-truth，所以generator的训练代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div>
<div class="line">2</div>
</pre></td><td class="code"><pre><div class="line">&gt; generator.train_on_batch(x = np.concatenate( z , c ),y = [np.ones(batch_size,<span class="number">1</span>),c])</div>
<div class="line">&gt;</div>
</pre></td></tr></table></figure>
</blockquote>
<h2 id="DRAW-A-Recurrent-Neural-Network-For-Image-Generation"><a href="#DRAW-A-Recurrent-Neural-Network-For-Image-Generation" class="headerlink" title="DRAW: A Recurrent Neural Network For Image Generation"></a>DRAW: A Recurrent Neural Network For Image Generation</h2><p> <a href="https://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="noopener">paper</a>  <a href="https://github.com/ericjang/draw" target="_blank" rel="noopener">tensorflow</a>  <a href="">2015 - 800citation</a> <a href="https://blog.evjang.com/2016/06/understanding-and-implementing.html" target="_blank" rel="noopener">ref</a> </p>
<p>the DRAW network is a generative model of<br>images in the variational auto-encoder framework that decomposes image formation into multiple<br>stages of additions to a canvas matrix. The DRAW paper assumes an LSTM based generative model<br>of these sequential drawing actions which is more general than our model. In practice, these drawing<br>actions seem to progressively refine an initially blurry region of an image to be sharper. </p>
<h2 id="Pix2pix"><a href="#Pix2pix" class="headerlink" title="Pix2pix"></a>Pix2pix</h2><p><a href="https://arxiv.org/pdf/1611.07004.pdf" target="_blank" rel="noopener">paper</a>  <a href="http://www.sohu.com/a/134110704_741733" target="_blank" rel="noopener">ref1</a> <a href="https://github.com/affinelayer/pix2pix-tensorflow" target="_blank" rel="noopener">tensorflow</a> </p>
<p>pix2pix是基于条件对抗生成网络来学习从输入图像到输出图像的映射。</p>
<h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>生成器的目标就是将输入的图像转换为目标图像，利用编码-解码器的架构来实现。</p>
<p><img src="/2018/08/20/Variant-GAN/9dd87e799b054c538ead26df0d7394fb_th.png" alt="9dd87e799b054c538ead26df0d7394fb_th"></p>
<p>输入图像是256*256大小3种颜色通道的图像（红、绿、蓝通道，对于黑白图，这三个通道的数值相等）。生成器接收输入，并将它用一系列编码器（卷积＋激活函数）简化成更小的表示（representation）。这样做的基本想法是我们用最终的编码层可以得到一种对数据更高层次（抽象）的表达。解码器层呢主要做了相反的操作（反卷积deconvolution＋激活函数），并将编码层的动作反过来。</p>
<p><img src="/2018/08/20/Variant-GAN/ac5b965024b647a8954ade2c6bdf22d3_th.png" alt="ac5b965024b647a8954ade2c6bdf22d3_th"></p>
<p>为了提高这种图像到图像转换的效率，作者用了一种称为U－Net的方法而不是编码－解码器方法。它们本来是一回事，但是U－Net引入了所谓的“跳跃链接”，以便将编码器层和解码器层直接相连，这种跳跃链接可以为网络提供一种省略编码／解码部分的选择，从而当网络真的用不到它们的时候，处理效率就会很快了。</p>
<p><img src="/2018/08/20/Variant-GAN/84bbfddafa9c4d9cb3c2b5aa2ec2e3f2_th.png" alt="84bbfddafa9c4d9cb3c2b5aa2ec2e3f2_th"></p>
<blockquote>
<p>U-Net网络结构</p>
<p><img src="/2018/08/20/Variant-GAN/u_net.png" alt="u_net"></p>
</blockquote>
<h3 id="辨别器"><a href="#辨别器" class="headerlink" title="辨别器"></a>辨别器</h3><p>对比发现，生成器和辨别器的输入是不同的：前者只有一张图片作为输入，后者有两张图片作为输入，辨别器的输出是一个30*30的图像，每一个像素都是0～1的数值，代表了这一部分与目标图像比起来有多像。在pix2pix的执行中，这30*30图像中的每一个像素都对应了输入图像的70*70个块（patch，这些patch会有很多重叠，因为输入图像大小是256*256）。这种架构称为“PatchGAN”。</p>
<p><img src="/2018/08/20/Variant-GAN/86c9fccb701d4bc8b4011fa4bc259f6a_th.png" alt="86c9fccb701d4bc8b4011fa4bc259f6a_th"></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><h4 id="生成器-1"><a href="#生成器-1" class="headerlink" title="生成器"></a>生成器</h4><p>除了辨别器判断生成图片的真假损失</p>
<p><img src="/2018/08/20/Variant-GAN/4.png" alt="4"></p>
<p>还有$L_1$损失来衡量生成图片的优劣。</p>
<p><img src="/2018/08/20/Variant-GAN/6.png" alt="6"></p>
<h4 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h4><p>在损失函数中，L1被添加进来来保证输入和输出的共性。这就启发出了一个观点，那就是图像的变形分为两种，局部的和全局的。既然L1可以防止全局的变形。那么只要让D去保证局部能够精准即可。于是，Pix2Pix中的D被实现为Patch-D，D区分图像中的每个$N*N$大小的补丁是真是假。</p>
<p><img src="/2018/08/20/Variant-GAN/4.png" alt="4"></p>
<h2 id="Pix2PixHD"><a href="#Pix2PixHD" class="headerlink" title="Pix2PixHD"></a>Pix2PixHD</h2><p><a href="">paper</a>  <a href="https://blog.csdn.net/linmingan/article/details/79941645" target="_blank" rel="noopener">ref1</a> <a href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/78740321" target="_blank" rel="noopener">ref2</a> </p>
<h2 id="Coupled-GAN"><a href="#Coupled-GAN" class="headerlink" title="Coupled-GAN"></a>Coupled-GAN</h2><p><a href="https://arxiv.org/pdf/1606.07536.pdf" target="_blank" rel="noopener">paper</a> <a href="https://wiseodd.github.io/techblog/2017/02/18/coupled_gan/" target="_blank" rel="noopener">ref</a> <a href="https://github.com/eriklindernoren/Keras-GAN/blob/master/cogan/cogan.py" target="_blank" rel="noopener">keras</a> </p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>AAE是一种学习数据分布$P(X)$的方法，Conditional GAN则学习数据的条件分布$P(X|c)$，而Coupled-GAN意在学习数据的联合分布$P(X_1,X_2)$，其中$X_1, X_2$是来自不同域的，比如同一个场景的图片但是一个是彩色图片，一个是深度图片；又或者同一张脸的不同表情（笑和不笑）。</p>
<p>Coupled-GAN是从数据的边缘分布$x_1 \sim P(X_1)$和$x_2 \sim P(X_2)$采样，来学习数据的联合分布，而实现这个的技巧是权值共享。我们认为数据的高层级表征是共享的，故我们强制网络共享部分层的权重，这样CoGAN会趋近学习到两种域数据的共同表征，也就是它们的联合分布。</p>
<p>但是，网络共享哪些层的权重呢？我们知道，神经网络在进行分类任务时，是从下到上的方式学习数据的特征，也即是说从低层级特征到高层级特征。低层级特征过于细致，不够泛化，它们往往捕捉图片的厚度，色彩饱和度等特征；而高层级特征能够学习到数据更为抽象的特征，比如“鸟”，“狗”，忽略图片色彩厚度等细节，所以我们强制神经网络的处理高层级的层共享参数。</p>
<p>对discriminator来说，它的共享层应为最后几层；而对generator来说，它的共享层应该是前面几层，因为生成器的工作方式是从抽象特征生成具体图像。</p>
<p><img src="/2018/08/20/Variant-GAN/schematic.png" alt="schematic"></p>
<h3 id="LOSS-FUNC"><a href="#LOSS-FUNC" class="headerlink" title="LOSS FUNC"></a>LOSS FUNC</h3><p>只使用了GAN损失。</p>
<h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><h4 id="Digit-Rotation"><a href="#Digit-Rotation" class="headerlink" title="Digit Rotation"></a>Digit Rotation</h4><p>生成MNIST手写体数字图片相对应的90度旋转图片。两个数据域分别是MNIST图片和被旋转90的手写数字图片。</p>
<p><img src="/2018/08/20/Variant-GAN/Screen Shot 2018-09-03 at 9.51.47 AM.png" alt="Screen Shot 2018-09-03 at 9.51.47 AM"></p>
<h4 id="Digit-Edge"><a href="#Digit-Edge" class="headerlink" title="Digit Edge"></a>Digit Edge</h4><p>生成手写体数字相应的边缘图片。</p>
<p><img src="/2018/08/20/Variant-GAN/Screen Shot 2018-09-03 at 10.09.37 AM.png" alt="Screen Shot 2018-09-03 at 10.09.37 AM"></p>
<h4 id="Negative-Image"><a href="#Negative-Image" class="headerlink" title="Negative Image"></a>Negative Image</h4><p>生成图像的反图像。<a href="https://blog.csdn.net/JohinieLi/article/details/77098915" target="_blank" rel="noopener">PIL-Negative Img</a> </p>
<p><img src="/2018/08/20/Variant-GAN/Screen Shot 2018-09-03 at 10.10.36 AM.png" alt="Screen Shot 2018-09-03 at 10.10.36 AM"></p>
<h4 id="Color-amp-Depth-Images"><a href="#Color-amp-Depth-Images" class="headerlink" title="Color &amp; Depth Images"></a>Color &amp; Depth Images</h4><h2 id="Domain数据迁移"><a href="#Domain数据迁移" class="headerlink" title="Domain数据迁移"></a>Domain数据迁移</h2><p><strong>CycleGAN</strong>，<strong>DualGAN</strong>，<strong>DiscoGAN</strong></p>
<h3 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><p><a href="https://zhuanlan.zhihu.com/p/26995910" target="_blank" rel="noopener">ref1</a> <a href="https://blog.csdn.net/qq_21190081/article/details/78807931" target="_blank" rel="noopener">ref2</a> <a href="https://blog.csdn.net/on2way/article/details/78768221" target="_blank" rel="noopener">ref3</a> </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/GAN/" rel="tag"># GAN</a>
          
            <a href="/tags/Variant-GAN/" rel="tag"># Variant GAN</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/18/Logistic-Regression/" rel="next" title="Logistic Regression">
                <i class="fa fa-chevron-left"></i> Logistic Regression
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/21/Algorithm/" rel="prev" title="Algorithm">
                Algorithm <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Qing Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">66</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#DCGAN"><span class="nav-number">1.</span> <span class="nav-text">DCGAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-Settings"><span class="nav-number">1.1.</span> <span class="nav-text">Experiment Settings</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LS-GAN"><span class="nav-number">2.</span> <span class="nav-text">LS-GAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conditional-GAN"><span class="nav-number">3.</span> <span class="nav-text">Conditional GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-Settings-1"><span class="nav-number">3.1.</span> <span class="nav-text">Experiment Settings</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Info-GAN"><span class="nav-number">4.</span> <span class="nav-text">Info-GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-Setup"><span class="nav-number">4.1.</span> <span class="nav-text">Experiment Setup</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AC-GAN"><span class="nav-number">5.</span> <span class="nav-text">AC-GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiment-setup"><span class="nav-number">5.1.</span> <span class="nav-text">Experiment setup</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Context-GAN"><span class="nav-number">6.</span> <span class="nav-text">Context-GAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#WGAN"><span class="nav-number">7.</span> <span class="nav-text">WGAN</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GAN-IN-KERAS"><span class="nav-number"></span> <span class="nav-text">GAN_IN_KERAS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DRAW-A-Recurrent-Neural-Network-For-Image-Generation"><span class="nav-number">1.</span> <span class="nav-text">DRAW: A Recurrent Neural Network For Image Generation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pix2pix"><span class="nav-number">2.</span> <span class="nav-text">Pix2pix</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#生成器"><span class="nav-number">2.1.</span> <span class="nav-text">生成器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#辨别器"><span class="nav-number">2.2.</span> <span class="nav-text">辨别器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">2.3.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#生成器-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">生成器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#判别器"><span class="nav-number">2.3.2.</span> <span class="nav-text">判别器</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pix2PixHD"><span class="nav-number">3.</span> <span class="nav-text">Pix2PixHD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Coupled-GAN"><span class="nav-number">4.</span> <span class="nav-text">Coupled-GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">4.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LOSS-FUNC"><span class="nav-number">4.2.</span> <span class="nav-text">LOSS FUNC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Application"><span class="nav-number">4.3.</span> <span class="nav-text">Application</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Digit-Rotation"><span class="nav-number">4.3.1.</span> <span class="nav-text">Digit Rotation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Digit-Edge"><span class="nav-number">4.3.2.</span> <span class="nav-text">Digit Edge</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Negative-Image"><span class="nav-number">4.3.3.</span> <span class="nav-text">Negative Image</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Color-amp-Depth-Images"><span class="nav-number">4.3.4.</span> <span class="nav-text">Color &amp; Depth Images</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Domain数据迁移"><span class="nav-number">5.</span> <span class="nav-text">Domain数据迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CycleGAN"><span class="nav-number">5.1.</span> <span class="nav-text">CycleGAN</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qing Wong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
